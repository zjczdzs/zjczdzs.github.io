[{"categories":["分布式技术"],"content":"go语言开发的纯开源的面向云原生的分布式缓存。","date":"2023-06-06","objectID":"/nast%E6%A6%82%E8%BF%B0/","tags":["nast,分布式缓存，golang"],"title":"NAST概述","uri":"/nast%E6%A6%82%E8%BF%B0/"},{"categories":["分布式技术"],"content":"一、NATS介绍 NATS是由CloudFoundry的架构师Derek开发的一个开源的、轻量级、高性能的，支持发布、订阅机制的分布式消息队列系统。它的核心基于EventMachine开发，代码量不多，可以下载下来慢慢研究。 不同于Java社区的kafka，nats偏于redis式的消息中间件，不不像Kafka式的可以持久化。 NATS原来是使用Ruby编写，可以实现每秒150k消息，后来使用Go语言重写，能够达到每秒8-11百万个消息，整个程序很小只有3M Docker image，它不支持持久化消息，如果你离线，你就不能获得消息。 NATS适合云基础设施的消息通信系统、IoT设备消息通信和微服务架构。 目前已经采用了NATS系统的公司有：爱立信、HTC、百度、西门子、VMware。 NATS 有 3 个产品 core-nats: 不做持久化的及时信息传输系统 nats-streaming: 基于 nats 的持久化消息队列(已弃用) nats-jetstream: 基于 nats 的持久化消息队列 二、NATS服务器与客户端 NATS服务器与客户端 NATS服务器：用Golang语言开发，发行版包括二进制发布包和Docker镜像。 NATS客户端：包含了多种语言的客户端。 官方提供的客户端 Go client：　https://github.com/nats-io/go-nats Node.js client： https://github.com/nats-io/node-nats Ruby client：　https://github.com/nats-io/ruby-nats Java client：　https://github.com/nats-io/jnats C client：　https://github.com/nats-io/cnats C# client：　https://github.com/nats-io/csnats Nginx C client：https://github.com/nats-io/nginx-nats 还有社区提供的客户端： Spring： https://github.com/cloudfoundry-community/java-nats Lua：　https://github.com/DawnAngel/lua-nats PHP： https://github.com/repejota/phpnats Python：https://github.com/mcuadros/pynats Scala： https://github.com/tyagihas/scala_nats/ Haskell：https://github.com/ondrap/nats-queue 查看客户端API技巧 对于Golang客户端API文档，需要这样： 1）用 Go 下载 go版本客户端源码及使用文档 go git https://github.com/nats-io/go-nats.git 2）使用 Go 文档查看器来查看线上文档 godoc -http :8080 3）通过浏览器访问 API 文档 http://localhost:8080/pkg/github.com/nats-io/gnatsd/ 三、NATS的设计目标 ","date":"2023-06-06","objectID":"/nast%E6%A6%82%E8%BF%B0/:0:0","tags":["nast,分布式缓存，golang"],"title":"NAST概述","uri":"/nast%E6%A6%82%E8%BF%B0/"},{"categories":["分布式技术"],"content":"3.1 NATS的设计原则 NATS的设计原则是：高性能、可伸缩能力、易于使用，基于这些原则，NATS的设计目标包括： 1）高性能（fast） 2）一直可用（dial tone） 3）极度轻量级（small footprint） 4）最多交付一次（fire and forget，消息发送后不管） 5）支持多种消息通信模型和用例场景（flexible） ","date":"2023-06-06","objectID":"/nast%E6%A6%82%E8%BF%B0/:1:0","tags":["nast,分布式缓存，golang"],"title":"NAST概述","uri":"/nast%E6%A6%82%E8%BF%B0/"},{"categories":["分布式技术"],"content":"3.2 NATS理想的使用场景 NATS理想的使用场景有： 1）寻址、发现 2）命令和控制（控制面板） 3）负载均衡 4）多路可伸缩能力 5）定位透明 6）容错 ","date":"2023-06-06","objectID":"/nast%E6%A6%82%E8%BF%B0/:2:0","tags":["nast,分布式缓存，golang"],"title":"NAST概述","uri":"/nast%E6%A6%82%E8%BF%B0/"},{"categories":["分布式技术"],"content":"3.3 NATS设计哲学 NATS设计哲学认为，高质量的QoS应该在客户端构建，故只建立了请求-应答，不提供： 1）持久化 2）事务处理 3）增强的交付模式 4）企业级队列 四、基于主题的消息传递 从根本上说，NATS 是关于发布和侦听消息的。这两者都在很大程度上依赖于主题。 **什么是主题？**简单来说，主题只是一串字符，它们构成了发布者和订阅者可以用来查找彼此的名称。它有助于将消息范围限定为流或主题。 [外链图片转存失败,源站可能有防盗链机制,建议将图片保存下来直接上传(img-KhsRYivK-1678191670802)(null)] ","date":"2023-06-06","objectID":"/nast%E6%A6%82%E8%BF%B0/:3:0","tags":["nast,分布式缓存，golang"],"title":"NAST概述","uri":"/nast%E6%A6%82%E8%BF%B0/"},{"categories":["分布式技术"],"content":"4.1 使用者名称允许使用的字符 为了跨客户端兼容，我们建议使用 ASCII 字符（将来可能会更改）。 推荐字符：a 到 z，A 到 Z和0到9（名称区分大小写，不能包含空格）。特殊字符：句点。（用于分隔主题中的标记）和 * 和 \u003e（*和\u003e用作通配符）。保留的使用者名称：按照惯例，以a`$`开头的使用者名称保留供系统使用（例如，以$SYS或$JS或$KV等开头的使用者名称） ","date":"2023-06-06","objectID":"/nast%E6%A6%82%E8%BF%B0/:4:0","tags":["nast,分布式缓存，golang"],"title":"NAST概述","uri":"/nast%E6%A6%82%E8%BF%B0/"},{"categories":["分布式技术"],"content":"4.2 主题层次结构 .字符用于创建主题层次结构。例如，世界时钟应用程序可能会定义以下内容以对相关主题进行逻辑分组： time.us time.us.east time.us.east.atlanta time.eu.east time.eu.warsaw ","date":"2023-06-06","objectID":"/nast%E6%A6%82%E8%BF%B0/:5:0","tags":["nast,分布式缓存，golang"],"title":"NAST概述","uri":"/nast%E6%A6%82%E8%BF%B0/"},{"categories":["分布式技术"],"content":"4.2.1 匹配单个子主题 第一个通配符是*，它将匹配单个标记。例如，如果应用程序想要侦听东部时区，他们可以订阅 time.*.east，这将匹配time.us.east 和time.eu.east。`` [外链图片转存失败,源站可能有防盗链机制,建议将图片保存下来直接上传(img-DG3euyWI-1678191670677)(null)] ","date":"2023-06-06","objectID":"/nast%E6%A6%82%E8%BF%B0/:5:1","tags":["nast,分布式缓存，golang"],"title":"NAST概述","uri":"/nast%E6%A6%82%E8%BF%B0/"},{"categories":["分布式技术"],"content":"4.2.2 匹配一个子主题或该子主题下的迭代子主题 第二个通配符是\u003e它将匹配一个或多个标记，并且只能出现在主题的末尾。例如，time.us.\u003e将匹配time.us.east和 time.us.east.atlanta，而 time.us.* 将只匹配 time.us.east，因为它不能匹配多个。 [外链图片转存失败,源站可能有防盗链机制,建议将图片保存下来直接上传(img-ZfhrPWEQ-1678191672332)(null)] ","date":"2023-06-06","objectID":"/nast%E6%A6%82%E8%BF%B0/:5:2","tags":["nast,分布式缓存，golang"],"title":"NAST概述","uri":"/nast%E6%A6%82%E8%BF%B0/"},{"categories":["分布式技术"],"content":"4.2.3 监控和窃听 根据您的安全配置，通配符可以通过创建有时称为窃听的内容来用于监视。在最简单的情况下，您可以为\u003e创建订阅者``。此应用程序将接收在 NATS 群集上发送的所有消息（同样，受安全设置的约束）。 ","date":"2023-06-06","objectID":"/nast%E6%A6%82%E8%BF%B0/:5:3","tags":["nast,分布式缓存，golang"],"title":"NAST概述","uri":"/nast%E6%A6%82%E8%BF%B0/"},{"categories":["分布式技术"],"content":"4.2.4 混合通配符 通配符*可以在同一主题中多次出现。这两种类型也可以使用。例如，*.*.east.\u003e将接收time.us.east.atlanta。 ","date":"2023-06-06","objectID":"/nast%E6%A6%82%E8%BF%B0/:5:4","tags":["nast,分布式缓存，golang"],"title":"NAST概述","uri":"/nast%E6%A6%82%E8%BF%B0/"},{"categories":["分布式技术"],"content":"4.3 主题大小 建议将主题中的最大bit数量保持在最多 16 个bit的合理值。 ","date":"2023-06-06","objectID":"/nast%E6%A6%82%E8%BF%B0/:6:0","tags":["nast,分布式缓存，golang"],"title":"NAST概述","uri":"/nast%E6%A6%82%E8%BF%B0/"},{"categories":["分布式技术"],"content":"4.4 发布-订阅 NATS 为一对多通信实现了发布-订阅消息分发模型。发布者发送有关主题的消息，侦听该主题的任何活动订阅者都会收到该消息。订阅者还可以注册对通配符主题的兴趣，NATS 是一个发布订阅消息传递系统基于主题.侦听某个主题的订阅者会收到有关该主题发布的消息。如果订阅者未主动侦听主题，则不会收到消息。订阅者可以使用通配符标记（如 *and\u003e）来匹配单个标记或匹配主题的尾部。 [外链图片转存失败,源站可能有防盗链机制,建议将图片保存下来直接上传(img-IiqJ55vW-1678191670642)(null)] ","date":"2023-06-06","objectID":"/nast%E6%A6%82%E8%BF%B0/:7:0","tags":["nast,分布式缓存，golang"],"title":"NAST概述","uri":"/nast%E6%A6%82%E8%BF%B0/"},{"categories":["分布式技术"],"content":"4.5 消息 消息由以下部分组成： 一个主题。 字节数组形式的有效负载。 任意数量的header fields字段。 可选的’reply’地址字段。 消息具有最大大小（在服务器配置中使用max_payload 设置）。默认情况下，大小设置为 1 MB，但如果需要，可以增加到 64 MB（但我们建议将最大邮件大小保持在更合理的值，如 8 MB）。 ","date":"2023-06-06","objectID":"/nast%E6%A6%82%E8%BF%B0/:8:0","tags":["nast,分布式缓存，golang"],"title":"NAST概述","uri":"/nast%E6%A6%82%E8%BF%B0/"},{"categories":["分布式技术"],"content":"4.6 请求-回复 请求-回复是现代分布式系统中的常见模式。发送请求，应用程序要么等待具有特定超时的响应，要么异步接收响应。 一般来说，消息系统是以异步的形式工作，也就是说，publisher 往 subject 上发布一条消息后，并不在意 subscriber 的 reply 是什么。如果 publisher 在意 subscriber 的 reply 是什么的话，那么消息系统就应该以同步的形式工作，在具体实现中，是通过两次发布订阅来完成的：当 publisher 发布消息后，它会订阅一个特定的 subject，当 subscriber 处理完消息后，它会把 reply 发布到这个特定的 subject。当然，整个过程对使用者是透明的。 NATS 使用其核心通信机制（发布和订阅）支持请求-回复模式。使用回复主题在给定主题上发布请求。响应者侦听该主题并将响应发送到回复主题。回复主题称为“收件箱”。这些是动态定向回请求者的唯一主题，无论任何一方位于何处。 ","date":"2023-06-06","objectID":"/nast%E6%A6%82%E8%BF%B0/:9:0","tags":["nast,分布式缓存，golang"],"title":"NAST概述","uri":"/nast%E6%A6%82%E8%BF%B0/"},{"categories":["分布式技术"],"content":"4.6.1 NATS 使请求-回复变得简单而强大 多个 NATS 响应程序可以形成动态队列组。因此，无需在组内手动添加或删除订阅者，即可启动或停止分发消息。它是自动完成的。这允许响应者根据需求扩大或缩小规模。 NATS 应用程序“在退出之前耗尽”（在关闭连接之前处理缓冲的消息）。这允许应用程序在不丢弃请求的情况下缩减。 由于 NATS 基于发布-订阅，因此可观测性就像运行另一个应用程序一样简单，该应用程序可以查看请求和响应以测量延迟、监视异常、直接可伸缩性等。 NATS的强大功能甚至允许多个响应，其中第一个响应被利用，系统有效地丢弃额外的响应。这允许复杂的模式具有多个响应器，减少响应延迟和抖动。 无响应者 当请求发送到没有订阅者的主题时，可以方便地立即了解它。对于此用例，NATS 客户端可以选择加入no_responder消息.这需要支持标头的服务器和客户端。启用后，发送到没有订阅者的主题的请求将立即收到没有正文和503状态的回复。 大多数客户端将通过引发或返回错误来表示这种情况。例如： m, err := nc.Request(\"foo\", nil, time.Second); # err == nats.ErrNoResponders ","date":"2023-06-06","objectID":"/nast%E6%A6%82%E8%BF%B0/:9:1","tags":["nast,分布式缓存，golang"],"title":"NAST概述","uri":"/nast%E6%A6%82%E8%BF%B0/"},{"categories":["分布式技术"],"content":"4.7 NATS在微服务中的应用 可以发现 request reply 模式已经有了 RPC 的味道。正是因为 NATS 具备了 RPC 的能力，所以在微服务中采用 NATS 后，系统会更清晰。 传统微服务架构 采用 NATS 的微服务架构 五、组队列 当订阅者注册自己以接收来自发布者的消息时，消息传递的 1：N 扇出模式可确保发布者发送的任何消息都能到达已注册的所有订阅者。NATS 提供了一个名为“队列”的附加功能，该功能允许订阅者将自己注册为队列的一部分。作为队列一部分的订阅者形成“队列组”。 ","date":"2023-06-06","objectID":"/nast%E6%A6%82%E8%BF%B0/:10:0","tags":["nast,分布式缓存，golang"],"title":"NAST概述","uri":"/nast%E6%A6%82%E8%BF%B0/"},{"categories":["分布式技术"],"content":"队列组的工作原理 例如，考虑基于主题名称以 1：N 模式向所有订户传递邮件（甚至对不属于队列组的订户也会发生传递）。如果订阅者基于队列名称注册，它将始终根据主题名称接收其订阅的消息。但是，如果将更多订户添加到同一队列名称，则它们将成为队列组，并且每次队列组收到消息时，只有一个随机选择的队列组订户将使用一条消息。此类分布式队列是 NATS 提供的内置负载平衡功能。 优势 确保应用程序容错 工作负载处理可以纵向扩展或缩减 无需额外配置 队列组由应用程序及其队列订户定义，而不是由服务器配置定义 队列组名称遵循与科目最重要的是，它们区分大小写，不能包含空格。请考虑使用句点分层构建队列组。.某些服务器功能可以使用通配符匹配在他们身上。 队列订阅者是扩展服务的理想选择（订阅者队列是一个集群构成的消费者，集群分担消费消息，集群可随时拓展和缩减）。纵向扩展就像运行另一个应用程序一样简单，缩减是终止应用程序，并发出耗尽正在进行的请求的信号。这种灵活性和无需任何配置更改使 NATS 成为一种出色的服务通信技术，可以与所有平台技术配合使用。 ","date":"2023-06-06","objectID":"/nast%E6%A6%82%E8%BF%B0/:11:0","tags":["nast,分布式缓存，golang"],"title":"NAST概述","uri":"/nast%E6%A6%82%E8%BF%B0/"},{"categories":["分布式技术"],"content":"无响应者 当向服务（请求/回复）发出请求并且 NATS 服务器知道没有可用的服务（因为队列组中当前没有订阅主题的客户端应用程序）时，服务器将向请求客户端发送“无响应者”协议消息，该消息将中断阻止 API 调用。这允许应用程序立即做出反应。这进一步支持大规模构建响应速度快的系统，即使面对应用程序故障和网络分区也是如此。 ","date":"2023-06-06","objectID":"/nast%E6%A6%82%E8%BF%B0/:11:1","tags":["nast,分布式缓存，golang"],"title":"NAST概述","uri":"/nast%E6%A6%82%E8%BF%B0/"},{"categories":["分布式技术"],"content":"作为队列流式传输 跟捷流]还可以通过将保留策略设置为工作队列策略并利用流作为队列拉动消费者]轻松实现处理的水平可扩展性（或使用带有订阅者队列组的显式 ACK 推送使用者）。 [外链图片转存失败,源站可能有防盗链机制,建议将图片保存下来直接上传(img-7t1PYeSm-1678191672299)(null)] ","date":"2023-06-06","objectID":"/nast%E6%A6%82%E8%BF%B0/:12:0","tags":["nast,分布式缓存，golang"],"title":"NAST概述","uri":"/nast%E6%A6%82%E8%BF%B0/"},{"categories":["分布式技术"],"content":"排队地理关联性 连接到全局分布式 NATS 超级群集时，由于如果群集上没有可用于本地处理请求的侦听器，则服务请求消息只会路由到另一个群集（即另一个区域），因此会自动存在服务异地相关性。 ​ ","date":"2023-06-06","objectID":"/nast%E6%A6%82%E8%BF%B0/:12:1","tags":["nast,分布式缓存，golang"],"title":"NAST概述","uri":"/nast%E6%A6%82%E8%BF%B0/"},{"categories":["数据结构"],"content":"学习数据结构时的动手操作。","date":"2023-06-06","objectID":"/c-%E5%AE%9E%E7%8E%B0%E5%8D%95%E9%93%BE%E8%A1%A8%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C/","tags":["C++,链表"],"title":"C++实现单链表的基本操作","uri":"/c-%E5%AE%9E%E7%8E%B0%E5%8D%95%E9%93%BE%E8%A1%A8%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C/"},{"categories":["数据结构"],"content":"单链表节点结构体 struct ListNode { int val; //数据域 ListNode *next; //指针域 ListNode() : val(0), next(nullptr) {} //节点默认构造方法 ListNode(int x) : val(x), next(nullptr) {} //节点初始化val的构造方法 }; 链表遍历输出（方便测试） void Print_LinkNode(ListNode* head) { ListNode* p = head; while(p != nullptr) { p = p -\u003e next; cout \u003c\u003c p -\u003e val; if(p -\u003e next != nullptr) cout \u003c\u003c \" -\u003e \"; } } ","date":"2023-06-06","objectID":"/c-%E5%AE%9E%E7%8E%B0%E5%8D%95%E9%93%BE%E8%A1%A8%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C/:0:1","tags":["C++,链表"],"title":"C++实现单链表的基本操作","uri":"/c-%E5%AE%9E%E7%8E%B0%E5%8D%95%E9%93%BE%E8%A1%A8%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C/"},{"categories":["数据结构"],"content":"一、头结点插入法创建单链表 ListNode* List_Head_insert() { ListNode* head = new ListNode(); int x; cin \u003e\u003e x; while(x != 666) {//输入666结束链表的创建 ListNode* newnode = new ListNode(x); newnode -\u003e next = head -\u003e next; head -\u003e next = newnode; cin \u003e\u003e x; } return head; } 头插法测试代码 #include\u003ciostream\u003e //strin and stdout 的头文件 using namespace std; struct ListNode { int val; ListNode *next; ListNode() : val(0), next(nullptr) {} //节点默认构造方法 ListNode(int x) : val(x), next(nullptr) {} //节点初始化val的构造方法 }; // 头结点插入法 ListNode* List_Head_insert() { ListNode* head = new ListNode(); int x; cin \u003e\u003e x; while(x != 666) { ListNode* newnode = new ListNode(x); newnode -\u003e next = head -\u003e next; head -\u003e next = newnode; cin \u003e\u003e x; } return head; } void Print_LinkNode(ListNode* head) { ListNode* p = head; while(p != nullptr) { p = p -\u003e next; cout \u003c\u003c p -\u003e val; if(p -\u003e next != nullptr) cout \u003c\u003c \" -\u003e \"; } } int main() { ListNode* head = List_Head_insert(); //倒序插入不推荐 Print_LinkNode(head); } 输入 1 2 3 4 5 666 输出 5 -\u003e 4 -\u003e 3 -\u003e 2 -\u003e 1 ","date":"2023-06-06","objectID":"/c-%E5%AE%9E%E7%8E%B0%E5%8D%95%E9%93%BE%E8%A1%A8%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C/:0:2","tags":["C++,链表"],"title":"C++实现单链表的基本操作","uri":"/c-%E5%AE%9E%E7%8E%B0%E5%8D%95%E9%93%BE%E8%A1%A8%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C/"},{"categories":["数据结构"],"content":"二、尾结点插入法创建单链表 ListNode* List_Tail_insert() { ListNode* head = new ListNode(); ListNode* p = head; int x; cin \u003e\u003e x; while(x != 666) { ListNode* newnode = new ListNode(x); p -\u003e next = newnode; p = p -\u003e next; // p = newnode; cin \u003e\u003e x; } return head; } 尾插法测试代码 #include\u003ciostream\u003e //strin and stdout 的头文件 using namespace std; struct ListNode { int val; ListNode *next; ListNode() : val(0), next(nullptr) {} //节点默认构造方法 ListNode(int x) : val(x), next(nullptr) {} //节点初始化val的构造方法 }; // 尾结点插入法 ListNode* List_Tail_insert() { ListNode* head = new ListNode(); ListNode* p = head; int x; cin \u003e\u003e x; while(x != 666) { ListNode* newnode = new ListNode(x); p -\u003e next = newnode; p = p -\u003e next; // p = newnode; cin \u003e\u003e x; } return head; } void Print_LinkNode(ListNode* head) { ListNode* p = head; while(p != nullptr) { p = p -\u003e next; cout \u003c\u003c p -\u003e val; if(p -\u003e next != nullptr) cout \u003c\u003c \" -\u003e \"; } } int main() { ListNode* head = List_Tail_insert();//正序插入 Print_LinkNode(head); } 输入 1 2 3 4 5 666 输出 1 -\u003e 2 -\u003e 3 -\u003e 4 -\u003e 5 ","date":"2023-06-06","objectID":"/c-%E5%AE%9E%E7%8E%B0%E5%8D%95%E9%93%BE%E8%A1%A8%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C/:0:3","tags":["C++,链表"],"title":"C++实现单链表的基本操作","uri":"/c-%E5%AE%9E%E7%8E%B0%E5%8D%95%E9%93%BE%E8%A1%A8%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C/"},{"categories":["数据结构"],"content":"三、按序号查找 //按序号查找(输入有序号一定不要忘记非法输入检验与序号越界检验！！！) ListNode* Selectbyindex(int index,ListNode* head) { if(index \u003c 1)return nullptr; //非法输入检查不能忘！ ListNode* p = head -\u003e next; //尽量不要改变输入的指针域 //有头结点！！要从第一个元素开始head -\u003e next！！！ int i = 1; while(p != nullptr \u0026\u0026 i \u003c index) { //防止index超过链表长度要进行非空检验! p = p -\u003e next; i++; } return p; } 按序号查找测试代码 #include\u003ciostream\u003e //strin and stdout 的头文件 using namespace std; struct ListNode { int val; ListNode *next; ListNode() : val(0), next(nullptr) {} //节点默认构造方法 ListNode(int x) : val(x), next(nullptr) {} //节点初始化val的构造方法 }; // 头结点插入法 ListNode* List_Head_insert() { ListNode* head = new ListNode(); int x; cin \u003e\u003e x; while(x != 666) { ListNode* newnode = new ListNode(x); newnode -\u003e next = head -\u003e next; head -\u003e next = newnode; cin \u003e\u003e x; } return head; } //按序号查找(输入有序号一定不要忘记非法输入与序号越界检验！！！) ListNode* Selectbyindex(int index,ListNode* head) { if(index \u003c 1)return nullptr; //非法输入检查不能忘！ ListNode* p = head -\u003e next; //尽量不要改变输入的指针域 //有头结点！！要从第一个元素开始head -\u003e next！！！ int i = 1; while(p != nullptr \u0026\u0026 i \u003c index) { //防止index超过链表长度要进行非空检验! p = p -\u003e next; i++; } return p; } int main() { int index; ListNode* head = List_Tail_insert();//正序插入 cout \u003c\u003c \"请输入要查询的节点序号\" \u003c\u003cendl; cin \u003e\u003e index; ListNode* res = Selectbyindex(index,head); cout \u003c\u003c res -\u003e val; } 输入 1 5 3 6 7 666 2 输出 5 ","date":"2023-06-06","objectID":"/c-%E5%AE%9E%E7%8E%B0%E5%8D%95%E9%93%BE%E8%A1%A8%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C/:0:4","tags":["C++,链表"],"title":"C++实现单链表的基本操作","uri":"/c-%E5%AE%9E%E7%8E%B0%E5%8D%95%E9%93%BE%E8%A1%A8%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C/"},{"categories":["数据结构"],"content":"四、按值查找 //按值查找 ListNode* Selectbyvalue(int value,ListNode* head) { ListNode* p = head -\u003e next; while(p != nullptr \u0026\u0026 p -\u003e val != value) { //每次都能取出val值，不需要再加中间变量保存每一次的val了！！ p = p -\u003e next; } return p; } 按值查找测试代码 #include\u003ciostream\u003e //strin and stdout 的头文件 using namespace std; struct ListNode { int val; ListNode *next; ListNode() : val(0), next(nullptr) {} //节点默认构造方法 ListNode(int x) : val(x), next(nullptr) {} //节点初始化val的构造方法 }; // 头结点插入法 ListNode* List_Head_insert() { ListNode* head = new ListNode(); int x; cin \u003e\u003e x; while(x != 666) { ListNode* newnode = new ListNode(x); newnode -\u003e next = head -\u003e next; head -\u003e next = newnode; cin \u003e\u003e x; } return head; } //按值查找 ListNode* Selectbyvalue(int value,ListNode* head) { ListNode* p = head -\u003e next; while(p != nullptr \u0026\u0026 p -\u003e val != value) { //每次都能取出val值，不需要再加中间变量保存每一次的val了！！ p = p -\u003e next; } return p; } int main() { int value; ListNode* head = List_Tail_insert();//正序插入 cout \u003c\u003c \"请输入要查询的节点的值\" \u003c\u003cendl; cin \u003e\u003e value; ListNode* res = Selectbyvalue(value,head); cout \u003c\u003c res -\u003e val; } 输入 1 5 3 6 7 666 5 输出 5 ","date":"2023-06-06","objectID":"/c-%E5%AE%9E%E7%8E%B0%E5%8D%95%E9%93%BE%E8%A1%A8%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C/:0:5","tags":["C++,链表"],"title":"C++实现单链表的基本操作","uri":"/c-%E5%AE%9E%E7%8E%B0%E5%8D%95%E9%93%BE%E8%A1%A8%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C/"},{"categories":["数据结构"],"content":"五、按序号插入 //按序号插入 void Insertbyindex(int index,ListNode* head,ListNode* node) { if(index \u003c 1)return; //采用后插法 ListNode* p = head;//若插入第一个序号的位置，为了保证其有前驱节点要从head开始而不是head -\u003e next int i = 0;//相应的i改成0开始而不是1 while(p != nullptr) { if(i == index - 1){ //通常采用的是后插法，需要找到插入位置的前驱节点来后插 //前插法与之相反，但可以将对节点的前插操作转化为后插操作，即找到节点的前节点后插。 node -\u003e next = p -\u003e next; p -\u003e next = node; } //另一种后插实现前插的方法是，将node插入p的后面，再交换node和p的val。 //if(i == index) { //node -\u003e next = p -\u003e next; //p -\u003e next = node; //int temp = node -\u003e val; //node -\u003e val = p -\u003e val; //p -\u003e val = temp; //} p = p -\u003e next; i++; } } 按序号插入测试代码 #include\u003ciostream\u003e //strin and stdout 的头文件 using namespace std; struct ListNode { int val; ListNode *next; ListNode() : val(0), next(nullptr) {} //节点默认构造方法 ListNode(int x) : val(x), next(nullptr) {} //节点初始化val的构造方法 }; // 头结点插入法 ListNode* List_Head_insert() { ListNode* head = new ListNode(); int x; cin \u003e\u003e x; while(x != 666) { ListNode* newnode = new ListNode(x); newnode -\u003e next = head -\u003e next; head -\u003e next = newnode; cin \u003e\u003e x; } return head; } //按序号插入 void Insertbyindex(int index,ListNode* head,ListNode* node) { if(index \u003c 1)return; //采用后插法 ListNode* p = head;//若插入第一个序号的位置，为了保证其有前驱节点要从head开始而不是head -\u003e next int i = 0;//相应的i改成0开始而不是1 while(p != nullptr) { if(i == index - 1){ //通常采用的是后插法，需要找到插入位置的前驱节点来后插 //前插法与之相反，但可以将对节点的前插操作转化为后插操作，即找到节点的前节点后插。 node -\u003e next = p -\u003e next; p -\u003e next = node; } //另一种后插实现前插的方法是，将node插入p的后面，再交换node和p的val。 //if(i == index) { //node -\u003e next = p -\u003e next; //p -\u003e next = node; //int temp = node -\u003e val; //node -\u003e val = p -\u003e val; //p -\u003e val = temp; //} p = p -\u003e next; i++; } } void Print_LinkNode(ListNode* head) { ListNode* p = head; while(p != nullptr) { p = p -\u003e next; cout \u003c\u003c p -\u003e val; if(p -\u003e next != nullptr) cout \u003c\u003c \" -\u003e \"; } } int main() { int index; ListNode* head = List_Tail_insert();//正序插入 cout \u003c\u003c \"请输入要插入的节点序号\" \u003c\u003cendl; cin \u003e\u003e index; ListNode* node = new ListNode(4); Insertbyindex(index,head,node); Print_LinkNode(head); } 输入 1 2 3 5 666 4 输出 1 -\u003e 2 -\u003e 3 -\u003e 4 -\u003e 5 ","date":"2023-06-06","objectID":"/c-%E5%AE%9E%E7%8E%B0%E5%8D%95%E9%93%BE%E8%A1%A8%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C/:0:6","tags":["C++,链表"],"title":"C++实现单链表的基本操作","uri":"/c-%E5%AE%9E%E7%8E%B0%E5%8D%95%E9%93%BE%E8%A1%A8%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C/"},{"categories":["数据结构"],"content":"六、按序号删除 void Deletebyindex(int index,ListNode* head) { if(index \u003c 1)return; //找到其前驱节点 ListNode* p = head;//若删除第一个序号的位置，为了保证其有前驱节点要从head开始而不是head -\u003e next int i = 0;//相应的i改成0开始而不是1 while(p != nullptr) { 找到前驱节点删除改节点 if(i == index - 1) { ListNode* delnode = p -\u003e next; p -\u003e next = delnode -\u003e next; free(delnode);//c++没有垃圾收集机制，要手动释放不用的堆内存，否则容易内存泄漏！ } //另一种方法是找到该节点，将该节点值与后驱节点值替换，删除后驱节点。 //if(i == index) { //ListNode* afternode = p -\u003e next; //p -\u003e next = afternode -\u003e next; //p -\u003e val = afternode -\u003e val; //free(afternode); //} p = p -\u003e next; i++; } } 按序号删除测试代码 #include\u003ciostream\u003e //strin and stdout 的头文件 #include\u003ccstdlib\u003e //free的头文件 using namespace std; struct ListNode { int val; ListNode *next; ListNode() : val(0), next(nullptr) {} //节点默认构造方法 ListNode(int x) : val(x), next(nullptr) {} //节点初始化val的构造方法 }; // 头结点插入法 ListNode* List_Head_insert() { ListNode* head = new ListNode(); int x; cin \u003e\u003e x; while(x != 666) { ListNode* newnode = new ListNode(x); newnode -\u003e next = head -\u003e next; head -\u003e next = newnode; cin \u003e\u003e x; } return head; } void Deletebyindex(int index,ListNode* head) { if(index \u003c 1)return; //找到其前驱节点 ListNode* p = head;//若删除第一个序号的位置，为了保证其有前驱节点要从head开始而不是head -\u003e next int i = 0;//相应的i改成0开始而不是1 while(p != nullptr) { 找到前驱节点删除改节点 if(i == index - 1) { ListNode* delnode = p -\u003e next; p -\u003e next = delnode -\u003e next; free(delnode);//c++没有垃圾收集机制，要手动释放不用的堆内存，否则容易内存泄漏！ } //另一种方法是找到该节点，将该节点值与后驱节点值替换，删除后驱节点。 //if(i == index) { //ListNode* afternode = p -\u003e next; //p -\u003e next = afternode -\u003e next; //p -\u003e val = afternode -\u003e val; //free(afternode); //} p = p -\u003e next; i++; } } void Print_LinkNode(ListNode* head) { ListNode* p = head; while(p != nullptr) { p = p -\u003e next; cout \u003c\u003c p -\u003e val; if(p -\u003e next != nullptr) cout \u003c\u003c \" -\u003e \"; } } int main() { int index; ListNode* head = List_Tail_insert();//正序插入 cout \u003c\u003c \"请输入要删除的节点序号\" \u003c\u003cendl; cin \u003e\u003e index; ListNode* node = new ListNode(4); Deletebyindex(index,head); Print_LinkNode(head); } 输入 1 2 3 4 5 666 3 输出 1 -\u003e 2 -\u003e 4 -\u003e 5 ","date":"2023-06-06","objectID":"/c-%E5%AE%9E%E7%8E%B0%E5%8D%95%E9%93%BE%E8%A1%A8%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C/:0:7","tags":["C++,链表"],"title":"C++实现单链表的基本操作","uri":"/c-%E5%AE%9E%E7%8E%B0%E5%8D%95%E9%93%BE%E8%A1%A8%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C/"},{"categories":["数据结构"],"content":"汇总代码 #include\u003ciostream\u003e //strin and stdout 的头文件 #include\u003ccstdlib\u003e //free的头文件 using namespace std; struct ListNode { int val; ListNode *next; ListNode() : val(0), next(nullptr) {} //节点默认构造方法 ListNode(int x) : val(x), next(nullptr) {} //节点初始化val的构造方法 }; // 头结点插入法 ListNode* List_Head_insert() { ListNode* head = new ListNode(); int x; cin \u003e\u003e x; while(x != 666) { ListNode* newnode = new ListNode(x); newnode -\u003e next = head -\u003e next; head -\u003e next = newnode; cin \u003e\u003e x; } return head; } // 尾结点插入法 ListNode* List_Tail_insert() { ListNode* head = new ListNode(); ListNode* p = head; int x; cin \u003e\u003e x; while(x != 666) { ListNode* newnode = new ListNode(x); p -\u003e next = newnode; p = p -\u003e next; // p = newnode; cin \u003e\u003e x; } return head; } //遍历链表输出 void Print_LinkNode(ListNode* head) { ListNode* p = head; while(p != nullptr) { p = p -\u003e next; cout \u003c\u003c p -\u003e val; if(p -\u003e next != nullptr) cout \u003c\u003c \" -\u003e \"; } } //按序号查找(输入有序号一定不要忘记非法输入与序号越界检验！！！) ListNode* Selectbyindex(int index,ListNode* head) { if(index \u003c 1)return nullptr; //非法输入检查不能忘！ ListNode* p = head -\u003e next; //尽量不要改变输入的指针域 //有头结点！！要从第一个元素开始head -\u003e next！！！ int i = 1; while(p != nullptr \u0026\u0026 i \u003c index) { //防止index超过链表长度要进行非空检验! p = p -\u003e next; i++; } return p; } //按值查找 ListNode* Selectbyvalue(int value,ListNode* head) { ListNode* p = head -\u003e next; while(p != nullptr \u0026\u0026 p -\u003e val != value) { //每次都能取出val值，不需要再加中间变量保存每一次的val了！！ p = p -\u003e next; } return p; } //按序号插入 void Insertbyindex(int index,ListNode* head,ListNode* node) { if(index \u003c 1)return; //采用后插法 ListNode* p = head;//若插入第一个序号的位置，为了保证其有前驱节点要从head开始而不是head -\u003e next int i = 0;//相应的i改成0开始而不是1 while(p != nullptr) { if(i == index - 1){ //通常采用的是后插法，需要找到插入位置的前驱节点来后插 //前插法与之相反，但可以将对节点的前插操作转化为后插操作，即找到节点的前节点后插。 node -\u003e next = p -\u003e next; p -\u003e next = node; } //另一种后插实现前插的方法是，将node插入p的后面，再交换node和p的val。 //if(i == index) { //node -\u003e next = p -\u003e next; //p -\u003e next = node; //int temp = node -\u003e val; //node -\u003e val = p -\u003e val; //p -\u003e val = temp; //} p = p -\u003e next; i++; } } //按序号删除 void Deletebyindex(int index,ListNode* head) { if(index \u003c 1)return; //找到其前驱节点 ListNode* p = head;//若删除第一个序号的位置，为了保证其有前驱节点要从head开始而不是head -\u003e next int i = 0;//相应的i改成0开始而不是1 while(p != nullptr) { 找到前驱节点删除改节点 if(i == index - 1) { ListNode* delnode = p -\u003e next; p -\u003e next = delnode -\u003e next; free(delnode);//c++没有垃圾收集机制，要手动释放不用的堆内存，否则容易内存泄漏！ } //另一种方法是找到该节点，将该节点值与后驱节点值替换，删除后驱节点。 //if(i == index) { //ListNode* afternode = p -\u003e next; //p -\u003e next = afternode -\u003e next; //p -\u003e val = afternode -\u003e val; //free(afternode); //} p = p -\u003e next; i++; } } int main() { int index,value; //ListNode* head = List_Head_insert(); //倒序插入不推荐 //Print_LinkNode(head); ListNode* head = List_Tail_insert();//正序插入 //Print_LinkNode(head); //cout \u003c\u003c \"请输入要查询的节点序号\" \u003c\u003cendl; //cin \u003e\u003e index; //ListNode* res = Selectbyindex(index,head); //cout \u003c\u003c res -\u003e val; //cout \u003c\u003c \"请输入要查询的节点的值\" \u003c\u003cendl; //cin \u003e\u003e value; //ListNode* res = Selectbyvalue(value,head); //cout \u003c\u003c res -\u003e val; //cout \u003c\u003c \"请输入要插入的节点序号\" \u003c\u003cendl; //cin \u003e\u003e index; //ListNode* node = new ListNode(4); //Insertbyindex(index,head,node); //Print_LinkNode(head); cout \u003c\u003c \"请输入要删除的节点序号\" \u003c\u003cendl; cin \u003e\u003e index; ListNode* node = new ListNode(4); Deletebyindex(index,head); Print_LinkNode(head); } ","date":"2023-06-06","objectID":"/c-%E5%AE%9E%E7%8E%B0%E5%8D%95%E9%93%BE%E8%A1%A8%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C/:0:8","tags":["C++,链表"],"title":"C++实现单链表的基本操作","uri":"/c-%E5%AE%9E%E7%8E%B0%E5%8D%95%E9%93%BE%E8%A1%A8%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C/"},{"categories":["计算机网络"],"content":"个人学习笔记","date":"2023-06-06","objectID":"/tcp-ip%E5%8D%8F%E8%AE%AE%E7%AC%AC%E4%B8%80%E7%AB%A0%E7%AC%94%E8%AE%B0/","tags":["TCP/IP协议"],"title":"IP协议第一章笔记","uri":"/tcp-ip%E5%8D%8F%E8%AE%AE%E7%AC%AC%E4%B8%80%E7%AB%A0%E7%AC%94%E8%AE%B0/"},{"categories":["计算机网络"],"content":"一、概述 ","date":"2023-06-06","objectID":"/tcp-ip%E5%8D%8F%E8%AE%AE%E7%AC%AC%E4%B8%80%E7%AB%A0%E7%AC%94%E8%AE%B0/:0:0","tags":["TCP/IP协议"],"title":"IP协议第一章笔记","uri":"/tcp-ip%E5%8D%8F%E8%AE%AE%E7%AC%AC%E4%B8%80%E7%AB%A0%E7%AC%94%E8%AE%B0/"},{"categories":["计算机网络"],"content":"1.1引言 TCP/IP起源于60年代末美国政府资助的一个分组交换网络研究项目，到90年代已发展成为计算机之间最常应用的组网形式。 ","date":"2023-06-06","objectID":"/tcp-ip%E5%8D%8F%E8%AE%AE%E7%AC%AC%E4%B8%80%E7%AB%A0%E7%AC%94%E8%AE%B0/:1:0","tags":["TCP/IP协议"],"title":"IP协议第一章笔记","uri":"/tcp-ip%E5%8D%8F%E8%AE%AE%E7%AC%AC%E4%B8%80%E7%AB%A0%E7%AC%94%E8%AE%B0/"},{"categories":["计算机网络"],"content":"1.2分层 网络协议通常分不同层次进行开发，每一层分别负责不同的通信功能。一个协议族，比如TCP/IP，是一组不同层次上的多个协议的组合。TCP/IP通常被认为是一个四层协议系统。 链路层，有时也称作数据链路层或网络接口层，通常包括操作系统中的设备驱动程序和计算机中对应的网络接口卡。它们一起处理与电缆（或其他任何传输媒介）的物理接口细节。 网络层，有时也称作互联网层，处理分组在网络中的活动，例如分组的选路。在TCP/IP协议族中，网络层协议包括IP协议（网际协议），ICMP协议（Internet互联网控制报文协议），以及IGMP协议（Internet组管理协议）。 运输层主要为两台主机上的应用程序提供端到端的通信。在TCP/IP协议族中，有两个互不相同的传输协议：TCP（传输控制协议）和UDP（用户数据报协议） TCP为两台主机提供高可靠性的数据通信。它所做的工作包括把应用程序交给它的数据分成合适的小块交给下面的网络层，确认接收到的分组，设置发送最后确认分组的超时时钟等。 UDP则为应用层提供一种非常简单的服务。它只是把称作数据报的分组从一台主机发送到另一台主机，但并不保证该数据报能到达另一端。任何必需的可靠性必须由应用层来提供。 应用层负责处理特定的应用程序细节。几乎各种不同的TCP/IP实现都会提供下面这些通用的应用程序： Telnet远程登录。 FTP文件传输协议。 SMTP简单邮件传送协议。 SNMP简单网络管理协议。 我们注意到应用程序通常是一个用户进程，而下三层则一般在（操作系统）内核中执行。尽管这不是必需的，但通常都是这样处理的，例如UNIX操作系统。 顶层与下三层之间还有另一个关键的不同之处。应用层关心的是应用程序的细节，而不是数据在网络中的传输活动。下三层对应用程序一无所知，但它们要处理所有的通信细节。 TCP/IP协议族是一组不同的协议组合在一起构成的协议族。尽管通常称该协议族为TCP/IP，但TCP和IP只是其中的两种协议而已（该协议族的另一个名字是Internet协议族(InternetProtocolSuite)）。 路由器 构造互连网最简单的方法是把两个或多个网络通过路由器进行连接。它是一种特殊的用于网络互连的硬件盒。路由器的好处是为不同类型的物理网络提供连接：以太网、令牌环网、点对点的链接和FDDI（光纤分布式数据接口）等等。 也称作IP路由器（IPRouter），但我们这里使用路由器(Router)这个术语。从历史上说，这些盒子称作网关（gateway），在很多TCP/IP文献中都使用这个术语。现在*网关这个术语只用来表示应用层网关*：一个连接两种不同协议族的进程（例如，TCP/IP和IBM的SNA） 任何具有多个接口的系统，英文都称作是多接口的(multihomed)。一个主机也可以有多个接口，但一般不称作路由器,除非它的功能只是单纯地把分组从一个接口传送到另一个接口。同样，路由器并不一定指那种在互联网中用来转发分组的特殊硬件盒。大多数的TCP/IP实现也允许一个多接口主机来担当路由器的功能，但是主机为此必须进行特殊的配置。在这种情况下，我们既可以称该系统为主机（当它运行某一应用程序时，如FTP或Telnet），也可以称之为路由器（当它把分组从一个网络转发到另一个网络时）。在不同的场合下使用不同的术语。 在TCP/IP协议族中，网络层IP提供的是一种不可靠的服务。也就是说，它只是尽可能快地把分组从源结点送到目的结点，但是并不提供任何可靠性保证。而另一方面，TCP在不可靠的IP层上提供了一个可靠的运输层。为了提供这种可靠的服务，TCP采用了超时重传、发送和接收端到端的确认分组等机制。 网桥 连接网络的另一个途径是使用网桥。网桥是在链路层上对网络进行互连，而路由器则是在网络层上对网络进行互连。网桥使得多个局域网（LAN）组合在一起，这样对上层来说就好像是一个局域网。TCP/IP倾向于使用路由器而不是网桥来连接网络，因此我们将着重介绍路由器。 ","date":"2023-06-06","objectID":"/tcp-ip%E5%8D%8F%E8%AE%AE%E7%AC%AC%E4%B8%80%E7%AB%A0%E7%AC%94%E8%AE%B0/:2:0","tags":["TCP/IP协议"],"title":"IP协议第一章笔记","uri":"/tcp-ip%E5%8D%8F%E8%AE%AE%E7%AC%AC%E4%B8%80%E7%AB%A0%E7%AC%94%E8%AE%B0/"},{"categories":["计算机网络"],"content":"1.3TCP/IP的分层 IP是网络层上的主要协议，同时被TCP和UDP使用。TCP和UDP的每组数据都通过端系统和每个中间路由器中的IP层在互联网中进行传输。在图1-4中，我们给出了一个直接访问IP的应用程序。这是很少见的，但也是可能的（一些较老的选路协议就是以这种方式来实现的。当然新的运输层协议也有可能使用这种方式）。 ICMP是IP协议的附属协议。IP层用它来与其他主机或路由器交换错误报文和其他重要信息。尽管ICMP主要被IP使用，但应用程序也有可能访问它。将分析两个流行的诊断工具，Ping和Traceroute，它们都使用了ICMP。 IGMP是Internet组管理协议。它用来把一个UDP数据报多播到多个主机。广播（把一个UDP数据报发送到某个指定网络上的所有主机）和多播的一般特性。 ARP（地址解析协议）和RARP（逆地址解析协议）是某些网络接口（如以太网和令牌环网）使用的特殊协议，用来转换IP层和网络接口层使用的地址。 ","date":"2023-06-06","objectID":"/tcp-ip%E5%8D%8F%E8%AE%AE%E7%AC%AC%E4%B8%80%E7%AB%A0%E7%AC%94%E8%AE%B0/:3:0","tags":["TCP/IP协议"],"title":"IP协议第一章笔记","uri":"/tcp-ip%E5%8D%8F%E8%AE%AE%E7%AC%AC%E4%B8%80%E7%AB%A0%E7%AC%94%E8%AE%B0/"},{"categories":["计算机网络"],"content":"1.4互联网的地址 互联网每个接口必须有一个唯一的Internet地址（IP地址）。IP地址长32bit。IP地址具有一定的结构，五类不同的互联网地址如图所示。 这些32位的地址通常写成4个十进制的数，其中每个整数对应一个字节。这种表示方法称作”点分十进制表示法“ 多借口主机有多个IP地址，每个接口都对应一个IP地址。 唯一的IP地址由一个叫”互联网络信息中心“的管理机构分配。简称”InterNIC“。其只分配网络号，主机号由系统管理员负责分配。 InterNIC由三部分组成：注册服务，目录和数据库服务，以及信息服务。 一开始只有NIC负责分配IP（nic.ddn.mil）,后来InterNIC成立。目前NIC只处理国防数据网的注册请求，其他由InterNIC负责 三类IP地址： 单播地址（目的端位单个主机） 广播地址（目的端位给定网络上的所有主机）、 多播地址（目的端位同一组内的所有主机） ","date":"2023-06-06","objectID":"/tcp-ip%E5%8D%8F%E8%AE%AE%E7%AC%AC%E4%B8%80%E7%AB%A0%E7%AC%94%E8%AE%B0/:4:0","tags":["TCP/IP协议"],"title":"IP协议第一章笔记","uri":"/tcp-ip%E5%8D%8F%E8%AE%AE%E7%AC%AC%E4%B8%80%E7%AB%A0%E7%AC%94%E8%AE%B0/"},{"categories":["计算机网络"],"content":"1.5DNS域名系统 尽管通过IP地址可以识别主机上的网络接口，进而访问主机，但是人们最喜欢使用的还是主机名。 DNS是一个分布的数据库，由它来提供IP地址和主机名之间的映射信息。 作用：我们用Telnet进行远程登录时，既可以指定一个主机名，也可以指定一个IP地址。 ","date":"2023-06-06","objectID":"/tcp-ip%E5%8D%8F%E8%AE%AE%E7%AC%AC%E4%B8%80%E7%AB%A0%E7%AC%94%E8%AE%B0/:5:0","tags":["TCP/IP协议"],"title":"IP协议第一章笔记","uri":"/tcp-ip%E5%8D%8F%E8%AE%AE%E7%AC%AC%E4%B8%80%E7%AB%A0%E7%AC%94%E8%AE%B0/"},{"categories":["计算机网络"],"content":"1.6封装 用TCP传送数据时，数据被送入协议栈中，然后逐个通过每一层直到被当作一串比特流送入网络。其中每一层对收到的数据都要增加一些首部信息（有时还要增加尾部信息） TCP传给IP的数据单元称作TCP报文段或简称为TCP段（TCPsegment）。IP传给网络接口层的数据单元称作IP数据报(IPdatagram)。通过以太网传输的比特流称作帧(Frame)。 更准确地说，图1-7中IP和网络接口层之间传送的数据单元应该是分组（packet）。分组既可以是一个IP数据报，也可以是IP数据报的一个片（fragment）。 UDP数据与TCP数据基本一致。唯一的不同是UDP传给IP的信息单元称作UDP数据报（UDPdatagram），而且UDP的首部长为8字节。 由于TCP、UDP、ICMP和IGMP都要向IP传送数据，因此IP必须在生成的IP首部中加入某种标识，以表明数据属于哪一层。为此，IP在首部中存入一个长度为8bit的数值，称作协议域。1表示为ICMP协议，2表示为IGMP协议，6表示为TCP协议，17表示为UDP协议。 许多应用程序都可以使用TCP或UDP来传送数据。运输层协议在生成报文首部时要存入一个应用程序的标识符。TCP和UDP都用一个16bit的端口号来表示不同的应用程序。TCP和UDP把源端口号和目的端口号分别存入报文首部中。 网络接口分别要发送和接收IP、ARP和RARP数据，因此也必须在以太网的帧首部中加入应用程序某种形式的标识，以指明生成数据的网络层协议。为此，以太网的帧首部也有一个16bit的帧类型域。 ","date":"2023-06-06","objectID":"/tcp-ip%E5%8D%8F%E8%AE%AE%E7%AC%AC%E4%B8%80%E7%AB%A0%E7%AC%94%E8%AE%B0/:6:0","tags":["TCP/IP协议"],"title":"IP协议第一章笔记","uri":"/tcp-ip%E5%8D%8F%E8%AE%AE%E7%AC%AC%E4%B8%80%E7%AB%A0%E7%AC%94%E8%AE%B0/"},{"categories":["计算机网络"],"content":"1.7分用 分用是根据1.6封装规则进行解析，协议确实是通过目的端口号、源IP地址和源端口号进行解包的。 当目的主机收到一个以太网数据帧时，数据就开始从协议栈中由底向上升，同时去掉各层协议加上的报文首部。每层协议盒都要去检查报文首部中的协议标识，以确定接收数据的上层协议。这个过程称作分用。 协议ICMP和IGMP定位一直是一件很棘手的事情。在图1-4中，把它们与IP放在同一层上，那是因为事实上它们是IP的附属协议。但是在这里，我们又把它们放在IP层的上面，这是因为ICMP和IGMP报文都被封装在IP数据报中。对于ARP和RARP，我们也遇到类似的难题。在这里把它们放在以太网设备驱动程序的上方，这是因为它们和IP数据报一样，都有各自的以太网数据帧类型。但在图2-4中，我们又把ARP作为以太网设备驱动程序的一部分，放在IP层的下面。 ","date":"2023-06-06","objectID":"/tcp-ip%E5%8D%8F%E8%AE%AE%E7%AC%AC%E4%B8%80%E7%AB%A0%E7%AC%94%E8%AE%B0/:7:0","tags":["TCP/IP协议"],"title":"IP协议第一章笔记","uri":"/tcp-ip%E5%8D%8F%E8%AE%AE%E7%AC%AC%E4%B8%80%E7%AB%A0%E7%AC%94%E8%AE%B0/"},{"categories":["计算机网络"],"content":"1.8C/S模型 大部分网络应用程序使用C/S架构，C/S分为两种类型。 重复型 1.等待一个客户请求的到来。 2.处理客户请求。 3.发送响应给发送请求的客户 4.返回第一步 重复型服务器主要问题在第二步，这时不能位其他客户机提供服务。 并发型 1.等待一个客户请求的到来。 2.启动一个新的服务器来处理这个客户的请求。在这期间可能生成一个新的进程、任务或线程、协程，并依赖底层操作系统的支持。这个步骤如何进行取决于操作系统。生成的新服务器对客户的全部请求进行处理。处理结束后，终止这个新服务器。 3.返回第一步 并发服务器优点是对每个用户请求单独生成一个服务器处理。如果操作系统允许多任务（基本都允许），那么久可以同时位多个客户服务。 一般来说TCP服务是并发的，UDP服务是重复的。（有例外） 为什么只对服务器进行分类而不是对用户分类？ 因为对于一个用户来说，它通常并不能够辨别自己是与一个重复型还是并发型服务器对话。 ","date":"2023-06-06","objectID":"/tcp-ip%E5%8D%8F%E8%AE%AE%E7%AC%AC%E4%B8%80%E7%AB%A0%E7%AC%94%E8%AE%B0/:8:0","tags":["TCP/IP协议"],"title":"IP协议第一章笔记","uri":"/tcp-ip%E5%8D%8F%E8%AE%AE%E7%AC%AC%E4%B8%80%E7%AB%A0%E7%AC%94%E8%AE%B0/"},{"categories":["计算机网络"],"content":"1.9端口号 服务器一般都是通过知名端口号来识别的。例如，对于每个TCP/IP实现来说，FTP服务器的TCP端口号都是21，每个Telnet服务器的TCP端口号都是23，每个TFTP(简单文件传送协议)服务器的UDP端口号都是69。任何TCP/IP实现所提供的服务都用知名的1～1023之间的端口号。这些知名端口号由Internet号分配机构（InternetAssignedNumbersAuthority,IANA）来管理。 客户端通常对它所使用的端口号并不关心，只需保证该端口号在本机上是唯一的就可以了。客户端口号又称作临时端口号（即存在时间很短暂）。这是因为它通常只是在用户运行该客户程序时才存在，而服务器则只要主机开着的，其服务就运行。 大多数TCP/IP实现给临时端口分配1024～5000之间的端口号。大于5000的端口号是为其下载他服务器预留的（Internet上并不常用的服务)。我们可以在后面看见许多这样的给临时端口分配端口号的例子。 端口号可以分为三个范围：“已知端口”、“注册端口”以及“动态和/或专用端口”。 “已知端口”是从0到1023的端口。 “注册端口”是从1024到49151的端口。 “动态和/或专用端口”是从49152到65535的端口。理论上，不应为服务分配这些端口。 保留端口号 Unix系统有保留端口号的概念。只有具有超级用户特权的进程才允许给它自己分配一个保留端口号。这些端口号介于1～1023间，一些应用程序（如有名的Rlogin，26.2节）将它作为客户与服务器之间身份认证的一部分。 ","date":"2023-06-06","objectID":"/tcp-ip%E5%8D%8F%E8%AE%AE%E7%AC%AC%E4%B8%80%E7%AB%A0%E7%AC%94%E8%AE%B0/:9:0","tags":["TCP/IP协议"],"title":"IP协议第一章笔记","uri":"/tcp-ip%E5%8D%8F%E8%AE%AE%E7%AC%AC%E4%B8%80%E7%AB%A0%E7%AC%94%E8%AE%B0/"},{"categories":["计算机网络"],"content":"1.10标准化过程 有四个小组在负责Internet技术的规范与研究 Internet协会（ISOC）：是一个推动、支持和促进Internet不断增长和发展的专业组织，它把Internet作为全球研究通信的基础设施。 Internet体系结构委员会（IAB）：是一个技术监督和协调的机构。它由国际上来自不同专业的15个志愿者组成，其职能是负责Internet标准的最后编辑和技术审核。IAB隶属于ISOC。 Internet工程专门小组(IETF)是一个面向近期标准的组织，分为9个领域（应用、寻径和寻址、安全等）。IETF开发成为Internet标准的规范。 Internet研究专门小组（IRIF）：主要对长远的项目进行研究。是为了帮助IETF主席成立的。 IRIF和IETF都属于IAB。 ","date":"2023-06-06","objectID":"/tcp-ip%E5%8D%8F%E8%AE%AE%E7%AC%AC%E4%B8%80%E7%AB%A0%E7%AC%94%E8%AE%B0/:10:0","tags":["TCP/IP协议"],"title":"IP协议第一章笔记","uri":"/tcp-ip%E5%8D%8F%E8%AE%AE%E7%AC%AC%E4%B8%80%E7%AB%A0%E7%AC%94%E8%AE%B0/"},{"categories":["计算机网络"],"content":"1.11RFC 所有关于Internet的正式标准都以RFC（RequestforComment）文档出版。另外，大量的RFC并不是正式的标准，出版的目的只是为了提供信息。RFC的篇幅从1页到200页不等。每一项都用一个数字来标识，如RFC1122，数字越大说明RFC的内容越新。 有四种重要的RFC文档： 复制RFC：列出了所有Internet协议里使用到的数字和常数。所有端口号都有。 Internet正式协议标准：描述了各种Internet协议的标准化现状。每种协议都处于下面几种标准化状态之一：标准、草案标准、提议标准、实验标准、信息标准和历史标准。 主机需求RFC：1122针对链路层、网络层、运输层。1123针对应用层。它们列出了协议中关于“必须”、“应该”、“可以”、“不应该”或者“不能”等特性及其实现细节。 路由器需求RFC：与主机RFC需求类似，只单独描述了路由器的需求。 ","date":"2023-06-06","objectID":"/tcp-ip%E5%8D%8F%E8%AE%AE%E7%AC%AC%E4%B8%80%E7%AB%A0%E7%AC%94%E8%AE%B0/:11:0","tags":["TCP/IP协议"],"title":"IP协议第一章笔记","uri":"/tcp-ip%E5%8D%8F%E8%AE%AE%E7%AC%AC%E4%B8%80%E7%AB%A0%E7%AC%94%E8%AE%B0/"},{"categories":["计算机网络"],"content":"1.12标准的简单服务 有一些标准的简单服务几乎每种实现都要提供。 标准的简单服务以及其他标准的TCP/IP服务（如Telnet、FTP、SMTP等）的端口号时，我们发现它们都是奇数。这是有历史原因的，因为这些端口号都是从NCP端口号派生出来的（NCP，即网络控制协议，是ARPANET的运输层协议，是TCP的前身）。NCP是单工的，不是全双工的，因此每个应用程序需要两个连接，需预留一对奇数和偶数端口号。当TCP和UDP成为标准的运输层协议时，每个应用程序只需要一个端口号，因此就使用了NCP中的奇数。 ","date":"2023-06-06","objectID":"/tcp-ip%E5%8D%8F%E8%AE%AE%E7%AC%AC%E4%B8%80%E7%AB%A0%E7%AC%94%E8%AE%B0/:12:0","tags":["TCP/IP协议"],"title":"IP协议第一章笔记","uri":"/tcp-ip%E5%8D%8F%E8%AE%AE%E7%AC%AC%E4%B8%80%E7%AB%A0%E7%AC%94%E8%AE%B0/"},{"categories":["计算机网络"],"content":"1.13互联网 世界范围内的互联网—Internet，internet这个词第一个字母是否大写决定了它具有不同的含义。 internet意思是用一个共同的协议族把多个网络连接在一起。而Internet指的是世界范围内通过TCP/IP互相通信的所有主机集合（超过100万台）。Internet是一个internet，但internet不等于Internet。 ","date":"2023-06-06","objectID":"/tcp-ip%E5%8D%8F%E8%AE%AE%E7%AC%AC%E4%B8%80%E7%AB%A0%E7%AC%94%E8%AE%B0/:13:0","tags":["TCP/IP协议"],"title":"IP协议第一章笔记","uri":"/tcp-ip%E5%8D%8F%E8%AE%AE%E7%AC%AC%E4%B8%80%E7%AB%A0%E7%AC%94%E8%AE%B0/"},{"categories":["计算机网络"],"content":"1.14实现 既成事实标准的TCP/IP软件实现来自于位于伯克利的加利福尼亚大学的计算机系统研究小组。从历史上看，软件是随同4.xBSD系统（BerkeleySoftwareDistribution）的网络版一起发布的。它的源代码是许多其他实现的基础。图1-10列举了各种BSD版本发布的时间，并标注了重要的TCP/IP特性。列在左边的BSD网络版，其所有的网络源代码可以公开得到：包括协议本身以及许多应用程序和工具（如Telnet和FTP）。 ","date":"2023-06-06","objectID":"/tcp-ip%E5%8D%8F%E8%AE%AE%E7%AC%AC%E4%B8%80%E7%AB%A0%E7%AC%94%E8%AE%B0/:14:0","tags":["TCP/IP协议"],"title":"IP协议第一章笔记","uri":"/tcp-ip%E5%8D%8F%E8%AE%AE%E7%AC%AC%E4%B8%80%E7%AB%A0%E7%AC%94%E8%AE%B0/"},{"categories":["计算机网络"],"content":"1.15 应用编程接口 使用TCP/IP协议的应用程序通常采用两种应用编程：socket和TLI。前者有时称作“Berkeley socket”，表明它是从伯克利版发展而来的。后者起初是由 AT \u0026 T开发的，有时称作 XTI（X/Open运输层接口），以承认X/Open这个自己定义标准的国际计算机生产商所做的工作。 XTI实际上是TLI的一个超集。 ","date":"2023-06-06","objectID":"/tcp-ip%E5%8D%8F%E8%AE%AE%E7%AC%AC%E4%B8%80%E7%AB%A0%E7%AC%94%E8%AE%B0/:15:0","tags":["TCP/IP协议"],"title":"IP协议第一章笔记","uri":"/tcp-ip%E5%8D%8F%E8%AE%AE%E7%AC%AC%E4%B8%80%E7%AB%A0%E7%AC%94%E8%AE%B0/"},{"categories":["计算机网络"],"content":"1.16 测试网络 图1 - 11是本书中所有的例子运行的测试网络。 ","date":"2023-06-06","objectID":"/tcp-ip%E5%8D%8F%E8%AE%AE%E7%AC%AC%E4%B8%80%E7%AB%A0%E7%AC%94%E8%AE%B0/:16:0","tags":["TCP/IP协议"],"title":"IP协议第一章笔记","uri":"/tcp-ip%E5%8D%8F%E8%AE%AE%E7%AC%AC%E4%B8%80%E7%AB%A0%E7%AC%94%E8%AE%B0/"},{"categories":["计算机网络"],"content":"1.17 小结 TCP / IP协议族分为四层：链路层、网络层、运输层和应用层，每一层各有不同的责任。 在TCP / IP中，网络层和运输层之间的区别是最为关键的：网络层（ IP）提供点到点的服务，而运输层（TCP和UDP）提供端到端的服务。一个互联网是网络的网络。构造互联网的共同基石是路由器，它们在 IP层把网络连在一起。第一个字母大写的Internet是指分布在世界各地的大型互联网，其中包括 1万多个网络和超过100万台主机。 在一个互联网上，每个接口都用 IP地址来标识，尽管用户习惯使用主机名而不是 IP地址。域名系统为主机名和 IP地址之间提供动态的映射。端口号用来标识互相通信的应用程序。服务器使用知名端口号，而客户使用临时设定的端口号。 ","date":"2023-06-06","objectID":"/tcp-ip%E5%8D%8F%E8%AE%AE%E7%AC%AC%E4%B8%80%E7%AB%A0%E7%AC%94%E8%AE%B0/:17:0","tags":["TCP/IP协议"],"title":"IP协议第一章笔记","uri":"/tcp-ip%E5%8D%8F%E8%AE%AE%E7%AC%AC%E4%B8%80%E7%AB%A0%E7%AC%94%E8%AE%B0/"},{"categories":["容器"],"content":"运维之路的第一步。","date":"2023-06-06","objectID":"/docker%E5%85%A5%E9%97%A8%E5%8F%8A%E5%AE%89%E8%A3%85%E5%8F%8A%E5%9F%BA%E6%9C%AC%E5%91%BD%E4%BB%A4/","tags":["docker,运维,容器"],"title":"Docker入门及安装及基本命令","uri":"/docker%E5%85%A5%E9%97%A8%E5%8F%8A%E5%AE%89%E8%A3%85%E5%8F%8A%E5%9F%BA%E6%9C%AC%E5%91%BD%E4%BB%A4/"},{"categories":["容器"],"content":"docker简介 Docker 是一个用于开发，交付和运行应用程序的开放平台。Docker 使您能够将应用程序与基础架构分开，从而可以快速交付软件。借助 Docker，您可以与管理应用程序相同的方式来管理基础架构。通过利用 Docker 的方法来快速交付，测试和部署代码，您可以大大减少编写代码和在生产环境中运行代码之间的延迟。 Docker 包括三个基本概念: 镜像（Image）：Docker 镜像（Image），就相当于是一个 root 文件系统。比如官方镜像 ubuntu:16.04 就包含了完整的一套 Ubuntu16.04 最小系统的 root 文件系统。 容器（Container）：镜像（Image）和容器（Container）的关系，就像是面向对象程序设计中的类和实例一样，镜像是静态的定义，容器是镜像运行时的实体。容器可以被创建、启动、停止、删除、暂停等。 仓库（Repository）：仓库可看成一个代码控制中心，用来保存镜像。 Docker 使用客户端-服务器 (C/S) 架构模式，使用远程API来管理和创建Docker容器。 Docker 容器通过 Docker 镜像来创建。 容器与镜像的关系类似于面向对象编程中的对象与类。 安装docker Docker 并非是一个通用的容器工具，它依赖于已存在并运行的 Linux 内核环境。 Docker 实质上是在已经运行的 Linux 下制造了一个隔离的文件环境，因此它执行的效率几乎等同于所部署的 Linux 主机。 因此，Docker 必须部署在 Linux 内核的系统上。如果其他系统想部署 Docker 就必须安装一个虚拟 Linux 环境。 如果是Windows或者macOS下安装docker就需要先安装linux虚拟机再安装docker ","date":"2023-06-06","objectID":"/docker%E5%85%A5%E9%97%A8%E5%8F%8A%E5%AE%89%E8%A3%85%E5%8F%8A%E5%9F%BA%E6%9C%AC%E5%91%BD%E4%BB%A4/:0:0","tags":["docker,运维,容器"],"title":"Docker入门及安装及基本命令","uri":"/docker%E5%85%A5%E9%97%A8%E5%8F%8A%E5%AE%89%E8%A3%85%E5%8F%8A%E5%9F%BA%E6%9C%AC%E5%91%BD%E4%BB%A4/"},{"categories":["容器"],"content":"centos7安装docker 如果已安装docker，请卸载它们以及相关的依赖项 sudo yum remove docker \\ docker-client \\ docker-client-latest \\ docker-common \\ docker-latest \\ docker-latest-logrotate \\ docker-logrotate \\ docker-engine ","date":"2023-06-06","objectID":"/docker%E5%85%A5%E9%97%A8%E5%8F%8A%E5%AE%89%E8%A3%85%E5%8F%8A%E5%9F%BA%E6%9C%AC%E5%91%BD%E4%BB%A4/:1:0","tags":["docker,运维,容器"],"title":"Docker入门及安装及基本命令","uri":"/docker%E5%85%A5%E9%97%A8%E5%8F%8A%E5%AE%89%E8%A3%85%E5%8F%8A%E5%9F%BA%E6%9C%AC%E5%91%BD%E4%BB%A4/"},{"categories":["容器"],"content":"设置仓库 安装所需的软件包。yum-utils 提供了 yum-config-manager ，并且 device mapper 存储驱动程序需要 device-mapper-persistent-data 和 lvm2。 sudo yum install -y yum-utils \\ device-mapper-persistent-data \\ lvm2 设置阿里云仓库 sudo yum-config-manager \\ --add-repo \\ http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo ","date":"2023-06-06","objectID":"/docker%E5%85%A5%E9%97%A8%E5%8F%8A%E5%AE%89%E8%A3%85%E5%8F%8A%E5%9F%BA%E6%9C%AC%E5%91%BD%E4%BB%A4/:1:1","tags":["docker,运维,容器"],"title":"Docker入门及安装及基本命令","uri":"/docker%E5%85%A5%E9%97%A8%E5%8F%8A%E5%AE%89%E8%A3%85%E5%8F%8A%E5%9F%BA%E6%9C%AC%E5%91%BD%E4%BB%A4/"},{"categories":["容器"],"content":"安装 Docker Engine-Community sudo yum install docker-ce docker-ce-cli containerd.io docker-compose-plugin 要安装特定版本的 Docker Engine-Community，请在存储库中列出可用版本，然后选择并安装： 1、列出并排序您存储库中可用的版本。此示例按版本号（从高到低）对结果进行排序。 yum list docker-ce --showduplicates | sort -r 输出 docker-ce.x86_64 3:18.09.1-3.el7 docker-ce-stable docker-ce.x86_64 3:18.09.0-3.el7 docker-ce-stable docker-ce.x86_64 18.06.1.ce-3.el7 docker-ce-stable docker-ce.x86_64 18.06.0.ce-3.el7 docker-ce-stable 2、通过其完整的软件包名称安装特定版本，该软件包名称是软件包名称（docker-ce）加上版本字符串（第二列），从第一个冒号（:）一直到第一个连字符，并用连字符（-）分隔。例如：docker-ce-18.09.1。 $ sudo yum install docker-ce-\u003cVERSION_STRING\u003e docker-ce-cli-\u003cVERSION_STRING\u003e containerd.io 卸载docker 删除安装包： yum remove docker-ce 删除镜像、容器、配置文件等内容： rm -rf /var/lib/docker root下执行命令 docker版本号/信息 docker version docker info 启动docker systemctl start docker 关闭docker systemctl stop docker 重启docker systemctl restart docker docker自启动 systemctl enable docker 查看docker 运行状态 systemctl status docker 搜索镜像 docker search 镜像名 下载镜像（默认下载最新版本） docker pull 镜像名 docker pull 镜像名:tag 显示镜像 docker images 运行镜像 docker run 镜像名 docker run 镜像名:Tag 启动容器并配置端口映射 因为容器是隔离的，默认情况下，我们是无法通过宿主机（安装docker的服务器）端口来直接访问容器的 ,因为docker容器自己开辟空间的端口与宿主机端口没有联系，需要配置端口映射 -p 宿主机端口:容器端口 docker run -d -p 16379:6379 --name redis001 redis 删除容器 docker rm -f 容器名|容器ID 显示运行中的容器 docker ps 显示所有容器 docker ps -a 删除没有被容器使用的镜像 docker rmi -f 镜像名/镜像ID 强制删除镜像 docker image rm 镜像名称/镜像ID 重命名容器 docker rename 容器ID/容器名 新容器名 进入容器 docker exec -it 容器名/容器ID /bin/bash #进入 前面的 redis001容器 docker exec -it redis001 /bin/bash 退出容器 exit # 优雅退出 --- 无论是否添加-d 参数 执行此命令容器都不会被关闭 Ctrl + p + q 停止容器 docker stop 容器ID/容器名 重启容器 docker restart 容器ID/容器名 kill容器 docker kill 容器ID/容器名 容器日志 docker logs -f --tail=要查看末尾多少行 默认all 容器ID 数据挂载：将容器内的数据与外部宿主机文件绑定起来，类似一个双持久化，当容器删除时，宿主机文件数据目录仍在，下次启动容器只要将数据目录指向宿主机数据所在位置即可恢复！一个容器可以同时挂载多个文件 -v 宿主机文件存储位置:容器内文件位置 ","date":"2023-06-06","objectID":"/docker%E5%85%A5%E9%97%A8%E5%8F%8A%E5%AE%89%E8%A3%85%E5%8F%8A%E5%9F%BA%E6%9C%AC%E5%91%BD%E4%BB%A4/:1:2","tags":["docker,运维,容器"],"title":"Docker入门及安装及基本命令","uri":"/docker%E5%85%A5%E9%97%A8%E5%8F%8A%E5%AE%89%E8%A3%85%E5%8F%8A%E5%9F%BA%E6%9C%AC%E5%91%BD%E4%BB%A4/"},{"categories":["分布式技术"],"content":"在字节跳动青训营里对hdfs架构进一步的学习。","date":"2023-06-06","objectID":"/hdfs%E9%AB%98%E5%8F%AF%E7%94%A8%E4%B8%8E%E9%AB%98%E6%8B%93%E5%B1%95%E6%9C%BA%E5%88%B6%E5%88%86%E6%9E%90/","tags":["hdfs,大数据"],"title":"Hdfs高可用与高拓展机制分析","uri":"/hdfs%E9%AB%98%E5%8F%AF%E7%94%A8%E4%B8%8E%E9%AB%98%E6%8B%93%E5%B1%95%E6%9C%BA%E5%88%B6%E5%88%86%E6%9E%90/"},{"categories":["分布式技术"],"content":"一、元数据服务高可用 ","date":"2023-06-06","objectID":"/hdfs%E9%AB%98%E5%8F%AF%E7%94%A8%E4%B8%8E%E9%AB%98%E6%8B%93%E5%B1%95%E6%9C%BA%E5%88%B6%E5%88%86%E6%9E%90/:0:0","tags":["hdfs,大数据"],"title":"Hdfs高可用与高拓展机制分析","uri":"/hdfs%E9%AB%98%E5%8F%AF%E7%94%A8%E4%B8%8E%E9%AB%98%E6%8B%93%E5%B1%95%E6%9C%BA%E5%88%B6%E5%88%86%E6%9E%90/"},{"categories":["分布式技术"],"content":"1.1高可用的需求 故障类型： 软件故障 硬件故障 人为故障 灾难：数据中心级别不可用 故障不可避免，灾难有时发生 如果HDFS不可用，业务停止的损失极大，所以高可用就至关重要 ","date":"2023-06-06","objectID":"/hdfs%E9%AB%98%E5%8F%AF%E7%94%A8%E4%B8%8E%E9%AB%98%E6%8B%93%E5%B1%95%E6%9C%BA%E5%88%B6%E5%88%86%E6%9E%90/:1:0","tags":["hdfs,大数据"],"title":"Hdfs高可用与高拓展机制分析","uri":"/hdfs%E9%AB%98%E5%8F%AF%E7%94%A8%E4%B8%8E%E9%AB%98%E6%8B%93%E5%B1%95%E6%9C%BA%E5%88%B6%E5%88%86%E6%9E%90/"},{"categories":["分布式技术"],"content":"1.2高可用形式 服务高可用有 热备份：有另一个备份节点，发生故障时可直接切换 冷备份：将关键性文件切换到另外位置，发生故障时通过备份数据进行恢复。 故障恢复操作： 人工切换 自动切换 人工的反应、决策时间都更长，高可用需要让系统自动决策。 HDFS的设计中，采用了中心化的元数据管理节点NameNode。NameNode容易成为故障中的单点(single point of failure)。 ","date":"2023-06-06","objectID":"/hdfs%E9%AB%98%E5%8F%AF%E7%94%A8%E4%B8%8E%E9%AB%98%E6%8B%93%E5%B1%95%E6%9C%BA%E5%88%B6%E5%88%86%E6%9E%90/:2:0","tags":["hdfs,大数据"],"title":"Hdfs高可用与高拓展机制分析","uri":"/hdfs%E9%AB%98%E5%8F%AF%E7%94%A8%E4%B8%8E%E9%AB%98%E6%8B%93%E5%B1%95%E6%9C%BA%E5%88%B6%E5%88%86%E6%9E%90/"},{"categories":["分布式技术"],"content":"1.3HDFS NameNode高可用架构 组件介绍： ActiveNamenode:主节点，提供服务，生产日志 StandbyNamenode:备节点，消费日志 ZooKeeper:为自动选主提供统一协调服务 BookKeeper:提供日志存储服务 ZKFC: NameNode探活、触发主备切换 HA Client:提供了自动切换的客户端 edit log:操作的日志 ","date":"2023-06-06","objectID":"/hdfs%E9%AB%98%E5%8F%AF%E7%94%A8%E4%B8%8E%E9%AB%98%E6%8B%93%E5%B1%95%E6%9C%BA%E5%88%B6%E5%88%86%E6%9E%90/:3:0","tags":["hdfs,大数据"],"title":"Hdfs高可用与高拓展机制分析","uri":"/hdfs%E9%AB%98%E5%8F%AF%E7%94%A8%E4%B8%8E%E9%AB%98%E6%8B%93%E5%B1%95%E6%9C%BA%E5%88%B6%E5%88%86%E6%9E%90/"},{"categories":["分布式技术"],"content":"1.4理论基础：状态机复制和日志 状态机复制是实现容错的常用方法 组件：状态机以及其副本、变更日志、共识协议 ","date":"2023-06-06","objectID":"/hdfs%E9%AB%98%E5%8F%AF%E7%94%A8%E4%B8%8E%E9%AB%98%E6%8B%93%E5%B1%95%E6%9C%BA%E5%88%B6%E5%88%86%E6%9E%90/:4:0","tags":["hdfs,大数据"],"title":"Hdfs高可用与高拓展机制分析","uri":"/hdfs%E9%AB%98%E5%8F%AF%E7%94%A8%E4%B8%8E%E9%AB%98%E6%8B%93%E5%B1%95%E6%9C%BA%E5%88%B6%E5%88%86%E6%9E%90/"},{"categories":["分布式技术"],"content":"1.5NameNode状态持久化 FSImage：是保存文件目录树的日志 EditLog：是保存对文件操作的日志 checkpoint机制会合并两者生成一个新的目录树日志 ","date":"2023-06-06","objectID":"/hdfs%E9%AB%98%E5%8F%AF%E7%94%A8%E4%B8%8E%E9%AB%98%E6%8B%93%E5%B1%95%E6%9C%BA%E5%88%B6%E5%88%86%E6%9E%90/:5:0","tags":["hdfs,大数据"],"title":"Hdfs高可用与高拓展机制分析","uri":"/hdfs%E9%AB%98%E5%8F%AF%E7%94%A8%E4%B8%8E%E9%AB%98%E6%8B%93%E5%B1%95%E6%9C%BA%E5%88%B6%E5%88%86%E6%9E%90/"},{"categories":["分布式技术"],"content":"1.6NameNode操作日志的生产消费 Active生产，Standby (可能有多个)消费 ","date":"2023-06-06","objectID":"/hdfs%E9%AB%98%E5%8F%AF%E7%94%A8%E4%B8%8E%E9%AB%98%E6%8B%93%E5%B1%95%E6%9C%BA%E5%88%B6%E5%88%86%E6%9E%90/:6:0","tags":["hdfs,大数据"],"title":"Hdfs高可用与高拓展机制分析","uri":"/hdfs%E9%AB%98%E5%8F%AF%E7%94%A8%E4%B8%8E%E9%AB%98%E6%8B%93%E5%B1%95%E6%9C%BA%E5%88%B6%E5%88%86%E6%9E%90/"},{"categories":["分布式技术"],"content":"1.7NameNode块维护 区别 Active即接收，也发起变更· Standby只接收，不发起变更 ","date":"2023-06-06","objectID":"/hdfs%E9%AB%98%E5%8F%AF%E7%94%A8%E4%B8%8E%E9%AB%98%E6%8B%93%E5%B1%95%E6%9C%BA%E5%88%B6%E5%88%86%E6%9E%90/:7:0","tags":["hdfs,大数据"],"title":"Hdfs高可用与高拓展机制分析","uri":"/hdfs%E9%AB%98%E5%8F%AF%E7%94%A8%E4%B8%8E%E9%AB%98%E6%8B%93%E5%B1%95%E6%9C%BA%E5%88%B6%E5%88%86%E6%9E%90/"},{"categories":["分布式技术"],"content":"1.8自动主备切换–server ZKFailoverController：作为外部组件，驱动HDFS NameNode的主备切换 HA核心机制:Watch ","date":"2023-06-06","objectID":"/hdfs%E9%AB%98%E5%8F%AF%E7%94%A8%E4%B8%8E%E9%AB%98%E6%8B%93%E5%B1%95%E6%9C%BA%E5%88%B6%E5%88%86%E6%9E%90/:8:0","tags":["hdfs,大数据"],"title":"Hdfs高可用与高拓展机制分析","uri":"/hdfs%E9%AB%98%E5%8F%AF%E7%94%A8%E4%B8%8E%E9%AB%98%E6%8B%93%E5%B1%95%E6%9C%BA%E5%88%B6%E5%88%86%E6%9E%90/"},{"categories":["分布式技术"],"content":"1.9自动主备切换–client 核心机制-standbyexception client自动处理 ","date":"2023-06-06","objectID":"/hdfs%E9%AB%98%E5%8F%AF%E7%94%A8%E4%B8%8E%E9%AB%98%E6%8B%93%E5%B1%95%E6%9C%BA%E5%88%B6%E5%88%86%E6%9E%90/:9:0","tags":["hdfs,大数据"],"title":"Hdfs高可用与高拓展机制分析","uri":"/hdfs%E9%AB%98%E5%8F%AF%E7%94%A8%E4%B8%8E%E9%AB%98%E6%8B%93%E5%B1%95%E6%9C%BA%E5%88%B6%E5%88%86%E6%9E%90/"},{"categories":["分布式技术"],"content":"1.10BookKeeper架构 ","date":"2023-06-06","objectID":"/hdfs%E9%AB%98%E5%8F%AF%E7%94%A8%E4%B8%8E%E9%AB%98%E6%8B%93%E5%B1%95%E6%9C%BA%E5%88%B6%E5%88%86%E6%9E%90/:10:0","tags":["hdfs,大数据"],"title":"Hdfs高可用与高拓展机制分析","uri":"/hdfs%E9%AB%98%E5%8F%AF%E7%94%A8%E4%B8%8E%E9%AB%98%E6%8B%93%E5%B1%95%E6%9C%BA%E5%88%B6%E5%88%86%E6%9E%90/"},{"categories":["分布式技术"],"content":"1.11Quorum机制：多副本一致性读写 场景:多副本对象存储，用版本号标识数据新旧 ","date":"2023-06-06","objectID":"/hdfs%E9%AB%98%E5%8F%AF%E7%94%A8%E4%B8%8E%E9%AB%98%E6%8B%93%E5%B1%95%E6%9C%BA%E5%88%B6%E5%88%86%E6%9E%90/:11:0","tags":["hdfs,大数据"],"title":"Hdfs高可用与高拓展机制分析","uri":"/hdfs%E9%AB%98%E5%8F%AF%E7%94%A8%E4%B8%8E%E9%AB%98%E6%8B%93%E5%B1%95%E6%9C%BA%E5%88%B6%E5%88%86%E6%9E%90/"},{"categories":["分布式技术"],"content":"1.12BookKeeper Quorum 日志场景:顺序追加、只写 Write Quorum:写入副本数 Ack Quorum:响应副本数 ","date":"2023-06-06","objectID":"/hdfs%E9%AB%98%E5%8F%AF%E7%94%A8%E4%B8%8E%E9%AB%98%E6%8B%93%E5%B1%95%E6%9C%BA%E5%88%B6%E5%88%86%E6%9E%90/:12:0","tags":["hdfs,大数据"],"title":"Hdfs高可用与高拓展机制分析","uri":"/hdfs%E9%AB%98%E5%8F%AF%E7%94%A8%E4%B8%8E%E9%AB%98%E6%8B%93%E5%B1%95%E6%9C%BA%E5%88%B6%E5%88%86%E6%9E%90/"},{"categories":["分布式技术"],"content":"1.13BookKeeper Ensemble 均衡加载数据 Round-Robin Load Balancer· 第一轮: 1,2,3 第二轮: 2,3,4 第三轮: 3,4,1 第四轮: 4,1,2 二、数据存储高可用 ","date":"2023-06-06","objectID":"/hdfs%E9%AB%98%E5%8F%AF%E7%94%A8%E4%B8%8E%E9%AB%98%E6%8B%93%E5%B1%95%E6%9C%BA%E5%88%B6%E5%88%86%E6%9E%90/:13:0","tags":["hdfs,大数据"],"title":"Hdfs高可用与高拓展机制分析","uri":"/hdfs%E9%AB%98%E5%8F%AF%E7%94%A8%E4%B8%8E%E9%AB%98%E6%8B%93%E5%B1%95%E6%9C%BA%E5%88%B6%E5%88%86%E6%9E%90/"},{"categories":["分布式技术"],"content":"2.1单机存储–RAID Redundant Array of Independent Disks 图:提供RAID功能的NAS设备 ","date":"2023-06-06","objectID":"/hdfs%E9%AB%98%E5%8F%AF%E7%94%A8%E4%B8%8E%E9%AB%98%E6%8B%93%E5%B1%95%E6%9C%BA%E5%88%B6%E5%88%86%E6%9E%90/:14:0","tags":["hdfs,大数据"],"title":"Hdfs高可用与高拓展机制分析","uri":"/hdfs%E9%AB%98%E5%8F%AF%E7%94%A8%E4%B8%8E%E9%AB%98%E6%8B%93%E5%B1%95%E6%9C%BA%E5%88%B6%E5%88%86%E6%9E%90/"},{"categories":["分布式技术"],"content":"2.2RAID方案讲解 RAID 0：条带化-把数据按顺序依次分配在每个储存空间里 RAID 1: 冗余-把一份数据复制两份存储在每个储存空间里 RAID 3:容错校验 把数据分成多个“块”，按照一定的容错算法，存放在N+1个硬盘上，实际数据占用的有效空间为N个硬盘的空间总和，而第N+1个硬盘上存储的数据是校验容错信息，当这N+1个硬盘中的其中一个硬盘出现故障时，从其它N个硬盘中的数据也可以恢复原始数据，这样，仅使用这N个硬盘也可以带伤继续工作（如采集和回放素材），当更换一个新硬盘后，系统可以重新恢复完整的校验容错信息。 ","date":"2023-06-06","objectID":"/hdfs%E9%AB%98%E5%8F%AF%E7%94%A8%E4%B8%8E%E9%AB%98%E6%8B%93%E5%B1%95%E6%9C%BA%E5%88%B6%E5%88%86%E6%9E%90/:15:0","tags":["hdfs,大数据"],"title":"Hdfs高可用与高拓展机制分析","uri":"/hdfs%E9%AB%98%E5%8F%AF%E7%94%A8%E4%B8%8E%E9%AB%98%E6%8B%93%E5%B1%95%E6%9C%BA%E5%88%B6%E5%88%86%E6%9E%90/"},{"categories":["分布式技术"],"content":"2.3HDFS多副本 HDFS版本的RAID1多副本 优点 陵与路径简单 副本修复简单高可用 ","date":"2023-06-06","objectID":"/hdfs%E9%AB%98%E5%8F%AF%E7%94%A8%E4%B8%8E%E9%AB%98%E6%8B%93%E5%B1%95%E6%9C%BA%E5%88%B6%E5%88%86%E6%9E%90/:16:0","tags":["hdfs,大数据"],"title":"Hdfs高可用与高拓展机制分析","uri":"/hdfs%E9%AB%98%E5%8F%AF%E7%94%A8%E4%B8%8E%E9%AB%98%E6%8B%93%E5%B1%95%E6%9C%BA%E5%88%B6%E5%88%86%E6%9E%90/"},{"categories":["分布式技术"],"content":"Erasure Coding原理 HDFS版本的RAID2/3，常用Reed Solomon算法 算法原理 ","date":"2023-06-06","objectID":"/hdfs%E9%AB%98%E5%8F%AF%E7%94%A8%E4%B8%8E%E9%AB%98%E6%8B%93%E5%B1%95%E6%9C%BA%E5%88%B6%E5%88%86%E6%9E%90/:16:1","tags":["hdfs,大数据"],"title":"Hdfs高可用与高拓展机制分析","uri":"/hdfs%E9%AB%98%E5%8F%AF%E7%94%A8%E4%B8%8E%E9%AB%98%E6%8B%93%E5%B1%95%E6%9C%BA%E5%88%B6%E5%88%86%E6%9E%90/"},{"categories":["分布式技术"],"content":"HDFS Erasure Coding HDFS版本的RAID2 图:直接保存的EC和Stripe(条带化)后保存的EC ","date":"2023-06-06","objectID":"/hdfs%E9%AB%98%E5%8F%AF%E7%94%A8%E4%B8%8E%E9%AB%98%E6%8B%93%E5%B1%95%E6%9C%BA%E5%88%B6%E5%88%86%E6%9E%90/:16:2","tags":["hdfs,大数据"],"title":"Hdfs高可用与高拓展机制分析","uri":"/hdfs%E9%AB%98%E5%8F%AF%E7%94%A8%E4%B8%8E%E9%AB%98%E6%8B%93%E5%B1%95%E6%9C%BA%E5%88%B6%E5%88%86%E6%9E%90/"},{"categories":["分布式技术"],"content":"2.4网络架构 机架(Rack):放服务器的架子。 TOR(Top of Rack):机架顶部的交换机。 数据中心(Data Center):集中部署服务器的场所 2.5副本放置策略-机架感知 一个TOR故障导致整个机架不可用vs 降低跨rack流量 trade-off:一个本地、一个远端 三、元数据可拓展性 HDFS NameNode是个集中式服务，部署在单个机器上，内存和磁盘的容量、CPU的计算力都不能无限扩展。 拓展方法： 扩容单个服务器的能力 部署多个服务器来扩容 挑战： 名字空间分裂 DataNode分裂 目录树结构复杂 ","date":"2023-06-06","objectID":"/hdfs%E9%AB%98%E5%8F%AF%E7%94%A8%E4%B8%8E%E9%AB%98%E6%8B%93%E5%B1%95%E6%9C%BA%E5%88%B6%E5%88%86%E6%9E%90/:17:0","tags":["hdfs,大数据"],"title":"Hdfs高可用与高拓展机制分析","uri":"/hdfs%E9%AB%98%E5%8F%AF%E7%94%A8%E4%B8%8E%E9%AB%98%E6%8B%93%E5%B1%95%E6%9C%BA%E5%88%B6%E5%88%86%E6%9E%90/"},{"categories":["分布式技术"],"content":"3.1常见的Scale Out方案 图:三种数据路由方式 服务端侧 路由层 客户端侧 ","date":"2023-06-06","objectID":"/hdfs%E9%AB%98%E5%8F%AF%E7%94%A8%E4%B8%8E%E9%AB%98%E6%8B%93%E5%B1%95%E6%9C%BA%E5%88%B6%E5%88%86%E6%9E%90/:18:0","tags":["hdfs,大数据"],"title":"Hdfs高可用与高拓展机制分析","uri":"/hdfs%E9%AB%98%E5%8F%AF%E7%94%A8%E4%B8%8E%E9%AB%98%E6%8B%93%E5%B1%95%E6%9C%BA%E5%88%B6%E5%88%86%E6%9E%90/"},{"categories":["分布式技术"],"content":"3.2社区解决方案 BlockPool 解决datenode同时服务多组NameNode的问题 文件服务分层 Namespace Block Storage 用BlockPool来区分datenode的服务 数据块存储 心跳和块上报 ","date":"2023-06-06","objectID":"/hdfs%E9%AB%98%E5%8F%AF%E7%94%A8%E4%B8%8E%E9%AB%98%E6%8B%93%E5%B1%95%E6%9C%BA%E5%88%B6%E5%88%86%E6%9E%90/:19:0","tags":["hdfs,大数据"],"title":"Hdfs高可用与高拓展机制分析","uri":"/hdfs%E9%AB%98%E5%8F%AF%E7%94%A8%E4%B8%8E%E9%AB%98%E6%8B%93%E5%B1%95%E6%9C%BA%E5%88%B6%E5%88%86%E6%9E%90/"},{"categories":["分布式技术"],"content":"3.3社区解决方案 viewsf Federation架构:将多个不同集群组合起来，对外表现像一个集群一样。 图: viewfs通过在client-side的配置，指定不同的目录访问不同的NameNode。 ","date":"2023-06-06","objectID":"/hdfs%E9%AB%98%E5%8F%AF%E7%94%A8%E4%B8%8E%E9%AB%98%E6%8B%93%E5%B1%95%E6%9C%BA%E5%88%B6%E5%88%86%E6%9E%90/:20:0","tags":["hdfs,大数据"],"title":"Hdfs高可用与高拓展机制分析","uri":"/hdfs%E9%AB%98%E5%8F%AF%E7%94%A8%E4%B8%8E%E9%AB%98%E6%8B%93%E5%B1%95%E6%9C%BA%E5%88%B6%E5%88%86%E6%9E%90/"},{"categories":["分布式技术"],"content":"3.4字节跳动的NNProxy NNProxy是ByteDance自研的HDFS代理层，提供了路由服务。 NNProxy主要实现了路由管理和RPC转发·以及鉴权、限流、查询缓存等额外能力 图:NNProxy所在系统上下游 NNProxy的路由规则保存 ![在这里插入图片描述](https://img-blog.csdnimg.cn/34fc748acbe14e4ea8d50377226dc2f9.png) NNProxy路由转发实现 目录树视图 四、存储数据高拓展性 ","date":"2023-06-06","objectID":"/hdfs%E9%AB%98%E5%8F%AF%E7%94%A8%E4%B8%8E%E9%AB%98%E6%8B%93%E5%B1%95%E6%9C%BA%E5%88%B6%E5%88%86%E6%9E%90/:21:0","tags":["hdfs,大数据"],"title":"Hdfs高可用与高拓展机制分析","uri":"/hdfs%E9%AB%98%E5%8F%AF%E7%94%A8%E4%B8%8E%E9%AB%98%E6%8B%93%E5%B1%95%E6%9C%BA%E5%88%B6%E5%88%86%E6%9E%90/"},{"categories":["分布式技术"],"content":"4.1延迟的分布与长尾延迟 延迟的分布:用百分数来表示访问的延迟的统计特征例如p95延迟为1ms，代表95%的请求延迟要低于1ms,但后5%的请求延迟会大于1ms 长尾延迟:尾部(p99/p999/p999)的延迟，衡量系统最差的请求的情况。会显著的要差于平均值 木桶原理使尾部延迟放大:访问的服务变多，尾部的请求就会越发的慢。 尾部延迟放大，整个服务被Backend 6拖累 ","date":"2023-06-06","objectID":"/hdfs%E9%AB%98%E5%8F%AF%E7%94%A8%E4%B8%8E%E9%AB%98%E6%8B%93%E5%B1%95%E6%9C%BA%E5%88%B6%E5%88%86%E6%9E%90/:22:0","tags":["hdfs,大数据"],"title":"Hdfs高可用与高拓展机制分析","uri":"/hdfs%E9%AB%98%E5%8F%AF%E7%94%A8%E4%B8%8E%E9%AB%98%E6%8B%93%E5%B1%95%E6%9C%BA%E5%88%B6%E5%88%86%E6%9E%90/"},{"categories":["分布式技术"],"content":"4.2长尾问题的表现-慢节点 慢节点:读取速度过慢，导致客户端阻塞。 慢节点的发生难以避免和预测 共享资源、后台维护活动、请求多级排队、功率限制。 固定的损耗:机器损坏率 混沌现象 离线任务也会遇到长尾问题 全部任务完成时间取决于最慢的任务什么时候完成。 集群规模变大，任务的数据量变大。 只要任何数据块的读取受到长尾影响，整个任务就会因此停滞. 集群扩大10倍，问题扩大N(\u003e10)倍 ","date":"2023-06-06","objectID":"/hdfs%E9%AB%98%E5%8F%AF%E7%94%A8%E4%B8%8E%E9%AB%98%E6%8B%93%E5%B1%95%E6%9C%BA%E5%88%B6%E5%88%86%E6%9E%90/:23:0","tags":["hdfs,大数据"],"title":"Hdfs高可用与高拓展机制分析","uri":"/hdfs%E9%AB%98%E5%8F%AF%E7%94%A8%E4%B8%8E%E9%AB%98%E6%8B%93%E5%B1%95%E6%9C%BA%E5%88%B6%E5%88%86%E6%9E%90/"},{"categories":["分布式技术"],"content":"4.3超大集群下的数据可靠性 条件一:超大集群下，有一部分机器是损坏来不及修理的。 条件二:副本放置策略完全随机。 条件三:DN的容量足够大 推论:必然有部分数据全部副本在损坏的机器上，发生数据丢失。 解决方法：Copyset 将DataNode分为若干个Copyset选块在copyset内部选择 原理:减少了副本放置的组合数，从而降低副本丢失的概率。 ","date":"2023-06-06","objectID":"/hdfs%E9%AB%98%E5%8F%AF%E7%94%A8%E4%B8%8E%E9%AB%98%E6%8B%93%E5%B1%95%E6%9C%BA%E5%88%B6%E5%88%86%E6%9E%90/:24:0","tags":["hdfs,大数据"],"title":"Hdfs高可用与高拓展机制分析","uri":"/hdfs%E9%AB%98%E5%8F%AF%E7%94%A8%E4%B8%8E%E9%AB%98%E6%8B%93%E5%B1%95%E6%9C%BA%E5%88%B6%E5%88%86%E6%9E%90/"},{"categories":["分布式技术"],"content":"4.4超大集群的负载均衡和数据迁移 新加入的DataNode会成为一个数据写入的热点，而老的datenode数据写入量就少了 数据的不均匀 节点容量不均匀 数据新日不均匀 访问类型不均匀 资源负载不均匀 典型场景 ","date":"2023-06-06","objectID":"/hdfs%E9%AB%98%E5%8F%AF%E7%94%A8%E4%B8%8E%E9%AB%98%E6%8B%93%E5%B1%95%E6%9C%BA%E5%88%B6%E5%88%86%E6%9E%90/:25:0","tags":["hdfs,大数据"],"title":"Hdfs高可用与高拓展机制分析","uri":"/hdfs%E9%AB%98%E5%8F%AF%E7%94%A8%E4%B8%8E%E9%AB%98%E6%8B%93%E5%B1%95%E6%9C%BA%E5%88%B6%E5%88%86%E6%9E%90/"},{"categories":["分布式技术"],"content":"4.5数据迁移工具-跨NN迁移 DistCopy 基于MapReduce，通过一个个任务，将数据从一个NameNode拷 贝到另一个 NameNode。 需要拷贝数据，流量较大，速度较慢。 FastCopy 开源社区的无需拷贝数据的快速元数据迁移方案√前提条件:新旧集群的DN列表吻合 对于元数据，直接复制目录树的结构和块信息。 对于数据块，直接要求DataNode从源 BlockPool hardlink 到目标 BlookPool，没有数据拷贝。 hardlink:直接让两个路径指向同一块数据。 balancer 工具向DataNode 发起迁移命令，平衡各个DataNode的容量。 场景 单机房使用、多机房使用限流措施 评价标准 稳定性成本 可运维性 eNode。 需要拷贝数据，流量较大，速度较慢。 FastCopy 开源社区的无需拷贝数据的快速元数据迁移方案√前提条件:新旧集群的DN列表吻合 对于元数据，直接复制目录树的结构和块信息。 对于数据块，直接要求DataNode从源 BlockPool hardlink 到目标 BlookPool，没有数据拷贝。 hardlink:直接让两个路径指向同一块数据。 balancer 工具向DataNode 发起迁移命令，平衡各个DataNode的容量。 [外链图片转存中…(img-UrAfd3Lb-1660221746580)] 场景 单机房使用、多机房使用限流措施 评价标准 稳定性成本 可运维性 执行效率 要实现，一个分布式文件系统要考虑的太多了，毕竟hdfs是个代码量十多万的项目。但是要是想搭建基本框架的人可以参考这个项目 还有一个用go语言写的简易gfs ","date":"2023-06-06","objectID":"/hdfs%E9%AB%98%E5%8F%AF%E7%94%A8%E4%B8%8E%E9%AB%98%E6%8B%93%E5%B1%95%E6%9C%BA%E5%88%B6%E5%88%86%E6%9E%90/:26:0","tags":["hdfs,大数据"],"title":"Hdfs高可用与高拓展机制分析","uri":"/hdfs%E9%AB%98%E5%8F%AF%E7%94%A8%E4%B8%8E%E9%AB%98%E6%8B%93%E5%B1%95%E6%9C%BA%E5%88%B6%E5%88%86%E6%9E%90/"},{"categories":["分布式技术"],"content":"是大数据的核心组件，也是分布式技术的入门。","date":"2023-06-06","objectID":"/hdfs%E5%88%86%E5%B8%83%E5%BC%8F%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E7%AE%80%E4%BB%8B%E4%B8%8E%E8%AE%BE%E8%AE%A1%E5%8E%9F%E7%90%86/","tags":["hdfs,大数据"],"title":"hdfs分布式文件系统简介与设计原理","uri":"/hdfs%E5%88%86%E5%B8%83%E5%BC%8F%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E7%AE%80%E4%BB%8B%E4%B8%8E%E8%AE%BE%E8%AE%A1%E5%8E%9F%E7%90%86/"},{"categories":["分布式技术"],"content":"一、hdfs基本介绍 全程hadoop distributed file system ","date":"2023-06-06","objectID":"/hdfs%E5%88%86%E5%B8%83%E5%BC%8F%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E7%AE%80%E4%BB%8B%E4%B8%8E%E8%AE%BE%E8%AE%A1%E5%8E%9F%E7%90%86/:0:0","tags":["hdfs,大数据"],"title":"hdfs分布式文件系统简介与设计原理","uri":"/hdfs%E5%88%86%E5%B8%83%E5%BC%8F%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E7%AE%80%E4%BB%8B%E4%B8%8E%E8%AE%BE%E8%AE%A1%E5%8E%9F%E7%90%86/"},{"categories":["分布式技术"],"content":"技术体系 计算框架：MapReduce。值得注意的是另外一个同属于Apache基金会的开源计算框架Apache Spark，当前业界的使用已经远超于MapReduce，尽管它不属于Hadoop项目，但是和Hadoop也有紧密关系。 ","date":"2023-06-06","objectID":"/hdfs%E5%88%86%E5%B8%83%E5%BC%8F%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E7%AE%80%E4%BB%8B%E4%B8%8E%E8%AE%BE%E8%AE%A1%E5%8E%9F%E7%90%86/:1:0","tags":["hdfs,大数据"],"title":"hdfs分布式文件系统简介与设计原理","uri":"/hdfs%E5%88%86%E5%B8%83%E5%BC%8F%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E7%AE%80%E4%BB%8B%E4%B8%8E%E8%AE%BE%E8%AE%A1%E5%8E%9F%E7%90%86/"},{"categories":["分布式技术"],"content":"单机文件系统 文件系统：单机文件系统非常普遍，从Windows NTFS到Linux的Ext4等，分布式文件系统是单机文件的延伸，概念术语是相通的，比如目录、文件、目录树等。 单机文件系统：常见的如Windows NTFS，Linux的Ext4，虽然不同的操作系统和实现，但是本质都是一样的，解决相同的问题。 分布式文件系统：本质上扩展、延伸了单机文件系统，提供了大容量、高可靠、低成本等功能特性；实现上一般也更为复杂。 ","date":"2023-06-06","objectID":"/hdfs%E5%88%86%E5%B8%83%E5%BC%8F%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E7%AE%80%E4%BB%8B%E4%B8%8E%E8%AE%BE%E8%AE%A1%E5%8E%9F%E7%90%86/:2:0","tags":["hdfs,大数据"],"title":"hdfs分布式文件系统简介与设计原理","uri":"/hdfs%E5%88%86%E5%B8%83%E5%BC%8F%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E7%AE%80%E4%BB%8B%E4%B8%8E%E8%AE%BE%E8%AE%A1%E5%8E%9F%E7%90%86/"},{"categories":["分布式技术"],"content":"分布式文件系统 分布式文件系统优点 大容量 更多的机器，更多的存储介质 高可靠 多个副本提高容错能力 低成本 不需要高端硬件来扩容 对象存储：例如AWS的S3，阿里云的OSS，开源的Minio。 块存储：例如AWS的EBS，开源社区也有Ceph等。 文件系统：HDFS、GlusterFS、CubeFS等 数据库：KV数据库比如Cassandra，关系型数据库如TiDB、OceanBase等 ","date":"2023-06-06","objectID":"/hdfs%E5%88%86%E5%B8%83%E5%BC%8F%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E7%AE%80%E4%BB%8B%E4%B8%8E%E8%AE%BE%E8%AE%A1%E5%8E%9F%E7%90%86/:3:0","tags":["hdfs,大数据"],"title":"hdfs分布式文件系统简介与设计原理","uri":"/hdfs%E5%88%86%E5%B8%83%E5%BC%8F%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E7%AE%80%E4%BB%8B%E4%B8%8E%E8%AE%BE%E8%AE%A1%E5%8E%9F%E7%90%86/"},{"categories":["分布式技术"],"content":"HDFS功能特性 分布式 受GFS启发，用Java实现的开源系统，没有量client并发读写 容错 自动处理、规避多种错误场景，例如常见的网络错误、机器宕机等。 高可用 —主多备模式实现元数据高可用，数据多副本实现用户数据的高可用 高吞吐 Client直接从DataNode读取用户数据，服务端支持海量client并发读写 可扩展 支持联邦集群模式，DataNode数量可达10w级别 廉价 只需要通用硬件，不需要定制高端的昂贵硬件设备 二、架构原理 ","date":"2023-06-06","objectID":"/hdfs%E5%88%86%E5%B8%83%E5%BC%8F%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E7%AE%80%E4%BB%8B%E4%B8%8E%E8%AE%BE%E8%AE%A1%E5%8E%9F%E7%90%86/:4:0","tags":["hdfs,大数据"],"title":"hdfs分布式文件系统简介与设计原理","uri":"/hdfs%E5%88%86%E5%B8%83%E5%BC%8F%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E7%AE%80%E4%BB%8B%E4%B8%8E%E8%AE%BE%E8%AE%A1%E5%8E%9F%E7%90%86/"},{"categories":["分布式技术"],"content":"HDFS组件 Client/SDK：读写操作的发起点，HDFS很多读写逻辑都是在SDK中实现的。 NameNode：元数据节点，是HDFS的中枢节点，也是服务的入口。 DataNode：数据节点，存放实际用户数据。 ","date":"2023-06-06","objectID":"/hdfs%E5%88%86%E5%B8%83%E5%BC%8F%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E7%AE%80%E4%BB%8B%E4%B8%8E%E8%AE%BE%E8%AE%A1%E5%8E%9F%E7%90%86/:5:0","tags":["hdfs,大数据"],"title":"hdfs分布式文件系统简介与设计原理","uri":"/hdfs%E5%88%86%E5%B8%83%E5%BC%8F%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E7%AE%80%E4%BB%8B%E4%B8%8E%E8%AE%BE%E8%AE%A1%E5%8E%9F%E7%90%86/"},{"categories":["分布式技术"],"content":"client写流程 数据存储到一个datanode后会依次复制到两个datanode ","date":"2023-06-06","objectID":"/hdfs%E5%88%86%E5%B8%83%E5%BC%8F%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E7%AE%80%E4%BB%8B%E4%B8%8E%E8%AE%BE%E8%AE%A1%E5%8E%9F%E7%90%86/:6:0","tags":["hdfs,大数据"],"title":"hdfs分布式文件系统简介与设计原理","uri":"/hdfs%E5%88%86%E5%B8%83%E5%BC%8F%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E7%AE%80%E4%BB%8B%E4%B8%8E%E8%AE%BE%E8%AE%A1%E5%8E%9F%E7%90%86/"},{"categories":["分布式技术"],"content":"client读流程 读流程只读其中一个副本 ","date":"2023-06-06","objectID":"/hdfs%E5%88%86%E5%B8%83%E5%BC%8F%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E7%AE%80%E4%BB%8B%E4%B8%8E%E8%AE%BE%E8%AE%A1%E5%8E%9F%E7%90%86/:7:0","tags":["hdfs,大数据"],"title":"hdfs分布式文件系统简介与设计原理","uri":"/hdfs%E5%88%86%E5%B8%83%E5%BC%8F%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E7%AE%80%E4%BB%8B%E4%B8%8E%E8%AE%BE%E8%AE%A1%E5%8E%9F%E7%90%86/"},{"categories":["分布式技术"],"content":"NameNode Namenode作用 维护目录树 维护目录树的增删改查操作，保证所有修改都能持久化，以便机器掉电不会造成数据丢失或不一致。 维护文件和数据块的关系 文件被切分成多个块，文件以数据块为单位进行多副本存放 维护文件块存放节点信息 通过接收DataNode的心跳汇报信息，维护集群节点的拓扑结构和每个文件块所有副本所在的DataNode类表。 分配新文件存放节点 Client创建新的文件时候，需要有NameNode来确定分配目标DataNode ","date":"2023-06-06","objectID":"/hdfs%E5%88%86%E5%B8%83%E5%BC%8F%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E7%AE%80%E4%BB%8B%E4%B8%8E%E8%AE%BE%E8%AE%A1%E5%8E%9F%E7%90%86/:8:0","tags":["hdfs,大数据"],"title":"hdfs分布式文件系统简介与设计原理","uri":"/hdfs%E5%88%86%E5%B8%83%E5%BC%8F%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E7%AE%80%E4%BB%8B%E4%B8%8E%E8%AE%BE%E8%AE%A1%E5%8E%9F%E7%90%86/"},{"categories":["分布式技术"],"content":"DateNode Datenode作用 数据块存取 DataNode需要高效实现对数据块在硬盘上的存取 心跳汇报 把存放在本机的数据块列表发送给NameNode，以便NameNode能维护数据块的位置信息，同时让 NameNode确定该节点处于正常存活状态 副本复制 1.数据写入时Pipeline lO操作 2.机器故障时补全副本 三、关键设计 基本设计 容错能力 能够处理绝大部分异常场景，例如服务器宕机、网络异常、磁盘故障、网络超时等。 一致性模型 为了实现容错，数据必须多副本存放，一致性要解决的问题是如何保障这多个副本的内容都是一致的 可扩展性 分布式存储系统需要具备横向扩张scale-out的能力 节点体系 常见的有主从模式、对等模式等，不管哪种模式，高可用是必须的功能。 数据放置 系统是由多个节点组成，数据是多个副本存放时，需要考虑数据存放的策略。 单机存储引擎 在绝大部分存储系统中，数据都是需要落盘持久化，单机引擎需要解决的是根据系统特点，如何高效得存取硬盘数据。 NameNode目录树设计，重点理解EditLog的设计，可类比关系型数据库中的Transaction Log概念。 仅在内存中修改：fsimage 文件系统目录树完整的存放在内存中 定时存放到硬盘上 修改是只会修改内存中的目录树 需要立即保存到硬盘：EditLog 目录树的修改日志 client更新目录树需要持久化EditLog后才能表示更新成功EditLog可存放在本地文件系统，也可存放在专用系统 NameNode HA方案一个关键点就是如何实现EditLog共享 NameNode数据放置：数据分散在各个节点上，如何定位找到它们？ 数据块信息维护 目录树保存每个文件的块id NameNode维护了每个数据块所在的节点信息 NameNode根据DataNode汇报的信息动态维护位置信息NameNode不会持久化数据块位置信息 数据块的放置分布策略 新数据存放到哪写节点 数据均衡需要怎么合理搬迁数据 3个副本怎么合理放置 DataNode设计：数据如何落盘存放？ 数据块硬盘存放 文件在NameNode已分割成block DataNode以block为单位对数据进行存取 启动扫盘获得本机文件块列表 DataNode需要知道本机存放了哪些数据块 启动时把本机硬盘上的数据块列表加载在内存中 Client读写链路的异常处理 Server端异常 情景:文件写入过程中，DataNode侧出现异常挂掉了。 可能出现在：创建连接时、数据传输时、complete阶段 解决方法:Pipeline Recovery Client端异常 client写异常处理: 解决方法—Lease Recovery 租约:Client要修改一个文件时，需要通过NameNode上锁，这个锁就是租约(Lease)。 情景:文件写了一半，client自己挂掉了。可能产生的问题:副本不一致、Lease无法释放 client读异常： 解决方法—节点faliover 读取文件的过程，DataNode 侧出现异常挂掉了 慢节点 （判断读取速度) 旁路系统：保障系统稳定运行 HouseKeeping组件：比如Balancer，Mover等， 这些组件不运行不会马上影响读写操作，但是长时间会积累系统性问题，例如读写不均衡导致IO热点等。 Balancer:均衡DataNode的容量 Mover:确保副本放置符合策略要求 控制面建设：好的系统不是只实现基本功能，还要实现监控和运维体系 可观测性设施：比如系统指标监控设施等，帮助快速发现定位问题。 指标埋点 数据米乐 访问日志 数据分析 运维体系建设：从最基本的命令行手工操作，脚本自动化再到完善的运维平台。 运维操作需要平台化 NameNode操作复杂 DataNode机器规模庞大 可观测性设施：比如系统指标监控设施等，帮助快速发现定位问题。 指标埋点 数据米乐 访问日志 数据分析 运维体系建设：从最基本的命令行手工操作，脚本自动化再到完善的运维平台。 运维操作需要平台化 NameNode操作复杂 DataNode机器规模庞大 组件控制面API ","date":"2023-06-06","objectID":"/hdfs%E5%88%86%E5%B8%83%E5%BC%8F%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E7%AE%80%E4%BB%8B%E4%B8%8E%E8%AE%BE%E8%AE%A1%E5%8E%9F%E7%90%86/:9:0","tags":["hdfs,大数据"],"title":"hdfs分布式文件系统简介与设计原理","uri":"/hdfs%E5%88%86%E5%B8%83%E5%BC%8F%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E7%AE%80%E4%BB%8B%E4%B8%8E%E8%AE%BE%E8%AE%A1%E5%8E%9F%E7%90%86/"},{"categories":["大数据技术"],"content":"字节跳动青训营里spark原理与改进的学习。","date":"2023-06-06","objectID":"/spark%E5%8E%9F%E7%90%86%E5%8F%8A%E4%BC%98%E5%8C%96/","tags":["spark,大数据"],"title":"Spark原理及优化","uri":"/spark%E5%8E%9F%E7%90%86%E5%8F%8A%E4%BC%98%E5%8C%96/"},{"categories":["大数据技术"],"content":"一、NATS介绍 NATS是由CloudFoundry的架构师Derek开发的一个开源的、轻量级、高性能的，支持发布、订阅机制的分布式消息队列系统。它的核心基于EventMachine开发，代码量不多，可以下载下来慢慢研究。 不同于Java社区的kafka，nats偏于redis式的消息中间件，不不像Kafka式的可以持久化。 NATS原来是使用Ruby编写，可以实现每秒150k消息，后来使用Go语言重写，能够达到每秒8-11百万个消息，整个程序很小只有3M Docker image，它不支持持久化消息，如果你离线，你就不能获得消息。 NATS适合云基础设施的消息通信系统、IoT设备消息通信和微服务架构。 目前已经采用了NATS系统的公司有：爱立信、HTC、百度、西门子、VMware。 NATS 有 3 个产品 core-nats: 不做持久化的及时信息传输系统 nats-streaming: 基于 nats 的持久化消息队列(已弃用) nats-jetstream: 基于 nats 的持久化消息队列 二、NATS服务器与客户端 NATS服务器与客户端 NATS服务器：用Golang语言开发，发行版包括二进制发布包和Docker镜像。 NATS客户端：包含了多种语言的客户端。 官方提供的客户端 Go client：　https://github.com/nats-io/go-nats Node.js client： https://github.com/nats-io/node-nats Ruby client：　https://github.com/nats-io/ruby-nats Java client：　https://github.com/nats-io/jnats C client：　https://github.com/nats-io/cnats C# client：　https://github.com/nats-io/csnats Nginx C client：https://github.com/nats-io/nginx-nats 还有社区提供的客户端： Spring： https://github.com/cloudfoundry-community/java-nats Lua：　https://github.com/DawnAngel/lua-nats PHP： https://github.com/repejota/phpnats Python：https://github.com/mcuadros/pynats Scala： https://github.com/tyagihas/scala_nats/ Haskell：https://github.com/ondrap/nats-queue 查看客户端API技巧 对于Golang客户端API文档，需要这样： 1）用 Go 下载 go版本客户端源码及使用文档 go git https://github.com/nats-io/go-nats.git 2）使用 Go 文档查看器来查看线上文档 godoc -http :8080 3）通过浏览器访问 API 文档 http://localhost:8080/pkg/github.com/nats-io/gnatsd/ 三、NATS的设计目标 ","date":"2023-06-06","objectID":"/spark%E5%8E%9F%E7%90%86%E5%8F%8A%E4%BC%98%E5%8C%96/:0:0","tags":["spark,大数据"],"title":"Spark原理及优化","uri":"/spark%E5%8E%9F%E7%90%86%E5%8F%8A%E4%BC%98%E5%8C%96/"},{"categories":["大数据技术"],"content":"3.1 NATS的设计原则 NATS的设计原则是：高性能、可伸缩能力、易于使用，基于这些原则，NATS的设计目标包括： 1）高性能（fast） 2）一直可用（dial tone） 3）极度轻量级（small footprint） 4）最多交付一次（fire and forget，消息发送后不管） 5）支持多种消息通信模型和用例场景（flexible） ","date":"2023-06-06","objectID":"/spark%E5%8E%9F%E7%90%86%E5%8F%8A%E4%BC%98%E5%8C%96/:1:0","tags":["spark,大数据"],"title":"Spark原理及优化","uri":"/spark%E5%8E%9F%E7%90%86%E5%8F%8A%E4%BC%98%E5%8C%96/"},{"categories":["大数据技术"],"content":"3.2 NATS理想的使用场景 NATS理想的使用场景有： 1）寻址、发现 2）命令和控制（控制面板） 3）负载均衡 4）多路可伸缩能力 5）定位透明 6）容错 ","date":"2023-06-06","objectID":"/spark%E5%8E%9F%E7%90%86%E5%8F%8A%E4%BC%98%E5%8C%96/:2:0","tags":["spark,大数据"],"title":"Spark原理及优化","uri":"/spark%E5%8E%9F%E7%90%86%E5%8F%8A%E4%BC%98%E5%8C%96/"},{"categories":["大数据技术"],"content":"3.3 NATS设计哲学 NATS设计哲学认为，高质量的QoS应该在客户端构建，故只建立了请求-应答，不提供： 1）持久化 2）事务处理 3）增强的交付模式 4）企业级队列 四、基于主题的消息传递 从根本上说，NATS 是关于发布和侦听消息的。这两者都在很大程度上依赖于主题。 **什么是主题？**简单来说，主题只是一串字符，它们构成了发布者和订阅者可以用来查找彼此的名称。它有助于将消息范围限定为流或主题。 [外链图片转存失败,源站可能有防盗链机制,建议将图片保存下来直接上传(img-KhsRYivK-1678191670802)(null)] ","date":"2023-06-06","objectID":"/spark%E5%8E%9F%E7%90%86%E5%8F%8A%E4%BC%98%E5%8C%96/:3:0","tags":["spark,大数据"],"title":"Spark原理及优化","uri":"/spark%E5%8E%9F%E7%90%86%E5%8F%8A%E4%BC%98%E5%8C%96/"},{"categories":["大数据技术"],"content":"4.1 使用者名称允许使用的字符 为了跨客户端兼容，我们建议使用 ASCII 字符（将来可能会更改）。 推荐字符：a 到 z，A 到 Z和0到9（名称区分大小写，不能包含空格）。特殊字符：句点。（用于分隔主题中的标记）和 * 和 \u003e（*和\u003e用作通配符）。保留的使用者名称：按照惯例，以a`$`开头的使用者名称保留供系统使用（例如，以$SYS或$JS或$KV等开头的使用者名称） ","date":"2023-06-06","objectID":"/spark%E5%8E%9F%E7%90%86%E5%8F%8A%E4%BC%98%E5%8C%96/:4:0","tags":["spark,大数据"],"title":"Spark原理及优化","uri":"/spark%E5%8E%9F%E7%90%86%E5%8F%8A%E4%BC%98%E5%8C%96/"},{"categories":["大数据技术"],"content":"4.2 主题层次结构 .字符用于创建主题层次结构。例如，世界时钟应用程序可能会定义以下内容以对相关主题进行逻辑分组： time.us time.us.east time.us.east.atlanta time.eu.east time.eu.warsaw ","date":"2023-06-06","objectID":"/spark%E5%8E%9F%E7%90%86%E5%8F%8A%E4%BC%98%E5%8C%96/:5:0","tags":["spark,大数据"],"title":"Spark原理及优化","uri":"/spark%E5%8E%9F%E7%90%86%E5%8F%8A%E4%BC%98%E5%8C%96/"},{"categories":["大数据技术"],"content":"4.2.1 匹配单个子主题 第一个通配符是*，它将匹配单个标记。例如，如果应用程序想要侦听东部时区，他们可以订阅 time.*.east，这将匹配time.us.east 和time.eu.east。`` [外链图片转存失败,源站可能有防盗链机制,建议将图片保存下来直接上传(img-DG3euyWI-1678191670677)(null)] ","date":"2023-06-06","objectID":"/spark%E5%8E%9F%E7%90%86%E5%8F%8A%E4%BC%98%E5%8C%96/:5:1","tags":["spark,大数据"],"title":"Spark原理及优化","uri":"/spark%E5%8E%9F%E7%90%86%E5%8F%8A%E4%BC%98%E5%8C%96/"},{"categories":["大数据技术"],"content":"4.2.2 匹配一个子主题或该子主题下的迭代子主题 第二个通配符是\u003e它将匹配一个或多个标记，并且只能出现在主题的末尾。例如，time.us.\u003e将匹配time.us.east和 time.us.east.atlanta，而 time.us.* 将只匹配 time.us.east，因为它不能匹配多个。 [外链图片转存失败,源站可能有防盗链机制,建议将图片保存下来直接上传(img-ZfhrPWEQ-1678191672332)(null)] ","date":"2023-06-06","objectID":"/spark%E5%8E%9F%E7%90%86%E5%8F%8A%E4%BC%98%E5%8C%96/:5:2","tags":["spark,大数据"],"title":"Spark原理及优化","uri":"/spark%E5%8E%9F%E7%90%86%E5%8F%8A%E4%BC%98%E5%8C%96/"},{"categories":["大数据技术"],"content":"4.2.3 监控和窃听 根据您的安全配置，通配符可以通过创建有时称为窃听的内容来用于监视。在最简单的情况下，您可以为\u003e创建订阅者``。此应用程序将接收在 NATS 群集上发送的所有消息（同样，受安全设置的约束）。 ","date":"2023-06-06","objectID":"/spark%E5%8E%9F%E7%90%86%E5%8F%8A%E4%BC%98%E5%8C%96/:5:3","tags":["spark,大数据"],"title":"Spark原理及优化","uri":"/spark%E5%8E%9F%E7%90%86%E5%8F%8A%E4%BC%98%E5%8C%96/"},{"categories":["大数据技术"],"content":"4.2.4 混合通配符 通配符*可以在同一主题中多次出现。这两种类型也可以使用。例如，*.*.east.\u003e将接收time.us.east.atlanta。 ","date":"2023-06-06","objectID":"/spark%E5%8E%9F%E7%90%86%E5%8F%8A%E4%BC%98%E5%8C%96/:5:4","tags":["spark,大数据"],"title":"Spark原理及优化","uri":"/spark%E5%8E%9F%E7%90%86%E5%8F%8A%E4%BC%98%E5%8C%96/"},{"categories":["大数据技术"],"content":"4.3 主题大小 建议将主题中的最大bit数量保持在最多 16 个bit的合理值。 ","date":"2023-06-06","objectID":"/spark%E5%8E%9F%E7%90%86%E5%8F%8A%E4%BC%98%E5%8C%96/:6:0","tags":["spark,大数据"],"title":"Spark原理及优化","uri":"/spark%E5%8E%9F%E7%90%86%E5%8F%8A%E4%BC%98%E5%8C%96/"},{"categories":["大数据技术"],"content":"4.4 发布-订阅 NATS 为一对多通信实现了发布-订阅消息分发模型。发布者发送有关主题的消息，侦听该主题的任何活动订阅者都会收到该消息。订阅者还可以注册对通配符主题的兴趣，NATS 是一个发布订阅消息传递系统基于主题.侦听某个主题的订阅者会收到有关该主题发布的消息。如果订阅者未主动侦听主题，则不会收到消息。订阅者可以使用通配符标记（如 *and\u003e）来匹配单个标记或匹配主题的尾部。 [外链图片转存失败,源站可能有防盗链机制,建议将图片保存下来直接上传(img-IiqJ55vW-1678191670642)(null)] ","date":"2023-06-06","objectID":"/spark%E5%8E%9F%E7%90%86%E5%8F%8A%E4%BC%98%E5%8C%96/:7:0","tags":["spark,大数据"],"title":"Spark原理及优化","uri":"/spark%E5%8E%9F%E7%90%86%E5%8F%8A%E4%BC%98%E5%8C%96/"},{"categories":["大数据技术"],"content":"4.5 消息 消息由以下部分组成： 一个主题。 字节数组形式的有效负载。 任意数量的header fields字段。 可选的’reply’地址字段。 消息具有最大大小（在服务器配置中使用max_payload 设置）。默认情况下，大小设置为 1 MB，但如果需要，可以增加到 64 MB（但我们建议将最大邮件大小保持在更合理的值，如 8 MB）。 ","date":"2023-06-06","objectID":"/spark%E5%8E%9F%E7%90%86%E5%8F%8A%E4%BC%98%E5%8C%96/:8:0","tags":["spark,大数据"],"title":"Spark原理及优化","uri":"/spark%E5%8E%9F%E7%90%86%E5%8F%8A%E4%BC%98%E5%8C%96/"},{"categories":["大数据技术"],"content":"4.6 请求-回复 请求-回复是现代分布式系统中的常见模式。发送请求，应用程序要么等待具有特定超时的响应，要么异步接收响应。 一般来说，消息系统是以异步的形式工作，也就是说，publisher 往 subject 上发布一条消息后，并不在意 subscriber 的 reply 是什么。如果 publisher 在意 subscriber 的 reply 是什么的话，那么消息系统就应该以同步的形式工作，在具体实现中，是通过两次发布订阅来完成的：当 publisher 发布消息后，它会订阅一个特定的 subject，当 subscriber 处理完消息后，它会把 reply 发布到这个特定的 subject。当然，整个过程对使用者是透明的。 NATS 使用其核心通信机制（发布和订阅）支持请求-回复模式。使用回复主题在给定主题上发布请求。响应者侦听该主题并将响应发送到回复主题。回复主题称为“收件箱”。这些是动态定向回请求者的唯一主题，无论任何一方位于何处。 ","date":"2023-06-06","objectID":"/spark%E5%8E%9F%E7%90%86%E5%8F%8A%E4%BC%98%E5%8C%96/:9:0","tags":["spark,大数据"],"title":"Spark原理及优化","uri":"/spark%E5%8E%9F%E7%90%86%E5%8F%8A%E4%BC%98%E5%8C%96/"},{"categories":["大数据技术"],"content":"4.6.1 NATS 使请求-回复变得简单而强大 多个 NATS 响应程序可以形成动态队列组。因此，无需在组内手动添加或删除订阅者，即可启动或停止分发消息。它是自动完成的。这允许响应者根据需求扩大或缩小规模。 NATS 应用程序“在退出之前耗尽”（在关闭连接之前处理缓冲的消息）。这允许应用程序在不丢弃请求的情况下缩减。 由于 NATS 基于发布-订阅，因此可观测性就像运行另一个应用程序一样简单，该应用程序可以查看请求和响应以测量延迟、监视异常、直接可伸缩性等。 NATS的强大功能甚至允许多个响应，其中第一个响应被利用，系统有效地丢弃额外的响应。这允许复杂的模式具有多个响应器，减少响应延迟和抖动。 无响应者 当请求发送到没有订阅者的主题时，可以方便地立即了解它。对于此用例，NATS 客户端可以选择加入no_responder消息.这需要支持标头的服务器和客户端。启用后，发送到没有订阅者的主题的请求将立即收到没有正文和503状态的回复。 大多数客户端将通过引发或返回错误来表示这种情况。例如： m, err := nc.Request(\"foo\", nil, time.Second); # err == nats.ErrNoResponders ","date":"2023-06-06","objectID":"/spark%E5%8E%9F%E7%90%86%E5%8F%8A%E4%BC%98%E5%8C%96/:9:1","tags":["spark,大数据"],"title":"Spark原理及优化","uri":"/spark%E5%8E%9F%E7%90%86%E5%8F%8A%E4%BC%98%E5%8C%96/"},{"categories":["大数据技术"],"content":"4.7 NATS在微服务中的应用 可以发现 request reply 模式已经有了 RPC 的味道。正是因为 NATS 具备了 RPC 的能力，所以在微服务中采用 NATS 后，系统会更清晰。 传统微服务架构 采用 NATS 的微服务架构 五、组队列 当订阅者注册自己以接收来自发布者的消息时，消息传递的 1：N 扇出模式可确保发布者发送的任何消息都能到达已注册的所有订阅者。NATS 提供了一个名为“队列”的附加功能，该功能允许订阅者将自己注册为队列的一部分。作为队列一部分的订阅者形成“队列组”。 ","date":"2023-06-06","objectID":"/spark%E5%8E%9F%E7%90%86%E5%8F%8A%E4%BC%98%E5%8C%96/:10:0","tags":["spark,大数据"],"title":"Spark原理及优化","uri":"/spark%E5%8E%9F%E7%90%86%E5%8F%8A%E4%BC%98%E5%8C%96/"},{"categories":["大数据技术"],"content":"队列组的工作原理 例如，考虑基于主题名称以 1：N 模式向所有订户传递邮件（甚至对不属于队列组的订户也会发生传递）。如果订阅者基于队列名称注册，它将始终根据主题名称接收其订阅的消息。但是，如果将更多订户添加到同一队列名称，则它们将成为队列组，并且每次队列组收到消息时，只有一个随机选择的队列组订户将使用一条消息。此类分布式队列是 NATS 提供的内置负载平衡功能。 优势 确保应用程序容错 工作负载处理可以纵向扩展或缩减 无需额外配置 队列组由应用程序及其队列订户定义，而不是由服务器配置定义 队列组名称遵循与科目最重要的是，它们区分大小写，不能包含空格。请考虑使用句点分层构建队列组。.某些服务器功能可以使用通配符匹配在他们身上。 队列订阅者是扩展服务的理想选择（订阅者队列是一个集群构成的消费者，集群分担消费消息，集群可随时拓展和缩减）。纵向扩展就像运行另一个应用程序一样简单，缩减是终止应用程序，并发出耗尽正在进行的请求的信号。这种灵活性和无需任何配置更改使 NATS 成为一种出色的服务通信技术，可以与所有平台技术配合使用。 ","date":"2023-06-06","objectID":"/spark%E5%8E%9F%E7%90%86%E5%8F%8A%E4%BC%98%E5%8C%96/:11:0","tags":["spark,大数据"],"title":"Spark原理及优化","uri":"/spark%E5%8E%9F%E7%90%86%E5%8F%8A%E4%BC%98%E5%8C%96/"},{"categories":["大数据技术"],"content":"无响应者 当向服务（请求/回复）发出请求并且 NATS 服务器知道没有可用的服务（因为队列组中当前没有订阅主题的客户端应用程序）时，服务器将向请求客户端发送“无响应者”协议消息，该消息将中断阻止 API 调用。这允许应用程序立即做出反应。这进一步支持大规模构建响应速度快的系统，即使面对应用程序故障和网络分区也是如此。 ","date":"2023-06-06","objectID":"/spark%E5%8E%9F%E7%90%86%E5%8F%8A%E4%BC%98%E5%8C%96/:11:1","tags":["spark,大数据"],"title":"Spark原理及优化","uri":"/spark%E5%8E%9F%E7%90%86%E5%8F%8A%E4%BC%98%E5%8C%96/"},{"categories":["大数据技术"],"content":"作为队列流式传输 跟捷流]还可以通过将保留策略设置为工作队列策略并利用流作为队列拉动消费者]轻松实现处理的水平可扩展性（或使用带有订阅者队列组的显式 ACK 推送使用者）。 [外链图片转存失败,源站可能有防盗链机制,建议将图片保存下来直接上传(img-7t1PYeSm-1678191672299)(null)] ","date":"2023-06-06","objectID":"/spark%E5%8E%9F%E7%90%86%E5%8F%8A%E4%BC%98%E5%8C%96/:12:0","tags":["spark,大数据"],"title":"Spark原理及优化","uri":"/spark%E5%8E%9F%E7%90%86%E5%8F%8A%E4%BC%98%E5%8C%96/"},{"categories":["大数据技术"],"content":"排队地理关联性 连接到全局分布式 NATS 超级群集时，由于如果群集上没有可用于本地处理请求的侦听器，则服务请求消息只会路由到另一个群集（即另一个区域），因此会自动存在服务异地相关性。 ​ ","date":"2023-06-06","objectID":"/spark%E5%8E%9F%E7%90%86%E5%8F%8A%E4%BC%98%E5%8C%96/:12:1","tags":["spark,大数据"],"title":"Spark原理及优化","uri":"/spark%E5%8E%9F%E7%90%86%E5%8F%8A%E4%BC%98%E5%8C%96/"},{"categories":["同态加密研究"],"content":"个人在信息安全作品赛的创新研究。","date":"2023-06-06","objectID":"/%E5%90%8C%E6%80%81%E5%8A%A0%E5%AF%86%E4%B8%AD%E6%97%A0%E7%AC%A6%E5%8F%B7%E6%95%B0%E6%AF%94%E8%BE%83%E5%A4%A7%E5%B0%8F%E7%9A%84%E7%A0%94%E7%A9%B6/","tags":["信息安全,同态加密"],"title":"同态加密中无符号数比较大小的研究","uri":"/%E5%90%8C%E6%80%81%E5%8A%A0%E5%AF%86%E4%B8%AD%E6%97%A0%E7%AC%A6%E5%8F%B7%E6%95%B0%E6%AF%94%E8%BE%83%E5%A4%A7%E5%B0%8F%E7%9A%84%E7%A0%94%E7%A9%B6/"},{"categories":["同态加密研究"],"content":"在我最近的做的一个同态里，常规的要排序需要将两数（鉴于核心技术看不到明文）相减，并且比较结果是否小于零来判断是否移位。而我所用的方案里第一步就要把数转换成无符号大整数ZZ_q类型，所以结果是不会输出负数的。那如何来判断两个数值未知的无符号数的大小呢。于是我写下本文来记录我所构造的几个方案。 核心思想——利用数值溢出来比较大小 虽然结果不会输出负数，但是无符号数会存在溢出的情况，比如一个无符号数的范围是在【0，2^16^】那么-1转换成无符号数后就会变成2^16 - 1这么大的数。于是，就可以利用这个数之大来判断两数的大小。 方案一 设有两数 a b （前提是a,b均小于且不等于2^16的一半大小） 如果有 a - b \u003e a + b 则 a \u003c b 例如 a = 3, b = 5 a - b = -2 a + b = 8 而在无符号数中 -2 是 2^16 - 2 这么大的数字，所以有 a - b \u003e a + b 如果 a = 5, b = 3时呢，那更不用说了，a - b 的结果只会是一个比 a+b 小的一个小整数。 这种方案虽然可行，但是还是效率太低了，因为比较两个数需要分别进行一次同态加减再解密比较大小。于是有了方案一的pro版。 方案二 我既然都限制了a,b都小于最大值的一半了,就可以把剩下一半都当作负数的范围。 这样做有啥好处呢？好处就是我可以只算 a - b,而不用算 a + b 了，a - b \u003e 2^15 就相当于 a - b \u003c 0 了。即 a \u003c b。 无论方案一和方案二都把原来的无符号数范围缩小到一半了，这不影响计算吗？ 确实影响。但是我的范围是可调的，如过我根据原来的范围就先扩大一倍，那计算时再缩小一倍就相当于没有影响了。当然因为我的范围它跟计算效率是没有关系的，我可以把最大值调的尽可能大，在条件允许的情况下越大越好。 前两种方案解决了比大小问题，但是最后都需要用私钥来解密后才能比大小，可以解决两者的比大小问题。而我的方案里服务器拿不到私钥才是最安全可信的。而且我比大小的目的也不是排序，我的根本目的是为了去除最大值与最小值。于是我又构造了一个不需要服务器拿到私钥且不需要密文之间排序的方案pro max…. ","date":"2023-06-06","objectID":"/%E5%90%8C%E6%80%81%E5%8A%A0%E5%AF%86%E4%B8%AD%E6%97%A0%E7%AC%A6%E5%8F%B7%E6%95%B0%E6%AF%94%E8%BE%83%E5%A4%A7%E5%B0%8F%E7%9A%84%E7%A0%94%E7%A9%B6/:0:0","tags":["信息安全,同态加密"],"title":"同态加密中无符号数比较大小的研究","uri":"/%E5%90%8C%E6%80%81%E5%8A%A0%E5%AF%86%E4%B8%AD%E6%97%A0%E7%AC%A6%E5%8F%B7%E6%95%B0%E6%AF%94%E8%BE%83%E5%A4%A7%E5%B0%8F%E7%9A%84%E7%A0%94%E7%A9%B6/"},{"categories":["语言学习"],"content":"go语言入门教程，精学请看其他篇。","date":"2023-06-06","objectID":"/go%E8%AF%AD%E8%A8%80%E5%85%A5%E9%97%A8/","tags":["golang"],"title":"Go语言入门学习","uri":"/go%E8%AF%AD%E8%A8%80%E5%85%A5%E9%97%A8/"},{"categories":["语言学习"],"content":"一.为什么需要go语言 其他编程语言的弊端。 硬件发展速度远远超过软件。 C语言等原生语言缺乏好的依赖管理(依赖头文件)。 Java和C+等语言过于笨重。 系统语言对垃圾回收和并行计算等基础功能缺乏支持。 对多核计算机缺乏支持。 Go语言是一个可以编译高效，支持高并发的，面向垃圾回收的全新语言。 秒级完成大型程序的单节点编译。 依赖管理清晰。 不支持继承，程序员无需花费精力定义不同类型之间的关系。 支持并发执行，支持多线程通讯。 对多核计算机支持友好。 自动垃圾回收 更丰富的内置类型 函数多返回值 错误处理 匿名函数和闭包 类型和接口 并发编程 反射 语言交互性 Go语言不支持的特性 不支持函数重载和操作符重载 为了避免在C/C++开发中的一些Bug和混乱，不支持隐式转换 支持接口抽象，不支持继承 不支持动态加载代码 不支持动态链接库 通过recover和panic来替代异常机制 不支持断言 不支持静态变量 [外链图片转存失败,源站可能有防盗链机制,建议将图片保存下来直接上传(img-y83xAJK8-1659583869067)(C:\\Users\\ZHAI\\AppData\\Roaming\\Typora\\typora-user-images\\image-20220723112727867.png)] 二、安装go 官网要进外网可能进不去 https://golang.org/dl/ 国内下载地址 Downloads - The Go Programming Language (google.cn) 下载安装包后选地方安装 配置环境变量 在d盘自建一个工作文件夹名字随意xxx，里面要创建三个文件夹分别名为bin,pkg,src 右键我的电脑-\u003e属性-\u003e高级系统设置-\u003e环境变量 在系统环境变量里新建一个名为GOROOT，目录为 go的安装目录 在用户变量里吧GOPATH的目录改到xxx 编辑系统环境变量的path， 加上一行%GOROOT%\\bin 再加上一行%GOPATH% 检验是否成功 win+r -\u003e 输cmd回车 -\u003e输go env回车 国内镜像配置 呼出命令行（快捷键 Win + R），输入cmd，执行下方两行命令 先输go env -w GO111MODULE=on回车 再输go env -w GOPROXY=https://goproxy.cn,direct回车 检验 go env 即安装成功 三、vscode配置go 打开vscode，安装一个Go插件，如下 按住Ctrl+Shift+P 输入Go:Install/Update Tools 点查看更多，全选后回车 显示安装完成。 在hello.go文件中编写go程序 从这里可以看出go文件的结构 package main // 包声明 import “fmt” // 引入包 func main() { // 函数 // 变量 fmt.Println(“hello World”) // 语句 \u0026 表达式 //注释 } 新建终端终端进入保存文件的目录后执行下面命令运行 （这里保存到桌面了） go run test.go 相关命令 go build xxx.go 编译生成二进制文件 Go语言不支持动态链接，因此编译时会将所有依赖编译进同一个二进制文件。 指定输出目录。go build -o bin/mybinary . go fmt 格式化go代码 go test单元测试 go test ./ … -v运行测试 go get 把项目所需依赖下载到本地 go install 在容器里直接编译源文件 go mod 语言管理 go tool 性能分析 go vet 代码静态检查，发现可能的bug或者可疑的构造 注意： 当标识符（包括常量、变量、类型、函数名、结构字段等等）以一个大写字母开头，如：Group1，那么使用这种形式的标识符的对象就可以被外部包的代码所使用（客户端程序需要先导入这个包），这被称为导出（像面向对象语言中的 public）；标识符如果以小写字母开头，则对包外是不可见的，但是他们在整个包的内部是可见并且可用的（像面向对象语言中的 protected ）。 需要注意的是 { 不能单独放在一行，所以以下代码在运行时会产生错误 package main import \"fmt\" func main() { // 错误，{ 不能在单独的行上 fmt.Println(\"Hello, World!\") } 在 Go 程序中，一行代表一个语句结束。每个语句不需要像 C 家族中的其它语言一样以分号 ; 结尾，因为这些工作都将由 Go 编译器自动完成。 如果你打算将多个语句写在同一行，它们则必须使用 ; 人为区分，但在实际开发中我们并不鼓励这种做法。 四、if 常规 if condition1 { } else if condition2{ } else { } 简短语句 —-支持在判断之前先声明一个变量 if v := x-100;v \u003c 0{ return v } 五、switch switch var1{ case val1: case val2: fallthrough//关键字代表执行下一个case case val3: f() default://默认分支 ... } 六、for go只有for循环没有while循环 原始for循环 for i:=0;i\u003c10;i++{ sum+=1 } 初始化语句和后置语句可选，与while等价 for;sum\u003c1000;{ sum+=sum } 无限循环 for{ if true { break } } for-range 遍历数组，切片，字符串，map等 for index,char:=range muString{ ... } for key,value:=range MyMap{ ... } for index,value:=range MyArray{ ... } 循环控制语句 break：经常用于中断当前 for 循环或跳出 switch 语句 continue: 跳过当前循环的剩余语句，然后继续进行下一轮循环。 goto: 将控制转移到被标记的语句 七、变量与常量 常量 const identifier type 变量 var identifier type ","date":"2023-06-06","objectID":"/go%E8%AF%AD%E8%A8%80%E5%85%A5%E9%97%A8/:0:0","tags":["golang"],"title":"Go语言入门学习","uri":"/go%E8%AF%AD%E8%A8%80%E5%85%A5%E9%97%A8/"},{"categories":["语言学习"],"content":"特殊常量iota 可以认为是一个可以被编译器修改的常量。 iota 在 const关键字出现时将被重置为 0(const 内部的第一行之前)，const 中每新增一行常量声明将使 iota 计数一次(iota 可理解为 const 语句块中的行索引)。 iota 可以被用作枚举值： const ( a = iota b = iota c = iota ) 第一个 iota 等于 0，每当 iota 在新的一行被使用时，它的值都会自动加 1；所以 a=0, b=1, c=2 可以简写为如下形式： const ( a = iota b c ) ","date":"2023-06-06","objectID":"/go%E8%AF%AD%E8%A8%80%E5%85%A5%E9%97%A8/:1:0","tags":["golang"],"title":"Go语言入门学习","uri":"/go%E8%AF%AD%E8%A8%80%E5%85%A5%E9%97%A8/"},{"categories":["语言学习"],"content":"iota 用法 package main import \"fmt\" func main() { const ( a = iota //0 b //1 c //2 d = \"ha\" //独立值，iota += 1 e //\"ha\" iota += 1 f = 100 //iota +=1 g //100 iota +=1 h = iota //7,恢复计数 i //8 ) fmt.Println(a,b,c,d,e,f,g,h,i) //0 1 2 ha ha 100 100 7 8 } ","date":"2023-06-06","objectID":"/go%E8%AF%AD%E8%A8%80%E5%85%A5%E9%97%A8/:1:1","tags":["golang"],"title":"Go语言入门学习","uri":"/go%E8%AF%AD%E8%A8%80%E5%85%A5%E9%97%A8/"},{"categories":["语言学习"],"content":"变量定义 变量声明 var语句用于声明一个变量列表，跟函数的参数列表一样，类型在最后。 可以一次声明多个变量 var c, python, java bool 变量初始化 变量声明可以包含初始值，每个变量对应一个。 如果初始化值已存在，则可以省略类型; 如果没有初始化，则变量默认为零值。bool 零值为 false,字符串为 \"\" 变量会从初始值中获得类型。var i, j int= 1, 2 短变量声明 在函数中，简洁赋值语句:=可在类型明确的地方代替var声明。 函数外的每个语句都必须以关键字开始（var, func等等) 因此:=结构不能在函数外使用。 如果变量已经使用 var 声明过了，再使用 *:=* 声明变量，就产生编译错误 短变量声明时不需要声明数据类型，由go自动推导。 c, python, java := true, false, “no!” ","date":"2023-06-06","objectID":"/go%E8%AF%AD%E8%A8%80%E5%85%A5%E9%97%A8/:2:0","tags":["golang"],"title":"Go语言入门学习","uri":"/go%E8%AF%AD%E8%A8%80%E5%85%A5%E9%97%A8/"},{"categories":["语言学习"],"content":"类型转换与推导 隐式转换有风险出错，所以go只有强制转换 ","date":"2023-06-06","objectID":"/go%E8%AF%AD%E8%A8%80%E5%85%A5%E9%97%A8/:3:0","tags":["golang"],"title":"Go语言入门学习","uri":"/go%E8%AF%AD%E8%A8%80%E5%85%A5%E9%97%A8/"},{"categories":["语言学习"],"content":"类型转换 表达式T(v)将值v转换为类型T。 一些关于数值的转换: var i int = 42 var i int = 42 var f float64 = float64(i) var u uint = uint(f) 或者，更加简单的形式: i :=42 f := float64(i) u := uint(f) ","date":"2023-06-06","objectID":"/go%E8%AF%AD%E8%A8%80%E5%85%A5%E9%97%A8/:3:1","tags":["golang"],"title":"Go语言入门学习","uri":"/go%E8%AF%AD%E8%A8%80%E5%85%A5%E9%97%A8/"},{"categories":["语言学习"],"content":"类型推导 在声明一个变量而不指定其类型时（即使用不带类型的:=语法或var=表达式语法)，变量的类型由右值推导得出。 var i int j = i // j 就也是一个 int 八、数组 相同类型且长度固定连续内存片段，以编号访问每个元素 定义方法 var identifier [len]type 示例 myArray := [3]int{1,2,3} 如果数组长度不确定，可以使用 … 代替数组的长度，编译器会根据元素个数自行推断数组的长度： var balance = [...]float32{1000.0, 2.0, 3.4, 7.0, 50.0} 或 balance := [...]float32{1000.0, 2.0, 3.4, 7.0, 50.0} 九、Make和New New 返回指针地址 Make返回第一个元素，可预设内存空间 mySlice1 :=new([]int) mySlice2 := make([]int, 0) Slice3 := make([]int, 10) mySlice4 := make([]int, 10,20) //第一个参数是数组，第二个参数是初始多大，第三个参数是最大长度。 //填0时后两项全交给系统管理 十、切片 语言切片是对数组的抽象，切片是对数组一个连续片段的引用，数组定义中不指定长度即为切片（不定长数组或动态数组） 可以声明一个未指定大小的数组来定义切片，切片不需要说明长度。 var identifier []type 切片在未初始化之前默认为nil，长度为0 或使用 make() 函数来创建切片: var slice1 []type = make([]type, len) 也可以简写为 slice1 := make([]type, len) 也可以指定容量，其中 capacity 为可选参数 make([]T, length, capacity) 默认 endIndex 时将表示一直到arr的最后一个元素。 s := arr[:endIndex] 默认 startIndex 时将表示从 arr 的第一个元素开始。 s1 := s[startIndex:endIndex] 将 arr 中从下标 startIndex 到 endIndex-1 下的元素创建为一个新的切片。 s := arr[startIndex:endIndex] 通过切片 s 初始化切片 s1。 s :=make([]int,len,cap) 切片是可索引的，并且可以由 len() 方法获取长度。 切片提供了计算容量的方法 cap() 可以测量切片最长可以达到多少。 myArray :=[]int{1,2，3，4，5} //切片截取 myslice := myArray [1:3] myslice1 := []int{} //代码描述了从拷贝切片的 copy 方法和向切片追加新元素的 append 方法。 /* 向切片添加一个元素 */ myslice1 =append(myslice1,1) /* 同时添加多个元素 */ myslice1 = append(myslice1,2,8,3,4) /* 拷贝 myslice1 的内容到 myArray */ copy(myArray,myslice1) //不需要管切片长度，但是没有原生的删除方法 切片删除 func main(){ myArray := [5]int{1,2,3,4,5} mySlice := myArray[1:3] fmt.Printf(\"mySlice %+v\\n\" , mySlice) fullSlice := myArray[:] remove3rdltem := deleteltem(fullSlice, 2) fmt.Printf(\"remove3rdltem %+v\\n\",remove3rdltem) ) func deleteltem(slice []int, index int)[]int { return append(slice[:index], slice[index+1:]...) } 注意：go语言里全部都是值传递，下面第一种改变切片的方式错误 func main() { myslice :=[]int{10,20，30，40，50} for _, value := range myslice { value = 2 } fmt.Printf( \"myslice %+vin\", myslice) } //这样才是对的 func main() { myslice :=[]int{10,20，30，40，50} for index := range myslice { myslice[index] 2 } fmt.Printf( \"\"myslice +v\\n\", myslice) } //range也可以用来枚举 Unicode 字符串。第一个参数是字符的索引，第二个是字符（Unicode的值）本身。 for i, c := range \"go\" { fmt.Println(i, c) } fmt作用 fmt.println(\"aaa\",\"bbb\",'cc')// 打印一行 fmt.printf(\"message %s%s%s\\n\",\"a\",\"b\",\"c\")//按值打印 fmt.Sprintf()//拼接字符串 var stockcode=123 var enddate=\"2020-12-31\" var url=\"Code=%d\u0026endDate=%s\" var target_url=fmt.Sprintf(url,stockcode,enddate) fmt.Println(target_url) //Code=123\u0026endDate=2020-12-31 fmt.Errorf() 十一、MAP key-value的组合 定义格式 myMap := make(map[string]string,10) //value可以是复杂类型的 myFuncMap := map[string] func() int{ \"funcA\": func() int { return 1 }, } // 这里的value是一个函数类型的 赋值 myMap[\"a\"] = \"b\" 取值 //按key取值 value,exists := myMap[\"a\"]//会有两个值，exists是布尔型的，判断是否存在值 if exists { println(value) } //遍历取值，前一个是key后是value for k, v := range myMap { println(k,v) } delete() 函数用于删除集合的元素, 参数为 map 和其对应的 key。实例如下： 十二、结构体和指针 通过type … struct关键字自定义结构体 Go语言支持指针，但不支持指针运算 指针变量的值为内存地址 未赋值的指针为nil type Human struce { firstName, lastName string } 十三、结构体标签 结构体中的字段除了有名字和类型外，还可以有一个可选的标签(tag)相当于key - value的key 使用场景:Kubernetes APlServer对所有资源的定义都用Json tag和protoBuff tag NodeName string ‘ison:“nodeName,omitempty” protobuf:“bytes,10.opt,name=nodeName” type MyType struct { Name string 'json:\"name\"' } func main(){ mt := MyType{Name: \"test\"} myType := reflect.TypeOf(mt) name := myType.Field(0) tag := name.Tag.Get(\"json\") println(tag) } 十四、自定义类型与类型别名 自定义类型 自定义类型是 定义了一个全新的类型 。我们可以基于内置的基本类型定义，也可以通过 struct 定义。例如： //将类型MyInt定义为int类型 type MyInt int 此时MyInt就是一种新的类型，它具有 int 的特性。 实际上，Go语言中的结构体类型就是一种自定义类型。 类型别名 比自定义类型的格式多一个 = type TypeA = Type TypeA只是Type的别名，本质上TypeA与Type是同一个类型。 两者的区别 package main import ( \"fmt\" ) //类型定义 type NewInt int //类型别名 type MyInt = int func main() { var a NewInt var b MyInt fmt.Printf(\"type of a:%T\\n\", a) //type of a:main.NewInt fmt.Printf(\"type of b:%T\\n\", b) //type of b:int } 输出 type of a:main.NewInt type of b:int a的类型是main.NewInt，表示main包下定义的NewInt类型。这是一个新的数据类型。 b的类型是int。MyInt类型别名只会在代码中存在，编译完成时并不会有MyInt类型。 十五、函数 len() 函数可以接受不同类型参数并返回该类型的长度。如果我们传入的是字符串则返回字符串的长度，","date":"2023-06-06","objectID":"/go%E8%AF%AD%E8%A8%80%E5%85%A5%E9%97%A8/:3:2","tags":["golang"],"title":"Go语言入门学习","uri":"/go%E8%AF%AD%E8%A8%80%E5%85%A5%E9%97%A8/"},{"categories":["杂项"],"content":"个人杂学杂记","date":"2023-06-06","objectID":"/%E6%97%A5%E5%BF%97%E5%88%86%E6%9E%90/","tags":["信息安全"],"title":"日志分析","uri":"/%E6%97%A5%E5%BF%97%E5%88%86%E6%9E%90/"},{"categories":["杂项"],"content":"@[toc] 1.流量与日志分析 日志，是作为记录系统与服务最直接有效的方法。在日志中，可 以发现访问记录以及发现攻击线索。日志分析也是最常用的分析安全 事件所采用的途径。系统日志和 web 日志分别记录了不同内容，为分析 攻击提供了有效证据。网络流量分析，也是作为排查安全事件所能获 得的有效证据，通过学习，学员可以了解系统和服务的主要日志，并能够通过分析获取攻击线索。 ","date":"2023-06-06","objectID":"/%E6%97%A5%E5%BF%97%E5%88%86%E6%9E%90/:0:0","tags":["信息安全"],"title":"日志分析","uri":"/%E6%97%A5%E5%BF%97%E5%88%86%E6%9E%90/"},{"categories":["杂项"],"content":"1.1系统日志分析 ","date":"2023-06-06","objectID":"/%E6%97%A5%E5%BF%97%E5%88%86%E6%9E%90/:1:0","tags":["信息安全"],"title":"日志分析","uri":"/%E6%97%A5%E5%BF%97%E5%88%86%E6%9E%90/"},{"categories":["杂项"],"content":"1.1.1window系统日志与分析方法 前提:开启审核策略，若日后系统出现故障、安全事故则可以查看系统的日志文件、排除故障，追查入侵者的信息等。 快捷 Win+R打开运行 → 输入 gpedit.msc 回车 → 计算机配置 → Windows 设置 → 安全设置 → 本地策略 → 审核策略。 查看日志 Win+R打开运行，输入“eventvwr.msc”，回车运行，打开“事件查看器”。 ![在这里插入图片描述](https://img-blog.csdnimg.cn/7646d596b6c444a5a9ec5af32dfebcb3.png) 筛选查看 系统日志：记录操作系统组件产生的事件，主要包括驱动程序、系统组件和应用软件的崩溃以及数据丢失错误等。默认存放路径：%SystemRoot%\\System32\\Winevt\\Logs\\System.evtx 安全日志：记录系统的安全审计事件，包含各种类型的登录日志、对象访问日志、进程追踪日志、特权使用、帐号管理、策略变更、系统事件。这个日志一般是安全工程师重点关注对象。 默认存放路径：%SystemRoot%\\System32\\Winevt\\Logs\\Security.evtx 应用程序日志： 包含由应用程序或系统程序记录的事件，主要记录程序运行方面的事件， 默认存放路径：%SystemRoot%\\System32\\Winevt\\Logs\\Application.evtx。 对于Windows事件日志分析，不同的EVENT ID代表了不同的意义，摘录一些常见的安全事件的说明 4624 --登录成功 4625 --登录失败 4634 -- 注销成功 4647 -- 用户启动的注销 4672 -- 使用超级用户（如管理员）进行登录 分析工具 Log Parser（是微软公司出品的日志分析工具，它功能强大，使用简单，可以分析基于文本的日志文件、XML 文件、CSV（逗号分隔符）文件，以及操作系统的事件日志、注册表、文件系统、Active Directory。它可以像使用 SQL 语句一样查询分析这些数据，甚至可以把分析结果以各种图表的形式展现出来。 Log Parser 2.2下载地址：https://www.microsoft.com/en-us/download/details.aspx?id=24659 Log Parser 使用示例：https://mlichtenberg.wordpress.com/2011/02/03/log-parser-rocks-more-than-50-examples/查看日志的重点 分析重点： ①查看登录日志中暴力破解痕迹； ②查看账号管理日志中账号的新增、修改痕迹； ③查看远程桌面登录日志中的登录痕迹。 暴力破解账密日志 攻击者通过暴力破解的方式入侵系统，不论是否成功，在日志中会留下入侵痕迹，所以事件id为4624和4625的事件是首当其冲的关注点。需要留意日志中的SubjectUserNameIpAddress。 入侵事件 发现连续三条日志，由登录失败到成功，WorkstationName均来自名为kali的主机，并且最终记录下kali的IP地址为192.168.74.129。这个过程可以判断攻击者通过192.168.74.129的主机暴力破解成功administrator的密码，此处即为暴破留下的痕迹 账号管理日志 Windows中日志中与账号创建有关的事件ID：4720, 4722, 4724,4738。攻击者攻陷一台Windows主机后，可能会创建后门账号、隐藏账号 远程桌面登录日志 上述的安全日志很可能被覆盖掉，为尽量不遗漏入侵痕迹，可进一步查看远程桌面的登录日志。攻击者建立后门账号后会通过远程桌面连接到失陷主机上，此时的登录行为会记录到远程桌面日志。 远程连接日志（应用程序和服务日志-\u003eMicrosoft-\u003eWindows-\u003e-TerminalServices-\u003eRemoteConnectionManager-\u003eOperational），重要事件 ID 和含义： 1149：用户认证成功 21：远程桌面服务：会话登录成功 24：远程桌面服务：会话已断开连接 25：远程桌面服务：会话重新连接成功 因此我们可以看看应用程序日志里事件id为1149： ","date":"2023-06-06","objectID":"/%E6%97%A5%E5%BF%97%E5%88%86%E6%9E%90/:1:1","tags":["信息安全"],"title":"日志分析","uri":"/%E6%97%A5%E5%BF%97%E5%88%86%E6%9E%90/"},{"categories":["杂项"],"content":"1.1.2linux 系统日志与分析方法 Linux系统拥有非常灵活和强大的日志功能，可以保存几乎所有的操作记录，并可以从中检索出我们需要的信息。 大部分Linux发行版默认的日志守护进程为 syslog，位于 /etc/syslog 或 /etc/syslogd 或/etc/rsyslog.d，默认配置文件为 /etc/syslog.conf 或 rsyslog.conf，任何希望生成日志的程序都可以向 syslog 发送信息。 Linux系统内核和许多程序会产生各种错误信息、警告信息和其他的提示信息，这些信息对管理员了解系统的运行状态是非常有用的，所以应该把它们写到日志文件中去。完成这个过程的程序就是syslog。syslog可以根据日志的类别和优先级将日志保存到不同的文件中。 默认配置下，日志文件通常都保存在“/var/log”目录下。 常见的日志类型，但并不是所有的Linux发行版都包含这些类型 常见的日志优先级: 系统日志是由一个名为syslog的服务管理的，如以下日志文件都是由syslog日志服务驱动的： /var/log/boot.log：录了系统在引导过程中发生的事件，就是Linux系统开机自检过程显示的信息 /var/log/lastlog ：记录最后一次用户成功登陆的时间、登陆IP等信息 /var/log/messages ：记录Linux操作系统常见的系统和服务错误信息 /var/log/secure ：Linux系统安全日志，记录用户和工作组变坏情况、用户登陆认证情况 /var/log/btmp ：记录Linux登陆失败的用户、时间以及远程IP地址 /var/log/syslog：只记录警告信息，常常是系统出问题的信息，使用lastlog查看 /var/log/wtmp：该日志文件永久记录每个用户登录、注销及系统的启动、停机的事件，使用last命令查看 /var/run/utmp：该日志文件记录有关当前登录的每个用户的信息。如 who、w、users、finger等就需要访问这个文件 /var/log/syslog 或 /var/log/messages 存储所有的全局系统活动数据，包括开机信息。基于 Debian 的系统如 Ubuntu 在/var/log/syslog 中存储它们，而基于 RedHat 的系统如 RHEL 或 CentOS 则在 /var/log/messages 中存储它们。 /var/log/auth.log 或 /var/log/secure 存储来自可插拔认证模块(PAM)的日志，包括成功的登录，失败的登录尝试和认证方式。Ubuntu 和 Debian 在 /var/log/auth.log 中存储认证信息，而 RedHat 和 CentOS 则在 /var/log/secure 中存储该信息。 ","date":"2023-06-06","objectID":"/%E6%97%A5%E5%BF%97%E5%88%86%E6%9E%90/:1:2","tags":["信息安全"],"title":"日志分析","uri":"/%E6%97%A5%E5%BF%97%E5%88%86%E6%9E%90/"},{"categories":["杂项"],"content":"1.2 web日志分析 Web访问日志记录了Web服务器接收处理请求及运行时错误等各种原始信息。通过对WEB日志进行的安全分析，不仅可 以帮助我们定位攻击者，还可以帮助我们还原攻击路径，找到网站存在的安全漏洞并进行修复。 ","date":"2023-06-06","objectID":"/%E6%97%A5%E5%BF%97%E5%88%86%E6%9E%90/:2:0","tags":["信息安全"],"title":"日志分析","uri":"/%E6%97%A5%E5%BF%97%E5%88%86%E6%9E%90/"},{"categories":["杂项"],"content":"iis 日志分析方法 与开发阶段不同的，运维阶段不可能让你去调试程序，发现各类问题， 我们只能通过各种系统日志来分析网站的运行状况， 对于部署在IIS上的网站来说，IIS日志提供了最有价值的信息，我们可以通过它来分析网站的响应情况，来判断网站是否有性能问题， 或者存在哪些需要改进的地方 这里面记录了： 请求发生在什么时刻， 哪个客户端IP访问了服务端IP的哪个端口， 客户端工具是什么类型，什么版本， 请求的URL以及查询字符串参数是什么， 请求的方式是GET还是POST， 请求的处理结果是什么样的：HTTP状态码，以及操作系统底层的状态码， 请求过程中，客户端上传了多少数据，服务端发送了多少数据， 请求总共占用服务器多长时间、等等。 有个叫 Log Parser 的工具就可以专门解析IIS日志，我们可以用它来查看日志中的信息。 建议选择输出格式为 SQL 。 注意：这里的SQL并不是指SQLSERVER，而是指所有提供ODBC访问接口的数据库。 我可以使用下面的命令将IIS日志导入到SQLSERVER中（说明：为了不影响页面宽度我将命令文本换行了）： \"C:\\Program Files\\Log Parser 2.2\\logparser.exe\" \"SELECT * FROM 'D:\\Temp\\u_ex130615.log' to MyMVC_WebLog\" -i:IISW3C -o:SQL -oConnString:\"Driver={SQL Server};server=localhost\\sqlexpress;database=MyTestDb;Integrated Security=SSPI\" -createtable:ON 导入完成后，我们就可以用熟悉的SQLSERVER来做各种查询和统计分析了，例如下面的查询： SELECT cip,csmethod,sport,csuristem,scstatus,scwin32status,scbytes,csbytes,timetaken FROM dbo.MyMVC_WebLog ![](https://img-blog.csdnimg.cn/421c547a12b34e7a9f68bd1290ae460d.png) 注意： IIS日志在将结果导出到SQLSERVER时，字段名中不符合标识符规范的字符将会删除。 例如：c-ip 会变成 cip， s-port 会变成 sport 。 IIS日志中记录的时间是UTC时间，而且把日期和时间分开了，导出到SQLSERVER时，会生成二个字段： 对于一个ASP.NET程序来说，如果抛出一个未捕获异常，会记录到IIS日志中（500）， 本文所说的异常可分为四个部分： 1.（ASP.NET）程序抛出的未捕获异常，导致服务器产生500的响应输出。 2.404之类的请求资源不存在错误。 3.大于500的服务器错误，例如：502，503 4.系统错误或网络传输错误。 前三类异常可以用下面的查询获得： select scStatus, count(*) AS count, sum(timetaken * 1.0) /1000.0 AS sum_timetaken_second from MyMVC_WebLog with(nolock) group by scStatus order by 3 desc ","date":"2023-06-06","objectID":"/%E6%97%A5%E5%BF%97%E5%88%86%E6%9E%90/:2:1","tags":["信息安全"],"title":"日志分析","uri":"/%E6%97%A5%E5%BF%97%E5%88%86%E6%9E%90/"},{"categories":["杂项"],"content":"apache日志分析 如果apache的安装时采用默认的配置,那么在/logs目录下就会生成两个文件,分别是access_log和error_log access_log CustomLog “| /usr/sbin/rotatelogs /var/log/apache2/%Y_%m_%d_other_vhosts_access.log 86400 480” vhost_combined 通过CustomLog指令,每天一天生成一个独立的日志文件,同时也写了定时器将一周前的日志文件全部清除,这样可以显得更清晰,既可以分离每一天的日志又可以清除一定时间以前的日志通过制,LogFormat定义日志的记录格式 下面是一条经典的访问记录 101.226.168.195 - - [17/Oct/2014:16:46:11 +0800] \"GET /actkaijiang/3dinfo.html HTTP/1.1\" 200 9678 \"http://www.yicp.com/actkaijiang/3dinfo.html\" \"Mozilla/5.0 (Windows NT 6.1) AppleWebKit/537.1 (KHTML, like Gecko) Chrome/21.0.1180.89 Safari/537.1; 360Spider\" 一共是有9项,将他们一一拆开 101.226.168.195 - - [17/Oct/2014:16:46:11 +0800] \"GET /actkaijiang/3dinfo.html HTTP/1.1\" 200 9678 \"http://www.yicp.com/actkaijiang/3dinfo.html\" \"Mozilla/5.0 (Windows NT 6.1) AppleWebKit/537.1 (KHTML, likeGecko)Chrome/21.0.1180.89Safari/537.1;360Spider\" (1) 101.226.168.195 这是一个请求到apache服务器的客户端ip,默认的情况下,第一项信息只是远程主机的ip地址,但我们如果需要apache查出主机的名字,可以将 HostnameLookups设置为on,但这种做法是不推荐使用,因为它大大的减缓了服务器.另外这里的ip地址不一定就是客户主机的ip地址,如果 客户端使用了代理服务器,那么这里的ip就是代理服务器的地址,而不是原机. (2) - 这一项是空白,使用\"-“来代替,这个位置是用于标注访问者的标示,这个信息是由identd的客户端存在,除非IdentityCheck为on,非则apache是不会去获取该部分的信息( (3) - 这一项又是为空白,不过这项是用户记录用户HTTP的身份验证,如果某些网站要求用户进行身份雁阵,那么这一项就是记录用户的身份信息 (4） [17/Oct/2014:16:46:11 +0800] 第四项是记录请求的时间,格式为[day/month/year:hour:minute:second zone],最后的+0800表示服务器所处的时区为东八区 (5)“GET /actkaijiang/3dinfo.html HTTP/1.1” 这一项整个记录中最有用的信息,首先,它告诉我们的服务器收到的是一个GET请求,其次,是客户端请求的资源路径,第三,客户端使用的协议时HTTP/1.1,整个格式为”%m %U%q %H\",即\"请求方法/访问路径/协议\" (6) 200 这是一个状态码,由服务器端发送回客户端,它告诉我们客户端的请求是否成功,或者是重定向,或者是碰到了什么样的错误,这项值为200，表示服务器已经成 功的响应了客户端的请求,一般来说,这项值以2开头的表示请求成功,以3开头的表示重定向,以4开头的标示客户端存在某些的错误,以5开头的标示服务器端 存在某些错误, (9)9678这项表示服务器向客户端发送了多少的字节,在日志分析统计的时侯,把这些字节加起来就可以得知服务器在某点时间内总的发送数据量是多少 (10) - http://www.yicp.com/actkaijiang/3dinfo.html 表示请求来源 (11)\"*Mozilla/5.0 (Windows NT 6.1) AppleWebKit/537.1 (KHTML, like Gecko) Chrome/21.0.1180.89 Safari/537.1; 360Spider*\" 这项主要记录客户端的浏览器信息 error_log error_log为错误日志,记录下任何错误的处理请求,它的位置和内容由ErrorLog指令控制,通常服务器出现什么错误,首先对它进行查阅,是一个最重要的日志文件 tail error_log,随意摘取一个记录 [Fri Dec 10 15:03:59 2010] [error] [client 218.19.140.242] File does not exist: /home/htmlfile/tradedata/favicon.ico 同样也是分为几个项 [Fri Dec 10 15:03:59 2010] [error] [client 218.19.140.242] File does not exist: /home/htmlfile/tradedata/favicon.ico 1.[Fri Dec 10 15:03:59 2010] 记录错误发生的时间,注意,它跟我们上面access_log记录的时间格式是不同的 [error] 这一项为错误的级别,根据LogLevel指令来控制错误的类别,上面的404是属于error级别 [client 218.19.140.242] 记录客户端的ip地址 File does not exist: /home/htmlfile/tradedata/favicon.ico 这一项首先对错误进行了描述,例如客户端访问一个不存在或路径错误的文件,就会给出404的提示错误 了解日志的各种定义后,这里分享一下从网上淘来的一些对日志分析的脚本 1.查看apache的进程数 ps -aux | grep httpd | wc -l 2.分析日志查看当天的ip连接数 cat default-access_log | grep \"10/Dec/2010\" | awk '{print $2}' | sort | uniq -c | sort -nr 3.查看指定的ip在当天究竟访问了什么url cat default-access_log | grep \"10/Dec/2010\" | grep \"218.19.140.242\" | awk '{print $7}' | sort | uniq -c | sort -nr 4.查看当天访问排行前10的url cat default-access_log | grep \"10/Dec/2010\" | awk '{print $7}' | sort | uniq -c | sort -nr | head -n 10 5.看到指定的ip究竟干了什么 cat default-access_log | grep 218.19.140.242 | awk '{print $1\"\\t\"$8}' | sort | uniq -c | sort -nr | less 6.查看访问次数最多的几个分钟(找到热点) awk '{print $4}' default-access_log |cut -c 14-18|sort|uniq -c|sort -nr|head ","date":"2023-06-06","objectID":"/%E6%97%A5%E5%BF%97%E5%88%86%E6%9E%90/:2:2","tags":["信息安全"],"title":"日志分析","uri":"/%E6%97%A5%E5%BF%97%E5%88%86%E6%9E%90/"},{"categories":["杂项"],"content":"nginx日志分析 Nginx是一个高性能的HTTP和反向代理服务器。Nginx access日志记录了web应用的访问记录。大致记录了访问方式（POST/GET）、客户端IP、远程用户、请求时间、请求状态码、访问host地址、请求页面大小、reffer信息、x_forwarded_for地址等等。nginx access日志的格式不是一成不变的，是可以自定义的。Nginx access具体日志格式与在服务器的存储位置可以查看nginx.conf配置文件。Nginx详细记录了每一次web请求。 log_format combined '$remote_addr - $remote_user [$time_local] ' ' \"$request\" $status $body_bytes_sent ' ' \"$http_referer\" \"$http_user_agent\" '; 如果nginx位于负载均衡器，squid，nginx反向代理之后，web服务器无法直接获取到客户端真实的IP地址了。 $remote_addr获取反向代理的IP地址。反向代理服务器在转发请求的http头信息中，可以增加X-Forwarded-For信息，用来记录客户端IP地址和客户端请求的服务器地址。 下面是修改后，生产环境下代理服务器用的日志格式。可以根据需要添加对应的日志参数 log_format main '$remote_addr - $remote_user [$time_local] requesthost:\"$http_host\"; \"$request\" requesttime:\"$request_time\"; ' '$status $body_bytes_sent \"$http_referer\" - $request_body' '\"$http_user_agent\" \"$http_x_forwarded_for\"'; 二：Nginx日志参数详解 参数注释如下： $remote_addr #与$http_x_forwarded_for 用以记录客户端的ip地址 $http_x_forwarded_for #当前端有代理服务器时，设置web节点记录客户端地址的配置，此参数生效的前提是代理服务器也要进行相关的http_x_forwarded_for设置 $remote_user #记录客户端用户名称,一般默认为空 $time_local #记录访问时间 $request #记录请求的URL和HTTP协议 $status #记录请求状态 $body_bytes_sent #记录发送给客户端文件内容大小 $http_referer #记录从哪个页面链接访问过来的 $http_user_agent #记录客户端浏览器相关信息 $request_time #处理完请求所花时间，以秒为单位 $http_host #请求地址，即浏览器中你输入的地址(IP或域名) $request_body #记录POST数据 $request_length #客户端请求的长度 $upstream_status #upstream状态，成功是200 $upstream_addr #后台upstream的地址，即真正提供服务的主机地址 $upstream_response_time #请求过程中，upstream响应时间 Nginx日志常用分析命令示范(注：日志的格式不同，awk取的项不同。下面命令针对上面日志格式执行) 1)总请求数 wc -l access.log |awk '{print $1}' 2)独立IP数 awk '{print $1}' access.log|sort |uniq |wc -l 3)每秒客户端请求数 TOP5 awk '{print $6}' access.log|sort|uniq -c|sort -rn|head -5 4)访问最频繁IP Top5 awk '{print $1}' access.log|sort |uniq -c |sort -nr |head -5 5)访问最频繁的URL TOP5 awk '{print $7}' access.log|sort |uniq -c |sort -nr |head -5 6)响应大于5秒的URL TOP5 awk '{if ($7 \u003e 5){print $6}}' access.log|sort|uniq -c|sort -rn |head -5 7)HTTP状态码(非200)统计 Top5 awk '{if ($11 != 200){print $11}}' access.log|sort|uniq -c|sort -rn|head -5 8)分析请求数大于50000的源IP cat access.log|awk '{print $NF}'|sort |uniq -c |sort -nr|awk '{if ($1 \u003e50000){print $2}}' ","date":"2023-06-06","objectID":"/%E6%97%A5%E5%BF%97%E5%88%86%E6%9E%90/:2:3","tags":["信息安全"],"title":"日志分析","uri":"/%E6%97%A5%E5%BF%97%E5%88%86%E6%9E%90/"},{"categories":["杂项"],"content":"tomcat 日志分析 这些日志文件的产生是在tomcat/conf/logging.properties中配置的 Tomcat 日志信息分 为 两 类 ： 一是运行中的日志，它主要 记录 运行的一些信息，尤其是一些异常 错误 日志信息 。 二是 访问 日志信息，它 记录 的 访问 的 时间 ， IP ， 访问 的 资 料等相 关 信息。 ","date":"2023-06-06","objectID":"/%E6%97%A5%E5%BF%97%E5%88%86%E6%9E%90/:2:4","tags":["信息安全"],"title":"日志分析","uri":"/%E6%97%A5%E5%BF%97%E5%88%86%E6%9E%90/"},{"categories":["杂项"],"content":"主流日志分析工具使用","date":"2023-06-06","objectID":"/%E6%97%A5%E5%BF%97%E5%88%86%E6%9E%90/:2:5","tags":["信息安全"],"title":"日志分析","uri":"/%E6%97%A5%E5%BF%97%E5%88%86%E6%9E%90/"},{"categories":["数据结构"],"content":"课设选用java实现二叉树，未用引用类型，全部使用递归实现。","date":"2023-06-06","objectID":"/java%E8%AF%AD%E8%A8%80%E7%94%9F%E6%88%90%E7%AE%97%E6%95%B0%E8%A1%A8%E8%BE%BE%E5%BC%8F%E4%BA%8C%E5%8F%89%E6%A0%91/","tags":["java,数据结构"],"title":"Java语言生成算数表达式二叉树","uri":"/java%E8%AF%AD%E8%A8%80%E7%94%9F%E6%88%90%E7%AE%97%E6%95%B0%E8%A1%A8%E8%BE%BE%E5%BC%8F%E4%BA%8C%E5%8F%89%E6%A0%91/"},{"categories":["数据结构"],"content":"几个月前数据结构的课设，抽到了一个比较简单的题目。想着用java语言来实现一下（学的时候是C语言版的数据结构）。毕竟在java项目中，万物皆可对象化，一个类型的数据创建为一个对象，其他函数可以来调用对象实例化是非常香的，所以我打算用java语言来完成本次课设。Java语言来写一个数据结构项目是很吃香的，毕竟java作为一个成熟的高级语言，它里面封装好了许多可以直接用的非常简便的函数，甚至还有封装好的数据结构比如“栈”，在java里我只需要Stack stack = new Stack;就可以直接生成的一个栈。 没想到网上找不到任何能参考的代码。java语言没有指针把我给难倒了，毕竟我所学的数据结构大量用到了指针功能，最终一个多星期还是写出来了，至于指针我调用了大量的递归，导致代码的可读性和执行效率降了一大截。后来了解了可以用引用类来替代指针（属实是当时java没学好）。为了让老师能看懂代码做了流程图来解释代码。 具体代码如下 先创建目录tree 创建一个名为Node的java.class文件来建立叶子结点的类，里面有三个成员变量，数据域、左孩子、右孩子。并自动生成了所有成员变量的set和get函数。 Node.java package tree; public class Node { Object data = null;//数据 Node left;//左节点 Node right = null;//右节点 public Node(){ } public Node(Object data) { super(); this.data = data; } public Object getData() { return data; } public void setData(Object data) { this.data = data; } public Node getLeft() { return left; } public void setLeft(Node left) { this.left = left; } public Node getRight() { return right; } public void setRight(Node right) { this.right = right; } } 创建二叉树的类，在里面把各种操作都写成了成员方法。 towtree.java package tree; import javax.script.*; import java.util.ArrayList; import java.util.Collections; import java.util.Scanner; import java.util.Stack; public class towtree\u003cE\u003e { private Node root;// 根节点 private String result = \"\";// 储存后缀表达式 Stack\u003cNode\u003e list = new Stack\u003cNode\u003e();// 生成树栈 Stack\u003cDouble\u003estack = new Stack\u003cDouble\u003e();// 计算结果栈 /* * 生成二叉树函数 * */ public void add(String str) { String[] sarray = str.split(\"\"); Node node = new Node(); if (sarray.length == 1) { String key = sarray[0]; root = new Node(); root.setData(key); } else { // debugcreattree(0,sarray,node); creattree(0,sarray,node); } } // 让根节点等于最后一个节点 public void creattree(int i,String[] str,Node node) { String key = str[i]; char ch = key.charAt(0); if ((ch \u003e= 'A' \u0026\u0026 ch \u003c= 'Z')||(ch \u003e= 'a' \u0026\u0026 ch \u003c= 'z')||(ch \u003e= '0' \u0026\u0026 ch \u003c= '9')) {// 如果是字母或数字 if (node.getData() == null) { // 进入判断字母或数字语句 node.setData(key); // 进入赋值语句 Node point = list.pop(); // 进入出栈语句 if (point.getRight() == null ) { // 进入右子树不存在并初始化右子树语句 Node node1 = new Node(); point.setRight(node1); list.push(point); // 进入入栈语句 int j = i + 1; if (j == str.length) return; creattree(j,str,point.getRight()); } else { // 进入右子树存在出栈语句 list.push(point); // 进入入栈语句 while (true) { Node pop = list.pop(); // pop进入出栈语句 if (list.isEmpty())break; Node top = list.pop(); // top进入出栈语句 if (top.getRight() == null){ // 进入右子树为空语句 int j = i + 1; if (j == str.length) return; if (top.getLeft().getData() == null ) { // 顶栈左子树未赋值并赋值pop语句 top.setLeft(pop); list.push(top); // top进入入栈语句 creattree(j,str,top.getLeft()); break; } creattree(j,str,top.getRight()); break; } else if (top.getRight().getData() == null) { if (top.getLeft().getData() == null ) { // 进入顶栈左子树未赋值并赋值pop语句 top.setLeft(pop); list.push(top); // top进入入栈语句 int j = i + 1; if (j == str.length) return; creattree(j,str,top.getRight()); break; }else { // 进入顶栈右子树存在未赋值并赋值pop语句 top.setRight(pop); list.push(top); // top进入入栈语句 } if (list.isEmpty())break; } } } } } else { // 如果是运算符 if (i == 0) { node.setData(key); root = node; Node node1 = new Node(); node.setLeft(node1); list.push(node); // 进入入栈语句 creattree(1,str,node.getLeft()); } else { Node point = list.pop(); // 进入出栈语句 if (point.getRight() == null ) { Node node1 = new Node(); point.setRight(node1); list.push(point); // 进入入栈语句 }else { list.push(point); // 进入入栈语句 } Node node1 = new Node(); node1.setData(key); int j = i + 1; if (j == str.length) return; Node node2 = new Node(); node1.setLeft(node2); list.push(node1); // 进入入栈语句 creattree(j,str,node1.getLeft()); } } } /* * 调试生成二叉树函数 * */ public void debugcreattree(int i,String[] str,Node node) { String key = str[i]; char ch = key.charAt(0); if ((ch \u003e= 'A' \u0026\u0026 ch \u003c= 'Z')||(ch \u003e= 'a' \u0026\u0026 ch \u003c= 'z')||(ch \u003e= '0' \u0026\u0026 ch \u003c= '9')) { if (node.getData() == null) { node.setData(key); System.out.println(key+\"进入赋值语句\"); Node point = list.pop(); System.out.println(point.getData().toString()+\"进入出栈语句\"); if (point.getRight() == null ) { System.out.println(point.getData().toString()+\"进入右子树不存在并初始化右子树语句\"); Node node1 = new Node();","date":"2023-06-06","objectID":"/java%E8%AF%AD%E8%A8%80%E7%94%9F%E6%88%90%E7%AE%97%E6%95%B0%E8%A1%A8%E8%BE%BE%E5%BC%8F%E4%BA%8C%E5%8F%89%E6%A0%91/:0:0","tags":["java,数据结构"],"title":"Java语言生成算数表达式二叉树","uri":"/java%E8%AF%AD%E8%A8%80%E7%94%9F%E6%88%90%E7%AE%97%E6%95%B0%E8%A1%A8%E8%BE%BE%E5%BC%8F%E4%BA%8C%E5%8F%89%E6%A0%91/"},{"categories":["分布式技术"],"content":"分布式技术学习笔记","date":"2023-06-05","objectID":"/%E5%88%86%E5%B8%83%E5%BC%8F%E6%8A%80%E6%9C%AF/","tags":["分布式"],"title":"分布式技术基础","uri":"/%E5%88%86%E5%B8%83%E5%BC%8F%E6%8A%80%E6%9C%AF/"},{"categories":["分布式技术"],"content":"一、分布式技术体系 二、分布式协调与同步 ","date":"2023-06-05","objectID":"/%E5%88%86%E5%B8%83%E5%BC%8F%E6%8A%80%E6%9C%AF/:0:0","tags":["分布式"],"title":"分布式技术基础","uri":"/%E5%88%86%E5%B8%83%E5%BC%8F%E6%8A%80%E6%9C%AF/"},{"categories":["分布式技术"],"content":"2.1 分布式互斥 传统单机上的互斥方法，为什么不能用于分布式环境呢？因为在分布式场景下,很难保证操作的原子性。 分布式系统里，这种排他性的资源访问方式，叫作**分布式互斥（Distributed Mutual Exclusion），*而这种被互斥访问的共享资源就叫作*临界资源（Critical Resource）。 如何才能让分布式系统里的程序互斥地访问临界资源。 ","date":"2023-06-05","objectID":"/%E5%88%86%E5%B8%83%E5%BC%8F%E6%8A%80%E6%9C%AF/:1:0","tags":["分布式"],"title":"分布式技术基础","uri":"/%E5%88%86%E5%B8%83%E5%BC%8F%E6%8A%80%E6%9C%AF/"},{"categories":["分布式技术"],"content":"霸道总裁：集中式算法 ⁉️原理： 我们引入一个协调者程序，得到一个分布式互斥算法。每个程序在需要访问临界资源时，先给协调者发送一个请求。如果当前没有程序使用这个资源，协调者直接授权请求程序访问；否则，按照先来后到的顺序为请求程序“排一个号”。如果有程序使用完资源，则通知协调者，协调者从“排号”的队列里取出排在最前面的请求，并给它发送授权消息。拿到授权消息的程序，可以直接去访问临界资源。 这个互斥算法，就是我们所说的集中式算法，也可以叫做中央服务器算法。之所以这么称呼，是因为协调者代表着集中程序或中央服务器。 集中式算法的示意图如下所示： ☎️通信成本： 从上述流程可以看出，一个程序完成一次临界资源访问，需要如下几个流程和消息交互： 向协调者发送请求授权信息，1 次消息交互； 协调者向程序发放授权信息，1 次消息交互； 程序使用完临界资源后，向协调者发送释放授权，1 次消息交互。 因此，每个程序完成一次临界资源访问，需要进行 3 次消息交互。 🎉优点：集中式算法的优点在于直观、简单、信息交互量少、易于实现，并且所有程序只需和协调者通信，程序之间无需通信。 📛缺点或局限性： 一方面，协调者会成为系统的性能瓶颈。想象一下，如果有 100 个程序要访问临界资源，那么协调者要处理 100*3=300 条消息。也就是说，协调者处理的消息数量会随着需要访问临界资源的程序数量线性增加。 另一方面，容易引发单点故障问题。协调者故障，会导致所有的程序均无法访问临界资源，导致整个系统不可用。 💲应用：zookeeper，redis 因此，在使用集中式算法的时候，一定要选择性能好、可靠性高的服务器来运行协调者。 **小结一下：**集中式算法具有简单、易于实现的特点，但可用性、性能易受协调者影响。在可靠性和性能有一定保障的情况下，比如中央服务器计算能力强、性能高、故障率低，或者中央服务器进行了主备备份，主故障后备可以立马升为主，且数据可恢复的情况下，集中式算法可以适用于比较广泛的应用场景如（HDFS）。 ","date":"2023-06-05","objectID":"/%E5%88%86%E5%B8%83%E5%BC%8F%E6%8A%80%E6%9C%AF/:1:1","tags":["分布式"],"title":"分布式技术基础","uri":"/%E5%88%86%E5%B8%83%E5%BC%8F%E6%8A%80%E6%9C%AF/"},{"categories":["分布式技术"],"content":"民主协商：分布式算法 ⁉️原理： 当一个程序要访问临界资源时，先向系统中的其他程序发送一条请求消息，在接收到所有程序返回的同意消息后，才可以访问临界资源。其中，请求消息需要包含所请求的资源、请求者的 ID，以及发起请求的时间。 这就是民主协商法。在分布式领域中，我们称之为分布式算法，或者使用组播和逻辑时钟的算法。 ☎️通信成本： 从上述流程可以看出，一个程序完成一次临界资源的访问，需要进行如下的信息交互： 向其他 n-1 个程序发送访问临界资源的请求，总共需要 n-1 次消息交互； 需要接收到其他 n-1 个程序回复的同意消息，方可访问资源，总共需要 n-1 次消息交互。 可以看出，一个程序要成功访问临界资源，至少需要 2*(n-1) 次消息交互。假设，现在系统中的 n 个程序都要访问临界资源，则会同时产生 2n(n-1) 条消息。总结来说，在大型系统中使用分布式算法，消息数量会随着需要访问临界资源的程序数量呈指数级增加，容易导致高昂的“沟通成本”。 🎉优点：分布式算法根据“先到先得”以及“投票全票通过”的机制，让每个程序按时间顺序公平地访问资源，简单粗暴、易于实现。 📛缺点或局限性： 这个算法可用性很低，主要包括两个方面的原因： 当系统内需要访问临界资源的程序增多时，容易产生“信令风暴”，也就是程序收到的请求完全超过了自己的处理能力，而导致自己正常的业务无法开展。 一旦某一程序发生故障，无法发送同意消息，那么其他程序均处在等待回复的状态中，使得整个系统处于停滞状态，导致整个系统不可用。所以，相对于集中式算法的协调者故障，分布式算法的可用性更低。 💲应用： 分布式算法适合节点数目少且变动不频繁的系统，且由于每个程序均需通信交互，因此适合 P2P 结构的系统。比如，运行在局域网中的分布式文件系统，具有 P2P 结构的系统等。 针对可用性低的一种改进办法是，如果检测到一个程序故障，则直接忽略这个程序，无需再等待它的同意消息。这就好比在自助餐厅，一个人离开餐厅了，那你在使用咖啡机前，也无需征得他的同意。但这样的话，每个程序都需要对其他程序进行故障检测，这无疑带来了更大的复杂性。 **归纳一下：**分布式算法是一个“先到先得”和“投票全票通过”的公平访问机制，但通信成本较高，可用性也比集中式算法低，适用于临界资源使用频度较低，且系统规模较小的场景。 ","date":"2023-06-05","objectID":"/%E5%88%86%E5%B8%83%E5%BC%8F%E6%8A%80%E6%9C%AF/:1:2","tags":["分布式"],"title":"分布式技术基础","uri":"/%E5%88%86%E5%B8%83%E5%BC%8F%E6%8A%80%E6%9C%AF/"},{"categories":["分布式技术"],"content":"轮值 CEO：令牌环算法 ⁉️原理： 程序访问临界资源问题也可按照轮值 CEO 的思路实现。 如下图所示，所有程序构成一个环结构，令牌按照顺时针（或逆时针）方向在程序之间传递，收到令牌的程序有权访问临界资源，访问完成后将令牌传送到下一个程序；若该程序不需要访问临界资源，则直接把令牌传送给下一个程序。在分布式领域，这个算法叫作令牌环算法，也可以叫作基于环的算法。为了便于理解与记忆，你完全可以把这个方法形象地理解为轮值 CEO 法。 ☎️通信成本：无。 🎉优点：在令牌环算法里单个程序具有更高的通信效率。同时，在一个周期内，每个程序都能访问到临界资源，因此令牌环算法的公平性很好。 📛缺点或局限性：对于集中式和分布式算法都存在的单点故障问题，在令牌环中，若某一个程序（例如上图的无人机 2）出现故障，则直接将令牌传递给故障程序的下一个程序（例如，上图中无人机 1 直接将令牌传送给无人机 3），从而很好地解决单点故障问题，提高系统的健壮性，带来更好的可用性。但，这就要求每个程序都要记住环中的参与者信息，这样才能知道在跳过一个参与者后令牌应该传递给谁。 💲应用：综上，令牌环算法非常适合通信模式为令牌环方式的分布式系统，例如移动自组织网络系统。一个典型的应用场景就是无人机通信。 **小结一下：**令牌环算法的公平性高，在改进单点故障后，稳定性也很高，适用于系统规模较小，并且系统中每个程序使用临界资源的频率高且使用时间比较短的场景。 ","date":"2023-06-05","objectID":"/%E5%88%86%E5%B8%83%E5%BC%8F%E6%8A%80%E6%9C%AF/:1:3","tags":["分布式"],"title":"分布式技术基础","uri":"/%E5%88%86%E5%B8%83%E5%BC%8F%E6%8A%80%E6%9C%AF/"},{"categories":["分布式技术"],"content":"知识扩展：有适合大规模系统中的分布式互斥算法吗？ 可以看到，上面提到的集中式、分布式和令牌环 3 个互斥算法，都不适用于规模过大、节点数量过多的系统。那么，什么样的互斥算法适用于大规模系统呢？ 由于大规模系统的复杂性，我们很自然地想到要用一个相对复杂的互斥算法。时下有一个很流行的互斥算法，**两层结构的分布式令牌环算法，**把整个广域网系统中的节点组织成两层结构，可以用于节点数量较多的系统，或者是广域网系统。 每个局域网中包含若干个局部进程和一个协调进程。局部进程在逻辑上组成一个环形结构，在每个环形结构上有一个局部令牌 T 在局部进程间传递。局域网与局域网之间通过各自的协调进程进行通信，这些协调进程同样组成一个环结构，这个环就是广域网中的全局环。在这个全局环上，有一个全局令牌在多个协调进程间传递。 ","date":"2023-06-05","objectID":"/%E5%88%86%E5%B8%83%E5%BC%8F%E6%8A%80%E6%9C%AF/:1:4","tags":["分布式"],"title":"分布式技术基础","uri":"/%E5%88%86%E5%B8%83%E5%BC%8F%E6%8A%80%E6%9C%AF/"},{"categories":["分布式技术"],"content":"总结 ","date":"2023-06-05","objectID":"/%E5%88%86%E5%B8%83%E5%BC%8F%E6%8A%80%E6%9C%AF/:1:5","tags":["分布式"],"title":"分布式技术基础","uri":"/%E5%88%86%E5%B8%83%E5%BC%8F%E6%8A%80%E6%9C%AF/"},{"categories":["分布式技术"],"content":"2.2 中心化的分布式选举（共识） 集群一般是由两个或两个以上的服务器组建而成，每个服务器都是一个节点。我们经常会听到数据库集群、管理集群等概念，也知道数据库集群提供了读写功能，管理集群提供了管理、故障恢复等功能。 为什么要有分布式选举？ 主节点，在一个分布式集群中负责对其他节点的协调和管理，也就是说，其他节点都必须听从主节点的安排。 主节点的存在，就可以保证其他节点的有序运行，以及数据库集群中的写入数据在每个节点上的一致性。这里的一致性是指，数据在每个集群节点中都是一样的，不存在不同的情况。 就应了那句话“国不可一日无君”，对应到分布式系统中就是“集群不可一刻无主”。总结来说，选举的作用就是选出一个主节点，由它来协调和管理其他节点，以保证集群有序运行和节点间数据的一致性。 目前常见的选主方法有基于序号选举的算法（ 比如，Bully 算法）、多数派算法（比如，Raft 算法、ZAB 算法）等。 ","date":"2023-06-05","objectID":"/%E5%88%86%E5%B8%83%E5%BC%8F%E6%8A%80%E6%9C%AF/:2:0","tags":["分布式"],"title":"分布式技术基础","uri":"/%E5%88%86%E5%B8%83%E5%BC%8F%E6%8A%80%E6%9C%AF/"},{"categories":["分布式技术"],"content":"长者为大：Bully 算法 🖋简介： Bully 算法是一种霸道的集群选主算法，为什么说是霸道呢？因为它的选举原则是“长者”为大，即在所有活着的节点中，选取 ID 最大的节点作为主节点。 ⁉️原理： 在 Bully 算法中，节点的角色有两种：普通节点和主节点。初始化时，所有节点都是平等的，都是普通节点，并且都有成为主的权利。但是，当选主成功后，有且仅有一个节点成为主节点，其他所有节点都是普通节点。当且仅当主节点故障或与其他节点失去联系后，才会重新选主。 Bully 算法在选举过程中，需要用到以下 3 种消息： Election 消息，用于发起选举； Alive 消息，对 Election 消息的应答； Victory 消息，竞选成功的主节点向其他节点发送的宣誓主权的消息。 Bully 算法选举的原则是“长者为大”，意味着它的**假设条件是，集群中每个节点均知道其他节点的 ID。**在此前提下，其具体的选举过程是： 集群中每个节点判断自己的 ID 是否为当前活着的节点中 ID 最大的，如果是，则直接向其他节点发送 Victory 消息，宣誓自己的主权； 如果自己不是当前活着的节点中 ID 最大的，则向比自己 ID 大的所有节点发送 Election 消息，并等待其他节点的回复； 若本节点收到比自己 ID 小的节点发送的 Election 消息，则回复一个 Alive 消息，告知其他节点，我比你大，重新选举； 若在给定的时间范围内，本节点没有收到其他节点回复的 Alive 消息，则认为自己成为主节点，并向其他节点发送 Victory 消息，宣誓自己成为主节点；若接收到来自比自己 ID 大的节点的 Alive 消息，则等待其他节点发送 Victory 消息； ☎️通信成本：不确定，但是不少。 🎉优点：Bully 算法的选择特别霸道和简单，选举谁活着且谁的 ID 最大谁就是主节点，其他节点必须无条件服从。速度快、算法复杂度低、简单易实现。 📛缺点或局限性：需要每个节点有全局的节点信息，因此额外信息存储较多；其次，任意一个比当前主节点 ID 大的新节点或节点故障后恢复加入集群的时候，都可能会触发重新选举，成为新的主节点，如果该节点频繁退出、加入集群，就会导致频繁切主。 💲应用：目前已经有很多开源软件采用了 Bully 算法进行选主，比如 MongoDB 的副本集故障转移功能。MongoDB 的分布式选举中，采用节点的最后操作时间戳来表示 ID，时间戳最新的节点其 ID 最大，也就是说时间戳最新的、活着的节点是主节点。 ","date":"2023-06-05","objectID":"/%E5%88%86%E5%B8%83%E5%BC%8F%E6%8A%80%E6%9C%AF/:2:1","tags":["分布式"],"title":"分布式技术基础","uri":"/%E5%88%86%E5%B8%83%E5%BC%8F%E6%8A%80%E6%9C%AF/"},{"categories":["分布式技术"],"content":"民主投票：Raft 算法的投票部分 🖋简介： Raft 算法是典型的多数派投票选举的共识算法，其选举机制与我们日常生活中的民主投票机制类似，核心思想是“少数服从多数”。也就是说，Raft 算法中，获得投票最多的节点成为主。 ⁉️原理： 采用 Raft 算法选举，集群节点的角色有 3 种： Leader，即主节点，同一时刻只有一个 Leader，负责协调和管理其他节点； Candidate，即候选者，每一个节点都可以成为 Candidate，节点在该角色下才可以被选为新的 Leader； Follower，Leader 的跟随者，不可以发起选举。 Raft 选举的流程，可以分为以下几步： 初始化时，所有节点均为 Follower 状态。 开始选主时，所有节点的状态由 Follower 转化为 Candidate，并向其他节点发送选举请求。 其他节点根据接收到的选举请求的先后顺序，回复是否同意成为主。这里需要注意的是，在每一轮选举中，一个节点只能投出一张票。 若发起选举请求的节点获得超过一半的投票，则成为主节点，其状态转化为 Leader，其他节点的状态则由 Candidate 降为 Follower。Leader 节点与 Follower 节点之间会定期发送心跳包，以检测主节点是否活着。 当 Leader 节点的任期到了，即发现其他服务器开始下一轮选主周期时，Leader 节点的状态由 Leader 降级为 Follower，进入新一轮选主。 节点的状态迁移如下所示（图中的 term 指的是选举周期）： 请注意，**每一轮选举，每个节点只能投一次票。**这种选举就类似人大代表选举，正常情况下每个人大代表都有一定的任期，任期到后会触发重新选举，且投票者只能将自己手里唯一的票投给其中一个候选者。对应到 Raft 算法中，选主是周期进行的，包括选主和任值两个时间段，选主阶段对应投票阶段，任值阶段对应节点成为主之后的任期。但也有例外的时候，如果主节点故障，会立马发起选举，重新选出一个主节点。 ☎️通信成本：通信量较大。 🎉优点：Raft 算法具有选举速度快、算法复杂度低、易于实现的优点；该算法选举稳定性比 Bully 算法好，这是因为当有新节点加入或节点故障恢复后，会触发选主，但不一定会真正切主，除非新节点或故障后恢复的节点获得投票数过半，才会导致切主。 📛缺点或局限性：它要求系统内每个节点都可以相互通信，且需要获得过半的投票数才能选主成功，因此通信量大。 💲应用：Google 开源的 Kubernetes，擅长容器管理与调度，为了保证可靠性，通常会部署 3 个节点用于数据备份。这 3 个节点中，有一个会被选为主，其他节点作为备。Kubernetes 的选主采用的是开源的 etcd 组件。而，etcd 的集群管理器 etcds，是一个高可用、强一致性的服务发现存储仓库，就是采用了 Raft 算法来实现选主和一致性的。 ","date":"2023-06-05","objectID":"/%E5%88%86%E5%B8%83%E5%BC%8F%E6%8A%80%E6%9C%AF/:2:2","tags":["分布式"],"title":"分布式技术基础","uri":"/%E5%88%86%E5%B8%83%E5%BC%8F%E6%8A%80%E6%9C%AF/"},{"categories":["分布式技术"],"content":"具有优先级的民主投票：ZAB 算法 🖋简介： ZAB（ZooKeeper Atomic Broadcast）选举算法是为 ZooKeeper 实现分布式协调功能而设计的。相较于 Raft 算法的投票机制，ZAB 算法增加了通过节点 ID 和数据 ID 作为参考进行选主，节点 ID 和数据 ID 越大，表示数据越新，优先成为主。相比较于 Raft 算法，ZAB 算法尽可能保证数据的最新性。所以，ZAB 算法可以说是对 Raft 算法的改进。 ⁉️原理： 使用 ZAB 算法选举时，集群中每个节点拥有 3 种角色： Leader，主节点； Follower，跟随者节点； Observer，观察者，无投票权。 选举过程中，集群中的节点拥有 4 个状态： Looking 状态，即选举状态。当节点处于该状态时，它会认为当前集群中没有 Leader，因此自己进入选举状态。 Leading 状态，即领导者状态，表示已经选出主，且当前节点为 Leader。 Following 状态，即跟随者状态，集群中已经选出主后，其他非主节点状态更新为 Following，表示对 Leader 的追随。 Observing 状态，即观察者状态，表示当前节点为 Observer，持观望态度，没有投票权和选举权。 投票过程中，每个节点都有一个唯一的三元组 (server_id, server_zxID, epoch)，其中 server_id 表示本节点的唯一 ID；server_zxID 表示本节点存放的数据 ID，数据 ID 越大表示数据越新，选举权重越大；epoch 表示当前选取轮数，一般用逻辑时钟表示。 ZAB 选举算法的核心是“少数服从多数，ID 大的节点优先成为主”，因此选举过程中通过 (vote_id, vote_zxID) 来表明投票给哪个节点，其中 vote_id 表示被投票节点的 ID，vote_zxID 表示被投票节点的服务器 zxID。ZAB 算法选主的原则是：server_zxID 最大者成为 Leader；若 server_zxID 相同，则 server_id 最大者成为 Leader。 接下来，我以 3 个 Server 的集群为例，此处每个 Server 代表一个节点，与你介绍 ZAB 选主的过程。 第一步：当系统刚启动时，3 个服务器当前投票均为第一轮投票，即 epoch=1，且 zxID 均为 0。此时每个服务器都推选自己，并将选票信息 \u003cepoch, vote_id, vote_zxID\u003e 广播出去。 第二步：根据判断规则，由于 3 个 Server 的 epoch、zxID 都相同，因此比较 server_id，较大者即为推选对象，因此 Server 1 和 Server 2 将 vote_id 改为 3，更新自己的投票箱并重新广播自己的投票。 第三步：此时系统内所有服务器都推选了 Server 3，因此 Server 3 当选 Leader，处于 Leading 状态，向其他服务器发送心跳包并维护连接；Server1 和 Server2 处于 Following 状态。 ☎️通信成本：采用广播方式发送信息，若节点中有 n 个节点，每个节点同时广播，则集群中信息量为 n*(n-1) 个消息 🎉优点:ZAB 算法性能高，对系统无特殊要求。该算法选举稳定性比较好，当有新节点加入或节点故障恢复后，会触发选主，但不一定会真正切主，除非新节点或故障后恢复的节点数据 ID 和节点 ID 最大，且获得投票数过半，才会导致切主。 📛缺点或局限性：容易出现广播风暴；且除了投票，还增加了对比节点 ID 和数据 ID，这就意味着还需要知道所有节点的 ID 和数据 ID，所以选举时间相对较长。 💲应用：zookeeper ","date":"2023-06-05","objectID":"/%E5%88%86%E5%B8%83%E5%BC%8F%E6%8A%80%E6%9C%AF/:2:3","tags":["分布式"],"title":"分布式技术基础","uri":"/%E5%88%86%E5%B8%83%E5%BC%8F%E6%8A%80%E6%9C%AF/"},{"categories":["分布式技术"],"content":"三种算法对比 ","date":"2023-06-05","objectID":"/%E5%88%86%E5%B8%83%E5%BC%8F%E6%8A%80%E6%9C%AF/:2:4","tags":["分布式"],"title":"分布式技术基础","uri":"/%E5%88%86%E5%B8%83%E5%BC%8F%E6%8A%80%E6%9C%AF/"},{"categories":["分布式技术"],"content":"知识扩展： 为什么“多数派”选主算法通常采用奇数节点，而不是偶数节点呢？ 多数派选主算法的核心是少数服从多数，获得投票多的节点胜出。想象一下，如果现在采用偶数节点集群，当两个节点均获得一半投票时，到底应该选谁为主呢？ 答案是，**在这种情况下，无法选出主，必须重新投票选举。**但即使重新投票选举，两个节点拥有相同投票数的概率也会很大。因此，多数派选主算法通常采用奇数节点。 这，也是大家通常看到 ZooKeeper、 etcd、Kubernetes 等开源软件选主均采用奇数节点的一个关键原因。 脑裂 脑裂问题就是在多机热备的高可用HA系统中，当两个结点心跳突然断开，纠纷列为两个独立的个体，由于互相失去联系，都认为对方出现了故障，因此都会争抢对方的资源，这就是脑裂问题 通俗的讲，脑裂(split-brain)就是“大脑分裂”，本来一个“大脑”被拆分成两个或多个。试想，如果一个人有多个大脑，且相互独立，就会导致人体“手舞足蹈”，“不听使唤”。 产生脑裂问题的原因： 1.网络问题-\u003e网络异常问题造成集群发生物理分离，造成脑裂 2.节点负载-\u003e若master结点负载过高，可能造成master结点停止响应，从而脱离集群，集群重新选主，恢复响应后出现脑裂问题 3.Leader假死-\u003e其余的followers选举出了一个新的Leader。这时，旧的Leader复活并且仍然认为自己是Leader 解决措施： 1.集群尽量部署在同一个内网环境中，从而保证各节点通讯的可靠性 2.master结点与data结点分离，保证master结点响应能力（通过node.master ：true 与 node.data：false 来决定是否有成为master结点的资格） 3.ZooKeeper维护了一个叫epoch的变量，每当新Leader产生时，会生成一个epoch标号（标识当前属于那个Leader的统治时期），epoch是递增的，followers如果确认了新的Leader存在，知道其epoch，就会拒绝epoch小于现任leader epoch的所有请求。 4.Zookeeper默认采用的是“过半原则”。所谓的过半原则就是：在Leader选举的过程中，如果某台zkServer获得了超过半数的选票，则此zkServer就可以成为Leader了。Zookeeper集群通过过半机制，达到了要么没有Leader，要没只有1个Leader，这样就避免了脑裂问题。 5.Quorums（法定人数）方式：比如3个节点的集群，Quorums = 2，也就是说集群可以容忍1个节点失效，这时候还能选举出1个lead，集群还可用。比如4个节点的集群，它的Quorums = 3，Quorums要超过3，相当于集群的容忍度还是1，如果2个节点失效，那么整个集群还是无效的。这是ZooKeeper防止“脑裂”默认采用的方法。 6.添加心跳线：添加心跳线。原来只有一条心跳线路，此时若断开，则接收不到心跳报告，判断对方已经死亡。若有2条心跳线路，一条断开，另一条仍然能够接收心跳报告，能保证集群服务正常运行。心跳线路之间也可以 HA（高可用），这两条心跳线路之间也可以互相检测，若一条断开，则另一条马上起作用。正常情况下，则不起作用，节约资源。 ","date":"2023-06-05","objectID":"/%E5%88%86%E5%B8%83%E5%BC%8F%E6%8A%80%E6%9C%AF/:2:5","tags":["分布式"],"title":"分布式技术基础","uri":"/%E5%88%86%E5%B8%83%E5%BC%8F%E6%8A%80%E6%9C%AF/"},{"categories":["分布式技术"],"content":"2.3 去中心化的分布式共识 从本质上看，分布式选举问题，其实就是传统的分布式共识方法，主要是基于多数投票策略实现的。 如果用于分布式在线记账一致性问题中，那么记账权通常会完全掌握到主节点的手里，这使得主节点非常容易造假，且存在性能瓶颈。因此，分布式选举不适用于分布式在线记账的一致性问题。 这里所说的分布式在线记账（区块链），是指在没有集中的发行方，也就是没有银行参与的情况下，任意一台接入互联网的电脑都能参与买卖，所有看到该交易的服务器都可以记录这笔交易，并且记录信息最终都是一致的，以保证交易的准确性。而如何保证交易的一致性，就是该场景下的分布式共识问题。 介绍 3 种主流的解决分布式在线记账一致性问题的共识技术 ","date":"2023-06-05","objectID":"/%E5%88%86%E5%B8%83%E5%BC%8F%E6%8A%80%E6%9C%AF/:3:0","tags":["分布式"],"title":"分布式技术基础","uri":"/%E5%88%86%E5%B8%83%E5%BC%8F%E6%8A%80%E6%9C%AF/"},{"categories":["分布式技术"],"content":"POW（Proof-of-Work，工作量证明） 🖋简介： 同一轮选举中有且仅有一个节点成为主节点。同理，在分布式在线记账问题中，针对同一笔交易，有且仅有一个节点或服务器可以获得记账权，然后其他节点或服务器同意该节点或服务器的记账结果，达成一致。也就是说，分布式共识包括两个关键点，获得记账权和所有节点或服务器达成一致。 ⁉️原理： 是以每个节点或服务器的计算能力（即“算力”）来竞争记账权的机制，因此是一种使用工作量证明机制的共识算法。也就是说，谁的计算力强、工作能力强，谁获得记账权的可能性就越大。 如何体现节点的“算力”呢？每个节点都去解一道题，谁能先解决谁的能力就强。 假设每个节点会划分多个区块用于记录用户交易，PoW 算法获取记账权的原理是：利用区块的 index、前一个区块的哈希值、交易的时间戳、区块数据和 nonce 值，通过 SHA256 哈希算法计算出一个哈希值，并判断前 k 个值是否都为 0。如果不是，则递增 nonce 值，重新按照上述方法计算；如果是，则本次计算的哈希值为要解决的题目的正确答案。谁最先计算出正确答案，谁就获得这个区块的记账权。 请注意：nonce 值是用来找到一个满足哈希值的数字；k 为哈希值前导零的个数，标记了计算的难度，0 越多计算难度越大。 达成共识的过程，就是获得记账权的节点将该区块信息广播给其他节点，其他节点判断该节点找到的区块中的所有交易都是有效且之前未存在过的，则认为该区块有效，并接受该区块，达成一致。 ☎️通信成本：PoW 机制每次达成共识需要全网共同参与运算 🎉优点：PoW 通过“挖矿”的方式发行新币，把比特币分散给个人，实现了相对的公平。PoW 的容错机制，允许全网 50% 的节点出错，因此，如果要破坏系统，则需要投入极大成本（若你有全球 51% 的算力，则可尝试攻击比特币）。 📛缺点或局限性：增加了每个节点的计算量，并且如果题目过难，会导致计算时间长、资源消耗多；而如果题目过于简单，会导致大量节点同时获得记账权，冲突多。这些问题，都会增加达成共识的时间。PoW 机制的缺点也很明显，共识达成的周期长、效率低，资源消耗大。 💲应用：目前，比特币平台采用了 PoW 算法，属于区块链 1.0 阶段，其重心在于货币，比特币大约 10min 才会产生一个区块，区块的大小也只有 1MB，仅能够包含 3000～4000 笔交易，平均每秒只能够处理 5~7（个位数）笔交易。 ","date":"2023-06-05","objectID":"/%E5%88%86%E5%B8%83%E5%BC%8F%E6%8A%80%E6%9C%AF/:3:1","tags":["分布式"],"title":"分布式技术基础","uri":"/%E5%88%86%E5%B8%83%E5%BC%8F%E6%8A%80%E6%9C%AF/"},{"categories":["分布式技术"],"content":"PoS（Proof-of-Stake，权益证明） 🖋简介： 为了解决 PoW 算法的问题，引入了 PoS 算法。 ⁉️原理： 由系统权益代替算力来决定区块记账权，拥有的权益越大获得记账权的概率就越大。 所谓的权益，就是每个节点占有货币的数量和时间，而货币就是节点所获得的奖励。PoW 算法充分利用了分布式在线记账中的奖励，鼓励“利滚利”。 在股权证明 PoS 模式下，根据你持有货币的数量和时间，给你发利息。每个币每天产生 1 币龄，比如你持有 100 个币，总共持有了 50 天，那么，你的币龄就为 5000。这个时候，如果你发现了一个 PoS 区块，你的币龄就会被减少 365。每被减少 365 币龄，你就可以从区块中获得 0.05 个币的利息 (可理解为年利率 5%)。 利息 = （5000*5% ）/365 = 0.68 个币。持币有利息。 基于 PoS 算法获得区块记账权的方法与基于 PoW 的方法类似，不同之处在于：节点计算获取记账权的方法不一样，PoW 是利用区块的 index、前一个区块的哈希值、交易的时间戳、区块数据和 nonce 值，通过 SHA256 哈希算法计算出一个哈希值，并判断前 k 个值是否都为 0，而 PoS 是根据节点拥有的股权或权益进行计算的。 ☎️通信成本：每个节点在计算自己记账权的时候，通过计算自己的股权或权益来评估，如果发现自己权益最大，则将自己的区块广播给其他节点，当然必须保证该区块的有效性。 🎉优点：PoS 将算力竞争转变成权益竞争。与 PoW 相比，PoS 不需要消耗大量的电力就能够保证区块链网络的安全性，同时也不需要在每个区块中创建新的货币来激励记账者参与当前网络的运行，这也就在一定程度上缩短了达成共识所需要的时间 📛缺点或局限性：PoS 算法中持币越多或持币越久，币龄就会越高，持币人就越容易挖到区块并得到激励，而持币少的人基本没有机会，这样整个系统的安全性实际上会被持币数量较大的一部分人掌握，容易出现垄断现象。 💲应用：以太坊平台属于区块链 2.0 阶段，在区块链 1.0 的基础上进一步强调了合约，采用了 PoS 算法。12 年发布的点点币（PPC），综合了 PoW 工作量证明及 PoS 权益证明方式，从而在安全和节能方面实现了创新。 ","date":"2023-06-05","objectID":"/%E5%88%86%E5%B8%83%E5%BC%8F%E6%8A%80%E6%9C%AF/:3:2","tags":["分布式"],"title":"分布式技术基础","uri":"/%E5%88%86%E5%B8%83%E5%BC%8F%E6%8A%80%E6%9C%AF/"},{"categories":["分布式技术"],"content":"DPoS（Delegated Proof of Stake，委托权益证明） 🖋简介： 为了解决 PoS 算法的垄断问题，2014 年比特股（BitShares）的首席开发者丹尼尔 · 拉里默（Dan Larimer）提出了委托权益证明法，也就是 DPoS 算法。 ⁉️原理： 类似股份制公司的董事会制度，普通股民虽然拥有股权，但进不了董事会，他们可以投票选举代表（受托人）代他们做决策。DPoS 是由被社区选举的可信帐户（受托人，比如得票数排行前 101 位）来拥有记账权。 为了成为正式受托人，用户要去社区拉票，获得足够多的信任。用户根据自己持有的货币数量占总量的百分比来投票，好比公司股票机制，假设总的发行股票为 1000，现在股东 A 持股 10，那么股东 A 投票权为 10/1000=1/100。如下图所示，根据自己拥有的权益，投票选出可代表自己的受托节点，受托节点之间竞争记账权。 在 DPos 算法中，通常会选出 k(比如 101) 个受托节点，它们的权利是完全相等的。受托节点之间争取记账权也是根据算力进行竞争的。只要受托节点提供的算力不稳定，计算机宕机或者利用手中的权力作恶，随时可以被握着货币的普通节点投票踢出整个系统，而后备的受托节点可以随时顶上去。 ☎️通信成本：低 🎉优点： DPoS 是在 PoW 和 PoS 的基础上进行改进的，相比于 PoS 算法，DPoS 引入了受托人，优点主要表现在： 由投票选举出的若干信誉度更高的受托人记账，解决了所有节点均参与竞争导致消息量大、达成一致的周期长的问题。也就是说，DPoS 能耗更低，具有更快的交易速度。 每隔一定周期会调整受托人，避免受托人造假和独权。 📛缺点或局限性：由于大多数持币人通过受托人参与投票，投票的积极性并不高；且一旦出现故障节点，DPoS 无法及时做出应对，导致安全隐患。 💲应用：DPoS 在比特股和 Steem 上已运行多年，整个网络中选举出的多个节点能够在 1s 之内对 99.9% 的交易进行确认。此外，DPoS 在 EOS（Enterprise Operation System，为商用分布式应用设计的一款区块链操作系统）中也有广泛应用，被称为区块链 3.0 阶段。 ","date":"2023-06-05","objectID":"/%E5%88%86%E5%B8%83%E5%BC%8F%E6%8A%80%E6%9C%AF/:3:3","tags":["分布式"],"title":"分布式技术基础","uri":"/%E5%88%86%E5%B8%83%E5%BC%8F%E6%8A%80%E6%9C%AF/"},{"categories":["分布式技术"],"content":"三种算法对比 ","date":"2023-06-05","objectID":"/%E5%88%86%E5%B8%83%E5%BC%8F%E6%8A%80%E6%9C%AF/:3:4","tags":["分布式"],"title":"分布式技术基础","uri":"/%E5%88%86%E5%B8%83%E5%BC%8F%E6%8A%80%E6%9C%AF/"},{"categories":["分布式技术"],"content":"知识扩展：一致性与共识的区别是什么？ 一致性是指，分布式系统中的多个节点之间，给定一系列的操作，在约定协议的保障下，对外界呈现的数据或状态是一致的。 共识是指，分布式系统中多个节点之间，彼此对某个状态达成一致结果的过程。 也就是说，一致性强调的是结果，共识强调的是达成一致的过程，共识算法是保障系统满足不同程度一致性的核心技术。 ","date":"2023-06-05","objectID":"/%E5%88%86%E5%B8%83%E5%BC%8F%E6%8A%80%E6%9C%AF/:3:5","tags":["分布式"],"title":"分布式技术基础","uri":"/%E5%88%86%E5%B8%83%E5%BC%8F%E6%8A%80%E6%9C%AF/"},{"categories":["分布式技术"],"content":"总结 ","date":"2023-06-05","objectID":"/%E5%88%86%E5%B8%83%E5%BC%8F%E6%8A%80%E6%9C%AF/:3:6","tags":["分布式"],"title":"分布式技术基础","uri":"/%E5%88%86%E5%B8%83%E5%BC%8F%E6%8A%80%E6%9C%AF/"},{"categories":["分布式技术"],"content":"2.4 分布式事务","date":"2023-06-05","objectID":"/%E5%88%86%E5%B8%83%E5%BC%8F%E6%8A%80%E6%9C%AF/:4:0","tags":["分布式"],"title":"分布式技术基础","uri":"/%E5%88%86%E5%B8%83%E5%BC%8F%E6%8A%80%E6%9C%AF/"}]